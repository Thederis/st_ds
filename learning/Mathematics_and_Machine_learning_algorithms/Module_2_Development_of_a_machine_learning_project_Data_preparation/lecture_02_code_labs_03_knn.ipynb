{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "223e1ebe",
   "metadata": {},
   "source": [
    "# Цель занятия\n",
    "На этом занятии мы рассмотрим применение алгоритма KNN для решения задач регрессии и классификации с подбором параметра K."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd02d985",
   "metadata": {},
   "source": [
    "## Регрессия\n",
    "\n",
    "Для примера регрессии с K-ближайших соседей (KNN) с подбором количества ближайших соседей (K) в библиотеке scikit-learn мы можем использовать набор данных по ценам на недвижимость в Бостоне. Мы будем использовать модуль GridSearchCV для выбора оптимального значения параметра K.\n",
    "\n",
    "Boston dataset - это набор данных, содержащий информацию о недвижимости в городе Бостон, штат Массачусетс, США. Датасет состоит из 506 строк и 14 столбцов.\n",
    "\n",
    "Каждая строка представляет собой информацию об одном районе Бостона, а каждый столбец - это различные характеристики этого района. Вот описание каждого столбца:\n",
    "\n",
    "- CRIM: Уровень преступности на душу населения в районе\n",
    "- ZN: Доля земельных участков для жилой застройки площадью более 25 000 кв. футов\n",
    "- INDUS: Доля площадей, занятых не жилой застройкой в районе\n",
    "- CHAS: Фиктивная переменная (1, если участок граничит с рекой, иначе 0)\n",
    "- NOX: Концентрация оксидов азота (частей на 10 миллионов)\n",
    "- RM: Среднее количество комнат в доме\n",
    "- AGE: Доля занимаемых владельцами жилья единиц, построенных до 1940 года\n",
    "- DIS: Взвешенное расстояние до пяти бостонских центров занятости\n",
    "- RAD: Индекс доступности радиальных магистралей\n",
    "- TAX: Ставка налога на имущество за 10 000 долларов США\n",
    "- PTRATIO: Соотношение учеников и учителей в районе\n",
    "- B: 1000 * (доля афроамериканцев в районе)\n",
    "- LSTAT: Доля населения с более низким социальным статусом\n",
    "- TARGET: Средняя стоимость занимаемых владельцами жилья единиц в 1000 долларов США"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc14ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Необходимые библиотеки\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn import model_selection as model_selection\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09fcdaa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка датасета: Для начала загрузим датасет в Pandas DataFrame.\n",
    "# Добавим имена столбцов (column_names)\n",
    "column_names = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', \n",
    "                'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT', 'TARGET']\n",
    "df = pd.read_csv('datasets/lecture_02_code_labs_03_knn.csv', \n",
    "                   header=None,\n",
    "                   delimiter=r\"\\s+\", \n",
    "                   names=column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6195d602",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Давайте проверим первые 5 строк датасета, чтобы убедиться, что загрузка прошла успешно.\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78be9fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Очистка данных: Проверим наличие пропущенных значений в датасете.\n",
    "# Если найдены пропущенные значения, то их можно удалить или заполнить средним, медианой или модой столбца.\n",
    "# В нашем случае пропущенных данных нет\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79600dbe",
   "metadata": {},
   "source": [
    "Визуализация данных: Используем библиотеку seaborn (sns) для визуализации данных. Например, построим scatter plot между двумя столбцами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72d9c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x='RM', y='TARGET', data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c49ee8d",
   "metadata": {},
   "source": [
    "Предобработка данных: Для того, чтобы подготовить данные для обучения модели машинного обучения, их необходимо обработать. Например, мы можем нормализовать данные используя StandardScaler из библиотеки scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1792db6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "df = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b75e1d",
   "metadata": {},
   "source": [
    "В библиотеке scikit-learn есть класс KNeighborsRegressor для решения задач регрессии с помощью алгоритма k-NN. Для подбора значения k можно использовать класс GridSearchCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3573012",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разделение на признаки и метки\n",
    "y = df['TARGET']\n",
    "X = df.drop(['TARGET'], axis=1)\n",
    "\n",
    "# Разделение на тренировочный и тестовый наборы\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Определение значений параметров для подбора\n",
    "param_grid = {'n_neighbors': range(1, 20)}\n",
    "\n",
    "# Создание модели k-NN\n",
    "knn = KNeighborsRegressor(metric='minkowski', p=2)\n",
    "\n",
    "# Создание объекта GridSearchCV для подбора параметра k\n",
    "grid = model_selection.GridSearchCV(knn, param_grid, cv=5)\n",
    "\n",
    "# Обучение модели на тренировочных данных\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# Определение лучшего значения k\n",
    "best_k = grid.best_params_['n_neighbors']\n",
    "\n",
    "# Прогнозирование целевых меток на тестовых данных\n",
    "y_pred = grid.predict(X_test)\n",
    "\n",
    "# Вычисление MSE\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"MSE для k = {best_k}: {mse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144a72e3",
   "metadata": {},
   "source": [
    "## Классификация\n",
    "\n",
    "Классификация с использованием метода ближайших соседей (k-Nearest Neighbors, KNN) является одним из простых и популярных методов машинного обучения. \n",
    "\n",
    "Пример использования KNN с подбором параметра k с помощью GridSearchCV в библиотеке scikit-learn представлен ниже. \n",
    "В этом примере мы используем набор данных Iris для классификации трех видов ирисов на основе их длины и ширины лепестков и чашелистников. Мы разбиваем данные на обучающую и тестовую выборки, создаем объект KNeighborsClassifier, определяем диапазон значений параметра k, который нужно проверить, и инициализируем объект GridSearchCV для перебора параметров с использованием кросс-валидации. Затем мы обучаем модель на обучающей выборке с использованием GridSearchCV для поиска оптимального значения k и создаем новую модель KNN с оптимальным значением K. В качестве метрики используется accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7f29a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Загружаем набор данных Iris\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Разбиваем данные на обучающую и тестовую выборки\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Создаем модель KNN\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# Определяем диапазон значений параметра k, которые нужно проверить\n",
    "k_range = list(range(1, 31))\n",
    "\n",
    "# Определяем сетку параметров, которые нужно проверить\n",
    "param_grid = dict(n_neighbors=k_range)\n",
    "\n",
    "# Инициализируем объект GridSearchCV для перебора параметров с использованием кросс-валидации\n",
    "grid = model_selection.GridSearchCV(knn, param_grid, cv=10, scoring='accuracy')\n",
    "\n",
    "# Обучаем модель на обучающей выборке с использованием GridSearchCV для поиска оптимального значения k\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# Получаем наилучшее значение k\n",
    "best_k = grid.best_params_['n_neighbors']\n",
    "\n",
    "# Создаем новую модель KNN с оптимальным значением k\n",
    "knn_best = KNeighborsClassifier(n_neighbors=best_k)\n",
    "\n",
    "# Обучаем модель на обучающей выборке с оптимальным значением k\n",
    "knn_best.fit(X_train, y_train)\n",
    "\n",
    "# Делаем предсказания на тестовой выборке\n",
    "y_pred = knn_best.predict(X_test)\n",
    "\n",
    "# Оцениваем точность предсказаний на тестовой выборке\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Оптимальное значение k:\", best_k)\n",
    "print(\"Точность предсказаний на тестовой выборке:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35524b14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
