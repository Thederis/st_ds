{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2/6  2. Градиентный спуск"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Цель занятия** — изучить понятия функции потерь, функционала ошибки и градиента, а также ознакомиться с алгоритмом градиентного спуска."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы уже познакомились с методом ближайших соседей. Это очень простой метод, обучение в котором сводится к запоминанию обучающей выборки. На этом занятии мы приступим к изучению дифференцируемых моделей линейной регрессии, которые обучаются с помощью градиентного спуска. Давайте разберемся, что это такое.  \n",
    "\n",
    "**Градиентный спуск** — это метод, который помогает модели машинного обучения находить оптимальные значения параметров. Он делает это путем постепенного изменения параметров таким образом, чтобы функция потерь (разница между предсказанными значениями и реальными значениями целевой переменной) становилась все меньше и меньше."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Градиентный спуск позволяет найти оптимальные значения параметров модели, минимизируя функцию потерь. Благодаря этому методу можно обучать различные модели машинного обучения: линейные модели, нейронные сети и другие."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>ФУНКЦИИ ПОТЕРЬ И ФУНКЦИОНАЛЫ ОШИБКИ В РЕГРЕССИИ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Начнем знакомство с градиентным спуском с таких понятий, как функции потерь и функционалы ошибок в задачах регрессии.\n",
    "\n",
    "**Функция потерь (loss function)** в задачах регрессии используется для оценки того, насколько хорошо модель предсказывает целевую переменную. Функция потерь выражает разницу между предсказанными значениями и реальными значениями целевой переменной на конкретном обучающем примере."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В задачах регрессии наиболее популярные функции потерь — это квадратичная ошибка, абсолютная ошибка и функция потерь Хьюбера."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure class=\"img\"><img src=\"//lms-cdn.skillfactory.ru/assets/courseware/v1/9b08092676ef6a5ddcb13c1f1e6518a2/asset-v1:SkillFactory+MFTIDSLIGHT+2022_DEC+type@asset+block/mftidslight_algo_m3_01.png\" alt=\"\" width=\"850px\">\n",
    "<div class=\"megaflex\" style=\"align-items: flex-start; justify-content: center;\">\n",
    "<p><em>Квадратичная функция потерь</em></p>\n",
    "<p><em>Абсолютная функция потерь</em></p>\n",
    "<p><em> Функция потерь Хьюбера</em></p>\n",
    "</div>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функции потерь используются при обучении моделей для определения оптимальных значений параметров модели, которые минимизируют потери. Для определения минимума функции удобно использовать производную функции."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure class=\"img\"><img src=\"//lms-cdn.skillfactory.ru/assets/courseware/v1/c3bdb389cac19ffb83d1e8b4dffbb09f/asset-v1:SkillFactory+MFTIDSLIGHT+2022_DEC+type@asset+block/mftidslight_algo_m3_02.png\" alt=\"\" width=\"850px\"></figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы стартуем из произвольной точки, вычисляем в ней производную и движемся в сторону, обратную значению производной, со скоростью, указанной в параметре *learning rate*. Траектория движения указана красными линиями."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Например, для направленной вверх параболы (квадратичная функция), которая является гладкой функцией с одним глобальным минимумом, производная указывает направление роста функции. Соответственно, двигаясь в обратном направлении, можно достичь глобального минимума. Это справедливо и для абсолютной функции потерь. Однако стоит заметить, что в абсолютной функции потерь производная не определена в нуле. Один из способов решения этой проблемы — использование функции потерь Хьюбера."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте введем еще одно понятие — функционал ошибки.  \n",
    "\n",
    "**Функционал ошибки (cost function)** — это математическая функция, которая измеряет среднюю ошибку модели на всем наборе данных. Функционал ошибки представляет собой сумму функции потерь на всех примерах обучающих данных, нормализованную на количество примеров в наборе данных. Функционал ошибки показывает, как хорошо модель работает на всех данных в целом, и служит основной метрикой для оценки качества модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Основное отличие между функцией потерь и функционалом ошибки заключается в том, что функция потерь измеряет ошибку на каждом примере данных, в то время как функционал ошибки измеряет среднюю ошибку на всем наборе данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В задачах регрессии наиболее популярные функционалы потерь — это среднеквадратичная ошибка (*MSE*), средняя абсолютная ошибка (*MAE*) и функционал ошибки *Хьюбера*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>ГРАДИЕНТ ФУНКЦИИ ПОТЕРЬ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для минимизации функции потерь, включающей в себя более чем один параметр, в машинном обучении используется **градиент** — вектор частных производных, который указывает направление наискорейшего возрастания функции потерь относительно параметров модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Градиент функции потерь используется для обновления параметров модели во время обучения с помощью метода градиентного спуска. Градиент функции потерь $L \\left(x \\cdot w, \\hat{y}\\right)$ обозначается с помощью символа «набла»: $\\nabla L \\left(x \\cdot w, \\hat{y}\\right)$.\n",
    "\n",
    "Градиент в машинном обучении может быть вычислен с помощью алгоритмов дифференцирования, таких как автоматическое дифференцирование или символьное дифференцирование."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Важно отметить, что в некоторых случаях функция потерь может быть не дифференцируемой или иметь разрывы. Это усложняет вычисление градиента и требует использования альтернативных методов оптимизации.\n",
    "\n",
    "Например, в регрессии абсолютная функция потерь недифференцируема в нуле. Для решения этой проблемы используют функцию потерь Хьюбера, где для малых значений функция потерь вычисляется через квадратичную ошибку, а для значений, больших $\\delta$, — через абсолютную ошибку.\n",
    "\n",
    "В функции потерь Хьюбера существует гиперпараметр , отвечающий за переход от подсчета квадратичной ошибки к абсолютной. Часто в литературе встречается значение . Но это значение не является универсальным, и его следует выбирать, исходя из характеристик данных и требуемой чувствительности к выбросам."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Градиент** — это вектор, показывающий направление наискорейшего возрастания функции в заданной точке. В машинном обучении градиент используется для настройки параметров модели с помощью методов оптимизации, таких как градиентный спуск или его модификации."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### СВОЙСТВА ГРАДИЕНТА"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим некоторые из свойств градиента в машинном обучении."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Экстремумы функций.** С помощью градиента можно находить точки экстремума функции (локальные минимумы и максимумы). Экстремум функции — это точка на ее графике, в которой функция достигает наибольшего (максимум) или наименьшего (минимум) значения в данной области определения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нахождение локальных и глобального минимумов функции потерь — основная цель использования градиента в машинном обучении."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure class=\"img\"><img src=\"//lms-cdn.skillfactory.ru/assets/courseware/v1/843ba951cc47237b4cc7027a7dec7a6e/asset-v1:SkillFactory+MFTIDSLIGHT+2022_DEC+type@asset+block/mftidslight_algo_m3_03.png\" alt=\"alt_text\" width=\"500px\">\n",
    "<center><p><em>Экстремумы функции</em></p>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если функция дифференцируема в экстремуме, то градиент в этой точке равен нулю. Соответственно, с помощью градиента можно искать экстремумы функции. Можно делать это аналитически. Однако в случае сложных функций, какими зачастую являются функции потерь в машинном обучении, используются численные методы нахождения минимальных значений функции."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure class=\"img\"><img src=\"//lms-cdn.skillfactory.ru/assets/courseware/v1/88b328c9b56a11838616861d6d474e1a/asset-v1:SkillFactory+MFTIDSLIGHT+2022_DEC+type@asset+block/mftidslight_algo_m3_04.png\" alt=\"alt_text\" title=\"image_tooltip\" width=\"600px\">\n",
    "<center><p><em>Сложные функции потерь</em></p>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Минимум функции.** Направление наискорейшего убывания: градиент показывает направление наибольшего увеличения функции в заданной точке. Это позволяет использовать градиент для настройки параметров модели с целью уменьшения функциональной ошибки. Для этого используется антиградиент — значение градиента с обратным знаком."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<body>\n",
    "<figure class=\"img\"><img src=\"//lms-cdn.skillfactory.ru/assets/courseware/v1/bed38106b93802197a7c57d2d31cd305/asset-v1:SkillFactory+MFTIDSLIGHT+2022_DEC+type@asset+block/mftidslight_algo_m3_05.png\" alt=\"alt_text\" title=\"image_tooltip\" width=\"600px\">\n",
    "<p><center>Использование антиградиента для нахождения минимума функции</center></p>\n",
    "</figure>\n",
    "</body>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для объяснения использования градиента для выявления направления наискорейшего убывания обычно пользуются метафорой горы. Представьте, что вы стоите на вершине горы и хотите спуститься в долину. Вы хотите найти точку с наименьшей высотой долины и двигаться в этом направлении. Вы можете смотреть в любом направлении и определять, куда надо двигаться, чтобы спуститься вниз."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Градиент функции — это инструмент, который позволяет понять, в каком направлении двигаться для достижения минимального значения функции. Если градиент функции большой, это значит, что вы находитесь на крутом склоне горы, и вам нужно двигаться быстрее, чтобы спуститься вниз. Если градиент маленький, это значит, что вы находитесь на пологом участке горы, и двигаться можно медленно."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure class=\"img\"><img src=\"//lms-cdn.skillfactory.ru/assets/courseware/v1/d8043423ec93981e971ff8038e0e6b7e/asset-v1:SkillFactory+MFTIDSLIGHT+2022_DEC+type@asset+block/mftidslight_algo_m3_06.png\" alt=\"alt_text\" title=\"image_tooltip\" width=\"600px\">\n",
    "<p><center>Аналогия градиента и спуска с горы</center></p>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><strong>Другие свойства градиента функции потерь:</strong></p>\n",
    "<ul class=\"list\">\n",
    "<li>Норма градиента связана со скоростью обучения — чем больше градиент, тем быстрее модель обучается. Однако слишком большой градиент может привести к неустойчивости процесса оптимизации и переобучению модели.</li><p></p>\n",
    "<li>Градиент может быть вычислен аналитически. В некоторых случаях градиент функции может быть выражен в явном виде, что упрощает процесс оптимизации. Например, для линейной регрессии градиент можно выразить в явном виде.</li><p></p>\n",
    "<li>Градиент может быть вычислен численно. В случаях, когда аналитический градиент не может быть вычислен, можно использовать численное дифференцирование для приближенного вычисления градиента.</li><p></p>\n",
    "<li>Градиент направлен перпендикулярно линии уровня в определенной точке функции. Линия уровня функции — это множество точек в ее области определения, в которых значение функции остается постоянным, т. е. все точки на линии имеют одинаковое значение функции.<p></p>\n",
    "<figure class=\"img\"><img src=\"//lms-cdn.skillfactory.ru/assets/courseware/v1/fc5843e00ee97a55429f49b88f7489f8/asset-v1:SkillFactory+MFTIDSLIGHT+2022_DEC+type@asset+block/mftidslight_algo_m3_07.png\" alt=\"alt_text\" title=\"image_tooltip\" width=\"600px\">\n",
    "<p><center>Градиент перпендикулярно линии уровня</center></p>\n",
    "</figure>\n",
    "</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ОПРЕДЕЛЕНИЕ ГРАДИЕНТНОГО СПУСКА"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь мы познакомились со всеми понятиями, необходимыми для определения градиентного спуска.\n",
    "\n",
    "**Градиентный спуск** — это метод оптимизации, используемый в машинном обучении для нахождения локального минимума функции потерь модели. Он основан на вычислении градиента функции потерь по параметрам модели и последующем обновлении этих параметров в направлении наиболее быстрого убывания градиента."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Псевдокод алгоритма градиентного спуска описан ниже.\n",
    "\n",
    "Входные параметры. Функция потерь $L \\left(w\\right)$, начальные параметры $w_0$, шаг обучения $\\alpha$, максимальное число итераций $T$, допустимая ошибка $\\epsilon$.\n",
    "Выходные параметры. Оптимальные параметры \n",
    "\n",
    "1: $w \\leftarrow w_0$ // Инициализируем значения весов $w$ с помощью $w_0$  \n",
    "2: $t \\leftarrow 0$ // Инициализируем счетчик итераций $t$  \n",
    "3: $e \\leftarrow \\infty$ // Инициализируем значение функции потерь $\\infty$  \n",
    "4: Запускаем цикл **while**  \n",
    "4: **while** $t<T$ do // Пока совершено менее $T$ шагов  \n",
    "4:     Вычислить функцию потерь $L \\left(w_t\\right)$ и градиент $\\nabla L \\left(w_t\\right)$  \n",
    "4:           Обновить параметры: $w_{t+1} \\leftarrow w_t − \\alpha_t \\nabla L \\left(w_t\\right)$ // $\\alpha_t$ — скорость обучения на текущем шаге  \n",
    "             // Проверить выполнение критерия останова, в данном случае, если норма разности нового и старого векторов весов < $\\epsilon$  \n",
    "4:         if ${||w}_{t+1} \\ -\\ w_t ||<\\ \\epsilon$ then  \n",
    "4:        break  \n",
    "4:       end if  \n",
    "4:    $t \\leftarrow t+1$  \n",
    "4: end while  \n",
    "5: return $w^* =0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Градиентный спуск — один из основных методов оптимизации в машинном обучении. Он может использоваться для настройки параметров любых моделей, которые могут быть обучены с помощью градиентного спуска."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ПАРАМЕТРЫ ГРАДИЕНТНОГО СПУСКА"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим подробнее параметры градиентного спуска.\n",
    "\n",
    "**Скорость обучения (learning rate)** — это гиперпараметр, который определяет размер шага в каждой итерации обновления параметров. Если скорость обучения выбрана слишком большой, то метод может не сойтись, и оптимизация не будет достигнута. Если скорость обучения слишком мала, метод может занять слишком много времени на поиск оптимума.\n",
    "\n",
    "Выбор оптимальной длины шага (шага градиентного спуска) в градиентном спуске — это важный вопрос, который может существенно влиять на скорость и точность сходимости алгоритма."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вот несколько способов выбора длины шага в градиентном спуске:\n",
    "\n",
    "**Адаптивный шаг (*adaptive step*).** Длина шага изменяется по формуле или в зависимости от ситуации на каждой итерации. Например, можно использовать методы AdaGrad, RMSprop или Adam, которые адаптивно изменяют длину шага в зависимости от градиента и предыдущих шагов.\n",
    "Пример базовой формулы для изменения скорости обучения:\n",
    "$$\\alpha_t = \\alpha_0 \\cdot \\frac{1}{1+d \\cdot t},$$\n",
    "где $\\alpha_t$ — скорость обучения в момент времени $t$,  \n",
    "\n",
    "$\\alpha_0$ — начальная скорость обучения,  \n",
    "$d$ — коэффициент затухания скорости обучения,  \n",
    "$t$ — текущая эпоха обучения.\n",
    "\n",
    "**Фиксированный шаг (*constant step*).** Длина шага остается постоянной в течение всего процесса обучения. Этот метод прост в реализации, но может быть неэффективным, так как шаг может быть слишком маленьким или большим, что приведет к медленной сходимости или неустойчивости.\n",
    "\n",
    "**Backtracking line search.** Это метод, который на каждой итерации градиентного спуска ищет оптимальную длину шага, которая удовлетворяет определенным критериям. Например, можно использовать метод Армихо (Armijo), который гарантирует уменьшение функции потерь на каждом шаге. Или метод золотого сечения (golden section), который находит оптимальную длину шага в заданном интервале."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Метод инициализации параметров** — это способ задания начальных значений параметров. Он может влиять на скорость сходимости метода, так как некоторые методы инициализации могут быть более эффективными, чем другие."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Некоторые из наиболее распространенных методов инициализации включают в себя следующее:\n",
    "\n",
    "* Случайная инициализация — начальные значения параметров модели выбираются случайным образом. Это наиболее распространенный метод инициализации.\n",
    "\n",
    "* Инициализация нулями — начальные значения всех параметров устанавливаются в ноль. Этот метод может быть полезным, если модель уже имеет предварительно обученные веса, которые затем можно дообучить на новых данных.\n",
    "\n",
    "* Инициализация на основе распределения — начальные значения параметров выбираются из определенного распределения, такого как нормальное или равномерное. Этот метод может быть полезным для определенных типов моделей и задач.\n",
    "\n",
    "Если начальные значения слишком далеки от оптимальных, то метод может потребовать больше времени на достижение оптимума. Для решения проблемы застревания в неоптимальных локальных минимумах существует техника *мультистарта*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Мультистарт (англ. multistart)** — это метод инициализации весов модели, который заключается в запуске обучения модели несколько раз с разными начальными значениями весов. Использование мультистарта может улучшить качество обучения модели и уменьшить вероятность застревания в локальных оптимумах.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Количество итераций** — это количество шагов обновления параметров, которые нужно выполнить, чтобы достичь оптимума. Это может быть фиксированный параметр или параметр, который зависит от критерия сходимости.\n",
    "\n",
    "**Критерии остановки** градиентного спуска определяют, когда следует остановить итерации алгоритма оптимизации. Это важно для того, чтобы избежать бесконечного цикла и переобучения модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вот некоторые распространенные критерии остановки градиентного спуска:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Достижение определенного количества итераций. Задается максимальное число итераций, после чего алгоритм останавливается. Количество итераций, необходимых для обучения алгоритма машинного обучения, может значительно различаться в зависимости от многих факторов — размер и сложность набора данных, выбранный алгоритм обучения, используемая аппаратная конфигурация, настройки гиперпараметров и т. д.\n",
    "\n",
    "  В целом, обучение алгоритма машинного обучения требует проведения множества итераций, или эпох, где одна эпоха представляет собой один проход по всем обучающим примерам в наборе данных. Часто требуется проводить многократные эпохи для достижения оптимальных результатов обучения.\n",
    "\n",
    "  Например, для некоторых типов нейронных сетей на больших наборах данных, может потребоваться проведение сотен или даже тысяч итераций, прежде чем модель сможет достигнуть высокой точности предсказаний. Однако для более простых моделей или на более маленьких наборах данны, может потребоваться гораздо меньшее количество итераций (до 100) для достижения приемлемых результатов.\n",
    "\n",
    "*  Достижение определенной точности. Определяется, какой порог разницы между значениями функции потерь на текущей и предыдущей итерациях считать достаточным для остановки алгоритма. Если разница меньше порога, то алгоритм прекращает работу.\n",
    "\n",
    "\n",
    "* Норма градиента становится меньше заданного значения. Норма градиента определяет скорость изменения функции потерь в каждой точке пространства параметров модели. Если норма градиента становится меньше заданного значения, то это означает, что модель достигла локального минимума, и алгоритм может быть остановлен.\n",
    "\n",
    "* Сходимость функции потерь. Алгоритм останавливается, когда значения функции потерь перестают существенно меняться на протяжении нескольких итераций.\n",
    "\n",
    "* Проверка изменения параметров модели. Алгоритм может быть остановлен, когда значения параметров модели перестают изменяться существенно на протяжении нескольких итераций.\n",
    "\n",
    "* Превышение максимального времени работы. Можно установить максимальное время работы алгоритма, после истечения которого он будет остановлен. Время можно установить в зависимости от сложности задачи и располагаемых вычислительных ресурсов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выбор критерия остановки градиентного спуска зависит от конкретной задачи и требуемой точности. Хорошая практика — комбинирование нескольких критериев, чтобы получить более надежный результат. Например, одновременное отслеживание нормы градиента, изменения параметров модели, сходимости функции потерь."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### МОДИФИКАЦИИ ГРАДИЕНТНОГО СПУСКА"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Существуют различные модификации алгоритма градиентного спуска, которые позволяют улучшить сходимость и скорость работы. Рассмотрим некоторые из них."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### МОДИФИКАЦИИ С ОБУЧЕНИЕМ НЕ ПО ВСЕЙ ВЫБОРКЕ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Стохастический градиентный спуск (SGD) и мини-батч градиентный спуск (mini-batch GD)** — методы оптимизации для обучения нейронных сетей и других моделей машинного обучения.\n",
    "\n",
    "SGD используется для обновления весов модели после каждого примера обучающего набора, в то время как mini-batch GD используется для обновления весов после каждой небольшой группы примеров, называемой мини-батч."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Преимущества модификаций с обучением не по всей выборке:**\n",
    "\n",
    "Быстрее обучают модели, так как обновления происходят на каждом примере или мини-батче.\n",
    "Работают с большими обучающими наборами данных, которые не могут поместиться в память компьютера для GD.\n",
    "Помогают избежать застревания в локальных оптимумах, поскольку они более случайные, чем обычный градиентный спуск."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Формула модификации стохастического градиентного спуска (SGD)**. Вместо вычисления градиента по всей выборке данных SGD вычисляет градиент только по одному обучающему объекту на каждой итерации. Это позволяет ускорить обучение и уменьшить требования к памяти.\n",
    "\n",
    "Формула SGD представлена в уравнении:\n",
    "$$w_{t+1}=w_t-\\alpha_t \\nabla L\\left(w_t ; y_{i t}, m\\left(x_{i t}\\right)\\right),$$\n",
    "где $w_t$ — вектор параметров модели на шаге $t$,  \n",
    "$\\alpha_t$ — скорость обучения (learning rate), определяющая величину шага в каждой итерации,  \n",
    "$\\nabla L$ — градиент функции потерь $L(w_t ; y_{i t}, m(x_{i t}))$ по параметрам модели $m$,  \n",
    "$x_it$ и $y_it$ — $i$-й обучающий пример из обучающего набора данных, используемый на шаге $t$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Формула модификации мини-пакетного градиентного спуска (mini-batch GD)**. Это комбинация стохастического градиентного спуска и полного градиентного спуска. На каждой итерации алгоритм вычисляет градиент на подвыборке данных фиксированного размера (например, 32 или 64 элемента), что позволяет улучшить скорость обучения и сходимость.\n",
    "\n",
    "Формула *mini-batch GD* представлена в уравнении:  \n",
    "$$w_{t+1}=w_t-\\alpha_t \\frac{1}{\\text { length }(M B)} \\sum_{i \\in M B} \\nabla L\\left(w_t ; y_{i t}, m\\left(x_{i t}\\right)\\right),$$\n",
    "где $w_t$ — вектор параметров модели на шаге $t$,  \n",
    "$\\alpha_t — скорость обучения (learning rate), определяющая величину шага в каждой итерации,  \n",
    "$MB$ — *mini-batch* (мини-пакет) размера $length \\left(MB\\right)$, выбранный случайным образом из обучающего набора данных. Обычно $MB$ выбирается от нескольких десятков до нескольких сотен обучающих примеров, в зависимости от размера обучающего набора данных,  \n",
    "$\\nabla L$ — градиент функции потерь $L(w_t ; y_{i t}, m(x_{i t}))$ по параметрам модели $m$,  \n",
    "$x_it$ и $y_it$ — $i$-й обучающий пример из *mini-batch* набора данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### МОДИФИКАЦИИ С ИНЕРЦИЕЙ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Градиентный спуск с инерцией (Momentum) и Nesterov Accelerated Gradient (NAG)** — расширения стандартного градиентного спуска. Они позволяют учитывать различный масштаб признаков и быстрее продвигаться к оптимуму функции потерь со сложными линиями уровней.\n",
    "Оптимизация с помощью **Momentum** — это метод стохастической оптимизации, который ускоряет процесс обучения за счет накопления «импульса» градиентов векторов.\n",
    "\n",
    "В процессе обучения градиенты вычисляются на каждом шаге для обновления параметров модели. При использовании Momentum, градиенты на каждом шаге умножаются на коэффициент «импульса» (обычно примерно равный 0.9). Он указывает, какую долю предыдущего шага нужно сохранить при вычислении градиентов на следующем шаге.\n",
    "\n",
    "Таким образом, импульс помогает ускорить компоненты градиента в тех направлениях, в которых они сохраняются на протяжении нескольких последовательных шагов, и затормозить в направлениях, в которых градиенты меняются быстро. Это позволяет быстрее и более стабильно сходиться к локальному оптимуму и уменьшить вероятность застревания в локальном минимуме.\n",
    "При использовании метода Momentum также возможно снижение количества осцилляций (взлетов и падений) при движении к минимуму функции потерь.\n",
    "\n",
    "Метод Momentum можно применять совместно с различными алгоритмами оптимизации — SGD (стохастический градиентный спуск), Adam и RMSprop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nesterov Accelerated Gradient (NAG)** — это метод стохастической оптимизации, который является модификацией метода Momentum. В методе Momentum градиенты на каждом шаге умножаются на коэффициент «импульса» и складываются с предыдущим шагом для обновления параметров модели. Однако в этом случае имеется небольшая задержка в обновлении параметров, так как градиенты вычисляются на текущей позиции, а обновление параметров происходит на следующем шаге."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В методе NAG сначала вычисляются градиенты на текущей позиции, затем делается шаг в направлении, заданном градиентами на следующей позиции. И только затем вычисляются импульсы, которые накапливаются и добавляются к шагу."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Преимущества модификаций с инерцией:\n",
    "* Помогают избежать локальных минимумов и ускоряют сходимость.\n",
    "\n",
    "* Позволяют обучать более глубокие и сложные модели с большим количеством параметров.\n",
    "\n",
    "* Устойчивы к застреванию в локальных оптимумах и помогают более быстро достигать глобального минимума функции потерь."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Формула модификации Моментум (Momentum)**. Эта модификация градиентного спуска учитывает предыдущие изменения вектора градиента при обновлении весов модели. Это позволяет ускорить обучение и уменьшить вероятность застревания в локальных минимумах."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$v_{t+1}=\\eta v_t+\\alpha_t \\nabla L\\left(w_t\\right),$$\n",
    "где $v_t$ — momentum, усредненное направление движения на шаге $t$,  \n",
    "$\\eta$ — коэффициент момента, выбирается около 0.9 для большинства задач,  \n",
    "$a_t$ — скорость обучения (*learning rate*), определяющая величину шага в каждой итерации,  \n",
    "$\\nabla L$ — градиент функции потерь $L \\left(w_t\\right)$ по параметрам модели $m$,  \n",
    "$L \\left(w_t\\right)$ — вектор параметров модели на шаге %t%.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Формула градиентного спуска с моментом добавляет вектор скорости $v_t$, который является экспоненциальным сглаживанием градиента на предыдущих шагах. Это помогает ускорить процесс оптимизации и сгладить колебания, особенно на «шумных» данных."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
