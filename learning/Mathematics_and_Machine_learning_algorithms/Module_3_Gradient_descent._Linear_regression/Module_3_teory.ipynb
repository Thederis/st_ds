{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2/6  2. Градиентный спуск"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Цель занятия** — изучить понятия функции потерь, функционала ошибки и градиента, а также ознакомиться с алгоритмом градиентного спуска."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы уже познакомились с методом ближайших соседей. Это очень простой метод, обучение в котором сводится к запоминанию обучающей выборки. На этом занятии мы приступим к изучению дифференцируемых моделей линейной регрессии, которые обучаются с помощью градиентного спуска. Давайте разберемся, что это такое.  \n",
    "\n",
    "**Градиентный спуск** — это метод, который помогает модели машинного обучения находить оптимальные значения параметров. Он делает это путем постепенного изменения параметров таким образом, чтобы функция потерь (разница между предсказанными значениями и реальными значениями целевой переменной) становилась все меньше и меньше."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Градиентный спуск позволяет найти оптимальные значения параметров модели, минимизируя функцию потерь. Благодаря этому методу можно обучать различные модели машинного обучения: линейные модели, нейронные сети и другие."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>ФУНКЦИИ ПОТЕРЬ И ФУНКЦИОНАЛЫ ОШИБКИ В РЕГРЕССИИ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Начнем знакомство с градиентным спуском с таких понятий, как функции потерь и функционалы ошибок в задачах регрессии.\n",
    "\n",
    "**Функция потерь (loss function)** в задачах регрессии используется для оценки того, насколько хорошо модель предсказывает целевую переменную. Функция потерь выражает разницу между предсказанными значениями и реальными значениями целевой переменной на конкретном обучающем примере."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В задачах регрессии наиболее популярные функции потерь — это квадратичная ошибка, абсолютная ошибка и функция потерь Хьюбера."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure class=\"img\"><img src=\"//lms-cdn.skillfactory.ru/assets/courseware/v1/9b08092676ef6a5ddcb13c1f1e6518a2/asset-v1:SkillFactory+MFTIDSLIGHT+2022_DEC+type@asset+block/mftidslight_algo_m3_01.png\" alt=\"\" width=\"850px\">\n",
    "<div class=\"megaflex\" style=\"align-items: flex-start; justify-content: center;\">\n",
    "<p><em>Квадратичная функция потерь</em></p>\n",
    "<p><em>Абсолютная функция потерь</em></p>\n",
    "<p><em> Функция потерь Хьюбера</em></p>\n",
    "</div>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функции потерь используются при обучении моделей для определения оптимальных значений параметров модели, которые минимизируют потери. Для определения минимума функции удобно использовать производную функции."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure class=\"img\"><img src=\"//lms-cdn.skillfactory.ru/assets/courseware/v1/c3bdb389cac19ffb83d1e8b4dffbb09f/asset-v1:SkillFactory+MFTIDSLIGHT+2022_DEC+type@asset+block/mftidslight_algo_m3_02.png\" alt=\"\" width=\"850px\"></figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы стартуем из произвольной точки, вычисляем в ней производную и движемся в сторону, обратную значению производной, со скоростью, указанной в параметре *learning rate*. Траектория движения указана красными линиями."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Например, для направленной вверх параболы (квадратичная функция), которая является гладкой функцией с одним глобальным минимумом, производная указывает направление роста функции. Соответственно, двигаясь в обратном направлении, можно достичь глобального минимума. Это справедливо и для абсолютной функции потерь. Однако стоит заметить, что в абсолютной функции потерь производная не определена в нуле. Один из способов решения этой проблемы — использование функции потерь Хьюбера."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте введем еще одно понятие — функционал ошибки.  \n",
    "\n",
    "**Функционал ошибки (cost function)** — это математическая функция, которая измеряет среднюю ошибку модели на всем наборе данных. Функционал ошибки представляет собой сумму функции потерь на всех примерах обучающих данных, нормализованную на количество примеров в наборе данных. Функционал ошибки показывает, как хорошо модель работает на всех данных в целом, и служит основной метрикой для оценки качества модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Основное отличие между функцией потерь и функционалом ошибки заключается в том, что функция потерь измеряет ошибку на каждом примере данных, в то время как функционал ошибки измеряет среднюю ошибку на всем наборе данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В задачах регрессии наиболее популярные функционалы потерь — это среднеквадратичная ошибка (*MSE*), средняя абсолютная ошибка (*MAE*) и функционал ошибки *Хьюбера*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>ГРАДИЕНТ ФУНКЦИИ ПОТЕРЬ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для минимизации функции потерь, включающей в себя более чем один параметр, в машинном обучении используется **градиент** — вектор частных производных, который указывает направление наискорейшего возрастания функции потерь относительно параметров модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Градиент функции потерь используется для обновления параметров модели во время обучения с помощью метода градиентного спуска. Градиент функции потерь $L \\left(x \\cdot w, \\hat{y}\\right)$ обозначается с помощью символа «набла»: $\\nabla L \\left(x \\cdot w, \\hat{y}\\right)$.\n",
    "\n",
    "Градиент в машинном обучении может быть вычислен с помощью алгоритмов дифференцирования, таких как автоматическое дифференцирование или символьное дифференцирование."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Важно отметить, что в некоторых случаях функция потерь может быть не дифференцируемой или иметь разрывы. Это усложняет вычисление градиента и требует использования альтернативных методов оптимизации.\n",
    "\n",
    "Например, в регрессии абсолютная функция потерь недифференцируема в нуле. Для решения этой проблемы используют функцию потерь Хьюбера, где для малых значений функция потерь вычисляется через квадратичную ошибку, а для значений, больших $\\delta$, — через абсолютную ошибку.\n",
    "\n",
    "В функции потерь Хьюбера существует гиперпараметр , отвечающий за переход от подсчета квадратичной ошибки к абсолютной. Часто в литературе встречается значение . Но это значение не является универсальным, и его следует выбирать, исходя из характеристик данных и требуемой чувствительности к выбросам."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Градиент** — это вектор, показывающий направление наискорейшего возрастания функции в заданной точке. В машинном обучении градиент используется для настройки параметров модели с помощью методов оптимизации, таких как градиентный спуск или его модификации."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### СВОЙСТВА ГРАДИЕНТА"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим некоторые из свойств градиента в машинном обучении."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Экстремумы функций.** С помощью градиента можно находить точки экстремума функции (локальные минимумы и максимумы). Экстремум функции — это точка на ее графике, в которой функция достигает наибольшего (максимум) или наименьшего (минимум) значения в данной области определения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нахождение локальных и глобального минимумов функции потерь — основная цель использования градиента в машинном обучении."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure class=\"img\"><img src=\"//lms-cdn.skillfactory.ru/assets/courseware/v1/843ba951cc47237b4cc7027a7dec7a6e/asset-v1:SkillFactory+MFTIDSLIGHT+2022_DEC+type@asset+block/mftidslight_algo_m3_03.png\" alt=\"alt_text\" width=\"500px\">\n",
    "<center><p><em>Экстремумы функции</em></p>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если функция дифференцируема в экстремуме, то градиент в этой точке равен нулю. Соответственно, с помощью градиента можно искать экстремумы функции. Можно делать это аналитически. Однако в случае сложных функций, какими зачастую являются функции потерь в машинном обучении, используются численные методы нахождения минимальных значений функции."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure class=\"img\"><img src=\"//lms-cdn.skillfactory.ru/assets/courseware/v1/88b328c9b56a11838616861d6d474e1a/asset-v1:SkillFactory+MFTIDSLIGHT+2022_DEC+type@asset+block/mftidslight_algo_m3_04.png\" alt=\"alt_text\" title=\"image_tooltip\" width=\"600px\">\n",
    "<center><p><em>Сложные функции потерь</em></p>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Минимум функции.** Направление наискорейшего убывания: градиент показывает направление наибольшего увеличения функции в заданной точке. Это позволяет использовать градиент для настройки параметров модели с целью уменьшения функциональной ошибки. Для этого используется антиградиент — значение градиента с обратным знаком."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<body>\n",
    "<figure class=\"img\"><img src=\"//lms-cdn.skillfactory.ru/assets/courseware/v1/bed38106b93802197a7c57d2d31cd305/asset-v1:SkillFactory+MFTIDSLIGHT+2022_DEC+type@asset+block/mftidslight_algo_m3_05.png\" alt=\"alt_text\" title=\"image_tooltip\" width=\"600px\">\n",
    "<p><center>Использование антиградиента для нахождения минимума функции</center></p>\n",
    "</figure>\n",
    "</body>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для объяснения использования градиента для выявления направления наискорейшего убывания обычно пользуются метафорой горы. Представьте, что вы стоите на вершине горы и хотите спуститься в долину. Вы хотите найти точку с наименьшей высотой долины и двигаться в этом направлении. Вы можете смотреть в любом направлении и определять, куда надо двигаться, чтобы спуститься вниз."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Градиент функции — это инструмент, который позволяет понять, в каком направлении двигаться для достижения минимального значения функции. Если градиент функции большой, это значит, что вы находитесь на крутом склоне горы, и вам нужно двигаться быстрее, чтобы спуститься вниз. Если градиент маленький, это значит, что вы находитесь на пологом участке горы, и двигаться можно медленно."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure class=\"img\"><img src=\"//lms-cdn.skillfactory.ru/assets/courseware/v1/d8043423ec93981e971ff8038e0e6b7e/asset-v1:SkillFactory+MFTIDSLIGHT+2022_DEC+type@asset+block/mftidslight_algo_m3_06.png\" alt=\"alt_text\" title=\"image_tooltip\" width=\"600px\">\n",
    "<p><center>Аналогия градиента и спуска с горы</center></p>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><strong>Другие свойства градиента функции потерь:</strong></p>\n",
    "<ul class=\"list\">\n",
    "<li>Норма градиента связана со скоростью обучения — чем больше градиент, тем быстрее модель обучается. Однако слишком большой градиент может привести к неустойчивости процесса оптимизации и переобучению модели.</li><p></p>\n",
    "<li>Градиент может быть вычислен аналитически. В некоторых случаях градиент функции может быть выражен в явном виде, что упрощает процесс оптимизации. Например, для линейной регрессии градиент можно выразить в явном виде.</li><p></p>\n",
    "<li>Градиент может быть вычислен численно. В случаях, когда аналитический градиент не может быть вычислен, можно использовать численное дифференцирование для приближенного вычисления градиента.</li><p></p>\n",
    "<li>Градиент направлен перпендикулярно линии уровня в определенной точке функции. Линия уровня функции — это множество точек в ее области определения, в которых значение функции остается постоянным, т. е. все точки на линии имеют одинаковое значение функции.<p></p>\n",
    "<figure class=\"img\"><img src=\"//lms-cdn.skillfactory.ru/assets/courseware/v1/fc5843e00ee97a55429f49b88f7489f8/asset-v1:SkillFactory+MFTIDSLIGHT+2022_DEC+type@asset+block/mftidslight_algo_m3_07.png\" alt=\"alt_text\" title=\"image_tooltip\" width=\"600px\">\n",
    "<p><center>Градиент перпендикулярно линии уровня</center></p>\n",
    "</figure>\n",
    "</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ОПРЕДЕЛЕНИЕ ГРАДИЕНТНОГО СПУСКА"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь мы познакомились со всеми понятиями, необходимыми для определения градиентного спуска.\n",
    "\n",
    "**Градиентный спуск** — это метод оптимизации, используемый в машинном обучении для нахождения локального минимума функции потерь модели. Он основан на вычислении градиента функции потерь по параметрам модели и последующем обновлении этих параметров в направлении наиболее быстрого убывания градиента."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Псевдокод алгоритма градиентного спуска описан ниже.\n",
    "\n",
    "Входные параметры. Функция потерь $L \\left(w\\right)$, начальные параметры $w_0$, шаг обучения $\\alpha$, максимальное число итераций $T$, допустимая ошибка $\\epsilon$.\n",
    "Выходные параметры. Оптимальные параметры \n",
    "\n",
    "1: $w \\leftarrow w_0$ // Инициализируем значения весов $w$ с помощью $w_0$  \n",
    "2: $t \\leftarrow 0$ // Инициализируем счетчик итераций $t$  \n",
    "3: $e \\leftarrow \\infty$ // Инициализируем значение функции потерь $\\infty$  \n",
    "4: Запускаем цикл **while**  \n",
    "4: **while** $t<T$ do // Пока совершено менее $T$ шагов  \n",
    "4:     Вычислить функцию потерь $L \\left(w_t\\right)$ и градиент $\\nabla L \\left(w_t\\right)$  \n",
    "4:           Обновить параметры: $w_{t+1} \\leftarrow w_t − \\alpha_t \\nabla L \\left(w_t\\right)$ // $\\alpha_t$ — скорость обучения на текущем шаге  \n",
    "             // Проверить выполнение критерия останова, в данном случае, если норма разности нового и старого векторов весов < $\\epsilon$  \n",
    "4:         if ${||w}_{t+1} \\ -\\ w_t ||<\\ \\epsilon$ then  \n",
    "4:        break  \n",
    "4:       end if  \n",
    "4:    $t \\leftarrow t+1$  \n",
    "4: end while  \n",
    "5: return $w^* =0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Градиентный спуск — один из основных методов оптимизации в машинном обучении. Он может использоваться для настройки параметров любых моделей, которые могут быть обучены с помощью градиентного спуска."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ПАРАМЕТРЫ ГРАДИЕНТНОГО СПУСКА"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим подробнее параметры градиентного спуска.\n",
    "\n",
    "**Скорость обучения (learning rate)** — это гиперпараметр, который определяет размер шага в каждой итерации обновления параметров. Если скорость обучения выбрана слишком большой, то метод может не сойтись, и оптимизация не будет достигнута. Если скорость обучения слишком мала, метод может занять слишком много времени на поиск оптимума.\n",
    "\n",
    "Выбор оптимальной длины шага (шага градиентного спуска) в градиентном спуске — это важный вопрос, который может существенно влиять на скорость и точность сходимости алгоритма."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вот несколько способов выбора длины шага в градиентном спуске:\n",
    "\n",
    "**Адаптивный шаг (*adaptive step*).** Длина шага изменяется по формуле или в зависимости от ситуации на каждой итерации. Например, можно использовать методы AdaGrad, RMSprop или Adam, которые адаптивно изменяют длину шага в зависимости от градиента и предыдущих шагов.\n",
    "Пример базовой формулы для изменения скорости обучения:\n",
    "$$\\alpha_t = \\alpha_0 \\cdot \\frac{1}{1+d \\cdot t},$$\n",
    "где $\\alpha_t$ — скорость обучения в момент времени $t$,  \n",
    "\n",
    "$\\alpha_0$ — начальная скорость обучения,  \n",
    "$d$ — коэффициент затухания скорости обучения,  \n",
    "$t$ — текущая эпоха обучения.\n",
    "\n",
    "**Фиксированный шаг (*constant step*).** Длина шага остается постоянной в течение всего процесса обучения. Этот метод прост в реализации, но может быть неэффективным, так как шаг может быть слишком маленьким или большим, что приведет к медленной сходимости или неустойчивости.\n",
    "\n",
    "**Backtracking line search.** Это метод, который на каждой итерации градиентного спуска ищет оптимальную длину шага, которая удовлетворяет определенным критериям. Например, можно использовать метод Армихо (Armijo), который гарантирует уменьшение функции потерь на каждом шаге. Или метод золотого сечения (golden section), который находит оптимальную длину шага в заданном интервале."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Метод инициализации параметров** — это способ задания начальных значений параметров. Он может влиять на скорость сходимости метода, так как некоторые методы инициализации могут быть более эффективными, чем другие."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Некоторые из наиболее распространенных методов инициализации включают в себя следующее:\n",
    "\n",
    "* Случайная инициализация — начальные значения параметров модели выбираются случайным образом. Это наиболее распространенный метод инициализации.\n",
    "\n",
    "* Инициализация нулями — начальные значения всех параметров устанавливаются в ноль. Этот метод может быть полезным, если модель уже имеет предварительно обученные веса, которые затем можно дообучить на новых данных.\n",
    "\n",
    "* Инициализация на основе распределения — начальные значения параметров выбираются из определенного распределения, такого как нормальное или равномерное. Этот метод может быть полезным для определенных типов моделей и задач.\n",
    "\n",
    "Если начальные значения слишком далеки от оптимальных, то метод может потребовать больше времени на достижение оптимума. Для решения проблемы застревания в неоптимальных локальных минимумах существует техника *мультистарта*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Мультистарт (англ. multistart)** — это метод инициализации весов модели, который заключается в запуске обучения модели несколько раз с разными начальными значениями весов. Использование мультистарта может улучшить качество обучения модели и уменьшить вероятность застревания в локальных оптимумах.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Количество итераций** — это количество шагов обновления параметров, которые нужно выполнить, чтобы достичь оптимума. Это может быть фиксированный параметр или параметр, который зависит от критерия сходимости.\n",
    "\n",
    "**Критерии остановки** градиентного спуска определяют, когда следует остановить итерации алгоритма оптимизации. Это важно для того, чтобы избежать бесконечного цикла и переобучения модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вот некоторые распространенные критерии остановки градиентного спуска:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Достижение определенного количества итераций. Задается максимальное число итераций, после чего алгоритм останавливается. Количество итераций, необходимых для обучения алгоритма машинного обучения, может значительно различаться в зависимости от многих факторов — размер и сложность набора данных, выбранный алгоритм обучения, используемая аппаратная конфигурация, настройки гиперпараметров и т. д.\n",
    "\n",
    "  В целом, обучение алгоритма машинного обучения требует проведения множества итераций, или эпох, где одна эпоха представляет собой один проход по всем обучающим примерам в наборе данных. Часто требуется проводить многократные эпохи для достижения оптимальных результатов обучения.\n",
    "\n",
    "  Например, для некоторых типов нейронных сетей на больших наборах данных, может потребоваться проведение сотен или даже тысяч итераций, прежде чем модель сможет достигнуть высокой точности предсказаний. Однако для более простых моделей или на более маленьких наборах данны, может потребоваться гораздо меньшее количество итераций (до 100) для достижения приемлемых результатов.\n",
    "\n",
    "*  Достижение определенной точности. Определяется, какой порог разницы между значениями функции потерь на текущей и предыдущей итерациях считать достаточным для остановки алгоритма. Если разница меньше порога, то алгоритм прекращает работу.\n",
    "\n",
    "\n",
    "* Норма градиента становится меньше заданного значения. Норма градиента определяет скорость изменения функции потерь в каждой точке пространства параметров модели. Если норма градиента становится меньше заданного значения, то это означает, что модель достигла локального минимума, и алгоритм может быть остановлен.\n",
    "\n",
    "* Сходимость функции потерь. Алгоритм останавливается, когда значения функции потерь перестают существенно меняться на протяжении нескольких итераций.\n",
    "\n",
    "* Проверка изменения параметров модели. Алгоритм может быть остановлен, когда значения параметров модели перестают изменяться существенно на протяжении нескольких итераций.\n",
    "\n",
    "* Превышение максимального времени работы. Можно установить максимальное время работы алгоритма, после истечения которого он будет остановлен. Время можно установить в зависимости от сложности задачи и располагаемых вычислительных ресурсов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выбор критерия остановки градиентного спуска зависит от конкретной задачи и требуемой точности. Хорошая практика — комбинирование нескольких критериев, чтобы получить более надежный результат. Например, одновременное отслеживание нормы градиента, изменения параметров модели, сходимости функции потерь."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### МОДИФИКАЦИИ ГРАДИЕНТНОГО СПУСКА"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Существуют различные модификации алгоритма градиентного спуска, которые позволяют улучшить сходимость и скорость работы. Рассмотрим некоторые из них."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### МОДИФИКАЦИИ С ОБУЧЕНИЕМ НЕ ПО ВСЕЙ ВЫБОРКЕ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Стохастический градиентный спуск (SGD) и мини-батч градиентный спуск (mini-batch GD)** — методы оптимизации для обучения нейронных сетей и других моделей машинного обучения.\n",
    "\n",
    "SGD используется для обновления весов модели после каждого примера обучающего набора, в то время как mini-batch GD используется для обновления весов после каждой небольшой группы примеров, называемой мини-батч."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Преимущества модификаций с обучением не по всей выборке:**\n",
    "\n",
    "Быстрее обучают модели, так как обновления происходят на каждом примере или мини-батче.\n",
    "Работают с большими обучающими наборами данных, которые не могут поместиться в память компьютера для GD.\n",
    "Помогают избежать застревания в локальных оптимумах, поскольку они более случайные, чем обычный градиентный спуск."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Формула модификации стохастического градиентного спуска (SGD)**. Вместо вычисления градиента по всей выборке данных SGD вычисляет градиент только по одному обучающему объекту на каждой итерации. Это позволяет ускорить обучение и уменьшить требования к памяти.\n",
    "\n",
    "Формула SGD представлена в уравнении:\n",
    "$$w_{t+1}=w_t-\\alpha_t \\nabla L\\left(w_t ; y_{i t}, m\\left(x_{i t}\\right)\\right),$$\n",
    "где $w_t$ — вектор параметров модели на шаге $t$,  \n",
    "$\\alpha_t$ — скорость обучения (learning rate), определяющая величину шага в каждой итерации,  \n",
    "$\\nabla L$ — градиент функции потерь $L(w_t ; y_{i t}, m(x_{i t}))$ по параметрам модели $m$,  \n",
    "$x_it$ и $y_it$ — $i$-й обучающий пример из обучающего набора данных, используемый на шаге $t$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Формула модификации мини-пакетного градиентного спуска (mini-batch GD)**. Это комбинация стохастического градиентного спуска и полного градиентного спуска. На каждой итерации алгоритм вычисляет градиент на подвыборке данных фиксированного размера (например, 32 или 64 элемента), что позволяет улучшить скорость обучения и сходимость.\n",
    "\n",
    "Формула *mini-batch GD* представлена в уравнении:  \n",
    "$$w_{t+1}=w_t-\\alpha_t \\frac{1}{\\text { length }(M B)} \\sum_{i \\in M B} \\nabla L\\left(w_t ; y_{i t}, m\\left(x_{i t}\\right)\\right),$$\n",
    "где $w_t$ — вектор параметров модели на шаге $t$,  \n",
    "$\\alpha_t — скорость обучения (learning rate), определяющая величину шага в каждой итерации,  \n",
    "$MB$ — *mini-batch* (мини-пакет) размера $length \\left(MB\\right)$, выбранный случайным образом из обучающего набора данных. Обычно $MB$ выбирается от нескольких десятков до нескольких сотен обучающих примеров, в зависимости от размера обучающего набора данных,  \n",
    "$\\nabla L$ — градиент функции потерь $L(w_t ; y_{i t}, m(x_{i t}))$ по параметрам модели $m$,  \n",
    "$x_it$ и $y_it$ — $i$-й обучающий пример из *mini-batch* набора данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### МОДИФИКАЦИИ С ИНЕРЦИЕЙ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Градиентный спуск с инерцией (Momentum) и Nesterov Accelerated Gradient (NAG)** — расширения стандартного градиентного спуска. Они позволяют учитывать различный масштаб признаков и быстрее продвигаться к оптимуму функции потерь со сложными линиями уровней.\n",
    "Оптимизация с помощью **Momentum** — это метод стохастической оптимизации, который ускоряет процесс обучения за счет накопления «импульса» градиентов векторов.\n",
    "\n",
    "В процессе обучения градиенты вычисляются на каждом шаге для обновления параметров модели. При использовании Momentum, градиенты на каждом шаге умножаются на коэффициент «импульса» (обычно примерно равный 0.9). Он указывает, какую долю предыдущего шага нужно сохранить при вычислении градиентов на следующем шаге.\n",
    "\n",
    "Таким образом, импульс помогает ускорить компоненты градиента в тех направлениях, в которых они сохраняются на протяжении нескольких последовательных шагов, и затормозить в направлениях, в которых градиенты меняются быстро. Это позволяет быстрее и более стабильно сходиться к локальному оптимуму и уменьшить вероятность застревания в локальном минимуме.\n",
    "При использовании метода Momentum также возможно снижение количества осцилляций (взлетов и падений) при движении к минимуму функции потерь.\n",
    "\n",
    "Метод Momentum можно применять совместно с различными алгоритмами оптимизации — SGD (стохастический градиентный спуск), Adam и RMSprop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nesterov Accelerated Gradient (NAG)** — это метод стохастической оптимизации, который является модификацией метода Momentum. В методе Momentum градиенты на каждом шаге умножаются на коэффициент «импульса» и складываются с предыдущим шагом для обновления параметров модели. Однако в этом случае имеется небольшая задержка в обновлении параметров, так как градиенты вычисляются на текущей позиции, а обновление параметров происходит на следующем шаге."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В методе NAG сначала вычисляются градиенты на текущей позиции, затем делается шаг в направлении, заданном градиентами на следующей позиции. И только затем вычисляются импульсы, которые накапливаются и добавляются к шагу."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Преимущества модификаций с инерцией:\n",
    "* Помогают избежать локальных минимумов и ускоряют сходимость.\n",
    "\n",
    "* Позволяют обучать более глубокие и сложные модели с большим количеством параметров.\n",
    "\n",
    "* Устойчивы к застреванию в локальных оптимумах и помогают более быстро достигать глобального минимума функции потерь."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Формула модификации Моментум (Momentum)**. Эта модификация градиентного спуска учитывает предыдущие изменения вектора градиента при обновлении весов модели. Это позволяет ускорить обучение и уменьшить вероятность застревания в локальных минимумах."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$v_{t+1}=\\eta v_t+\\alpha_t \\nabla L\\left(w_t\\right),$$\n",
    "где $v_t$ — momentum, усредненное направление движения на шаге $t$,  \n",
    "$\\eta$ — коэффициент момента, выбирается около 0.9 для большинства задач,  \n",
    "$a_t$ — скорость обучения (*learning rate*), определяющая величину шага в каждой итерации,  \n",
    "$\\nabla L$ — градиент функции потерь $L \\left(w_t\\right)$ по параметрам модели $m$,  \n",
    "$L \\left(w_t\\right)$ — вектор параметров модели на шаге %t%.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Формула градиентного спуска с моментом добавляет вектор скорости $v_t$, который является экспоненциальным сглаживанием градиента на предыдущих шагах. Это помогает ускорить процесс оптимизации и сгладить колебания, особенно на «шумных» данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Формула модификации Nesterov Accelerated Gradient (NAG).** Это модификация градиентного спуска, которая улучшает сходимость за счет добавления момента движения. В отличие от обычного градиентного спуска, который обновляет веса на основе текущего градиента, Nesterov momentum сначала делает шаг в направлении предыдущего накопленного градиента, а затем корректирует его на основе текущего градиента."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$v_{t+1}=\\eta v_t+\\alpha_t \\nabla L\\left(w_t-\\eta v_t\\right),$$\n",
    "$$w_{t+1} = w_t − v_{t+1},$$\n",
    "где $v_t$ — nesterov momentum, усредненное направление движения на шаге $t$,  \n",
    "$\\eta$ — коэффициент момента, выбирается около 0.9 для большинства задач,  \n",
    "$\\alpha_t$ — скорость обучения (*learning rate*), определяющая величину шага в каждой итерации,  \n",
    "$\\nabla L$ — градиент функции потерь $L \\left(w_t\\right)$ по параметрам модели $m$,  \n",
    "$w_t$ — вектор параметров модели на шаге $t$.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Формула *Nesterov Accelerated Gradient* добавляет корректировку вектора скорости $v_t$ перед вычислением градиента. Это позволяет более точно оценить градиент $cost$ функции и ускоряет процесс оптимизации."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### МОДИФИКАЦИИ С АДАПТИВНОЙ СКОРОСТЬЮ ИЗМЕНЕНИЯ КАЖДОГО ВЕСА"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модификации градиентного спуска с адаптивной скоростью изменения каждого веса, такие как Adagrad и RMSProp, являются расширениями стандартного градиентного спуска. Они позволяют эффективно оптимизировать функции потерь, учитывая различные характеристики градиента.\n",
    "\n",
    "**Adagrad** — это метод стохастической оптимизации, который позволяет автоматически адаптировать скорость обучения для каждого параметра модели в процессе обучения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Основная идея метода *Adagrad* заключается в том, чтобы присваивать больший вес параметрам, для которых наблюдается более редкое обновление, и меньший вес параметрам, для которых наблюдается частое обновление. Для этого на каждом шаге метод *Adagrad* вычисляет диагональную матрицу G, которая хранит сумму квадратов градиентов для каждого параметра на протяжении всего обучения. Затем скорость обучения для каждого параметра на текущем шаге вычисляется путем деления скорости обучения на корень из суммы квадратов градиентов для данного параметра на предыдущих шагах."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Преимущество метода Adagrad заключается в том, что он позволяет более эффективно обновлять параметры модели для различных направлений в пространстве параметров, что позволяет более быстро и точно сходиться к оптимальному решению. Кроме того, Adagrad не требует подбора скорости обучения, что является важным преимуществом в задачах с большим количеством параметров."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Однако метод Adagrad может иметь проблемы со сходимостью в случае, когда сумма квадратов градиентов становится очень большой. Эта проблема может быть решена с помощью методов оптимизации, основанных на *Adagrad*, — *Adadelta* и *RMSprop*.\n",
    "\n",
    "**RMSprop (Root Mean Square Propagation)** — это метод стохастической оптимизации, который использует историю градиентов для адаптации скорости обучения на каждом шаге.\n",
    "В методе RMSprop, вместо хранения суммы квадратов градиентов для каждого параметра, как в Adagrad, используется экспоненциально взвешенное среднее (*exponential moving average*) для хранения истории градиентов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Преимущество** метода RMSprop заключается в том, что он позволяет более эффективно обновлять параметры модели для различных направлений в пространстве параметров, учитывая историю градиентов. Кроме того, RMSprop автоматически адаптирует скорость обучения для каждого параметра, что упрощает настройку гиперпараметров.\n",
    "\n",
    "**Недостатком** метода RMSprop является то, что он не учитывает адаптацию скорости обучения в различных направлениях в пространстве параметров, что может привести к неэффективному движению вдоль осей, где градиенты меньше, чем вдоль осей, где градиенты больше."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"green-container div-margin\">\n",
    "<p><strong>Преимущества градиентного спуска с адаптивной скоростью изменения каждого веса:</strong></p>\n",
    "<ul class=\"list\">\n",
    "<li>Позволяют быстрее и эффективнее оптимизировать функции потерь, учитывая различные характеристики градиента.</li>\n",
    "<li>Могут помочь избежать застревания в локальных оптимумах и быстрее достигать глобального минимума функции потерь.</li>\n",
    "<li>Устойчивы к изменениям в данных и помогают улучшить обобщающую способность модели.</li>\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Формула модификации адаптивного градиентного спуска (Adaptive GD, AdaGrad).** Эта модификация алгоритма позволяет изменять длину шага (*learning rate*) в зависимости от геометрических свойств поверхности функции потерь.\n",
    "\n",
    "Например, метод *Adagrad* позволяет изменять длину шага для каждого параметра модели в зависимости от того, как часто он обновляется."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$G_{j t+1}=G_{j t}+\\nabla L\\left(w_t\\right)_j^2,$$\n",
    "$$w_{j t+1}=w_{j t}-\\frac{\\alpha_t}{\\sqrt{G_{j t}+\\epsilon}} \\nabla L\\left(w_t\\right)_j,$$\n",
    "где $G_{j t}$ — накопленные квадраты $j$ компонента градиента для шага $t$,  \n",
    "$\\nabla L$ — градиент функции потерь $L \\left(w_t\\right)$ по параметрам модели $m$,  \n",
    "$\\alpha_t$ — скорость обучения (*learning rate*), определяющая величину шага в каждой итерации,  \n",
    "$\\epsilon$ — значение, добавляемое для стабилизации вычислений,\n",
    "$w_t$ — вектор параметров модели на шаге $t$.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Формула *Adagrad* предлагает уникальный подход к выбору скорости обучения для каждого параметра, основанный на адаптивном масштабировании скорости обучения в соответствии с суммой квадратов предыдущих градиентов. *Adagrad* эффективен для работы с разреженными данными и шумными градиентами, что делает его популярным в обработке естественного языка и компьютерном зрении."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Формула модификации алгоритма RMSprop (Root Mean Square Propagation).** Эта модификация алгоритма корректирует скорость обучения каждого параметра в сети на основе среднего квадрата градиентов для этого параметра.\n",
    "\n",
    "Интуиция за алгоритмом RMSprop заключается в том, чтобы уделять больше внимания последним градиентам и меньше внимания прошлым градиентам при обновлении параметров модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$G_{j_{\\mathrm{t}+1}}=\\eta G_{j_t}+(1-\\eta) \\nabla L\\left(w_t\\right)_j^2 w_{j_{\\mathrm{t}+1}}=w_{j_t}-\\frac{\\alpha_t}{\\sqrt{G_{j_t}+\\epsilon}} \\nabla L\\left(w_t\\right)_j G_{j_t},$$\n",
    "$$G_{j t+1}=\\eta G_{j t}+(1-\\eta) \\nabla L\\left(w_t\\right)_j^2,$$\n",
    "$$w_{j t+1}=w_{j t}-\\frac{\\alpha_t}{\\sqrt{G_{j t}+\\varepsilon}} \\nabla L\\left(w_t\\right)_j,$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "где $G_{j t}$ — накопленные квадраты  компонента градиента для шага $t$,  \n",
    "$\\eta$ — коэффициент затухания (*damping factor*), выбирается около 0.9 для большинства задач,  \n",
    "$\\nabla L$ — градиент функции потерь $L \\left(w_t\\right)$ по параметрам модели $m$,  \n",
    "$\\alpha_t$ — скорость обучения (*learning rate*), определяющая величину шага в каждой итерации,  \n",
    "$\\epsilon$ — значение, добавляемое для стабилизации вычислений,\n",
    "$w_t$ — вектор параметров модели на шаге $t$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Формула *RMSprop* использует скользящее среднее квадрата градиента, чтобы нормировать скорость обучения для каждого параметра. Это позволяет уменьшить влияние выбросов в градиентах на процесс обучения и улучшить сходимость. Коэффициент затухания позволяет «забывать» более старые значения градиента, чтобы учитывать только более актуальные значения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### МОДИФИКАЦИИ С ИНЕРЦИЕЙ И АДАПТИВНОЙ СКОРОСТЬЮ ИЗМЕНЕНИЯ КАЖДОГО ВЕСА"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Adam (Adaptive Moment Estimation)** — это метод стохастической оптимизации, который комбинирует идеи методов Momentum и *RMSprop*. *Adam* использует экспоненциально взвешенное среднее градиентов, как в *RMSprop*, и добавляет коррекцию смещения, как в методе Momentum. Это позволяет обеспечить более стабильную и сбалансированную оптимизацию."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"megaflex\">\n",
    "<div class=\"pros\">\n",
    "<ul class=\"list\" style=\"margin-top: 0;\">\n",
    "<li><strong>Адаптивная скорость обучения.</strong> Adam автоматически адаптирует скорость обучения для каждого параметра в процессе оптимизации, что позволяет более быстро достигнуть оптимального значения функции потерь.</li>\n",
    "<li><strong>Контроль момента.</strong> Adam использует два экспоненциально сглаженных момента градиента для адаптивного выбора скорости обучения. Это позволяет более эффективно обрабатывать шум в данных и делать более точные оценки градиента.</li>\n",
    "<li><strong>Эффективность.</strong> Adam показывает хорошую производительность на больших наборах данных и быстро сходится к оптимальному значению функции потерь.</li>\n",
    "<li><strong>Использование памяти</strong>. Adam хранит только первые и вторые моменты градиента, что позволяет оптимизировать параметры на больших наборах данных, не требуя больших объемов оперативной памяти.</li>\n",
    "<li><strong>Сходимость.</strong> Adam показывает быструю сходимость на многих задачах, и его параметры могут быть настроены автоматически при помощи алгоритмов оптимизации гиперпараметров.</li>\n",
    "</ul>\n",
    "</div>\n",
    "<div class=\"cons\">Недостатком метода Adam является его сложность, которая может замедлить процесс обучения на больших моделях. Также в некоторых случаях метод Adam может не сходиться к оптимальному решению. Для некоторых задач может быть более эффективным использовать методы оптимизации, основанные на методе Momentum или RMSprop.</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Формула модификации.** Формула *Adam* объединяет идеи из Momentum и RMSprop и использует два скользящих средних — скользящее среднее градиента и скользящее среднее квадрата градиента . Она исправляет начальное смещение в начале оптимизации и адаптивно регулирует скорость обучения для каждого параметра."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$g_t = \\nabla L \\left(w_t\\right),$$\n",
    "$$m_t = \\beta_1 m_{t−1} + \\left(1− \\beta_1\\right) g_t,$$\n",
    "$$v_t = \\beta_2 v_{t−1} + \\left(1− \\beta_2\\right) g_t^2,$$\n",
    "$$\\hat{m}_t=\\frac{m_t}{1-\\beta_1^t},$$\n",
    "$$\\hat{v}_t=\\frac{v_t}{1-\\beta_2^t},$$\n",
    "$$w_{t+1}=w_t-\\frac{\\alpha}{\\sqrt{\\hat{v}_t}+\\epsilon} \\hat{m}_t,$$\n",
    "где $g_t$ — градиент на шаге $t$,  \n",
    "$m_t$ — скользящее среднее градиента на шаге $t$,  \n",
    "$\\beta_1$ и $\\beta_2$ — коэффициенты момента, обычно выбираются около 0.9 и 0.999 соответственно,  \n",
    "$v_t$ — скользящее среднее квадрата градиента на шаге $t$,  \n",
    "$\\hat{m_t}$ и $\\hat{v_t}$ — исправленные значения скользящего среднего градиента и квадрата градиента на шаге , чтобы учитывать начальное смещение в начале оптимизации,  \n",
    "$v_t$ — скользящее среднее квадрата градиента на шаге $t$,  \n",
    "$\\alpha_t$ — скорость обучения (*learning rate*), определяющая величину шага в каждой итерации,  \n",
    "$\\epsilon$ — значение, добавляемое для стабилизации вычислений,\n",
    "$w_t$ — вектор параметров модели на шаге $t$.  \n",
    "\n",
    "*Adam* — один из наиболее эффективных методов градиентного спуска, который часто используется в глубоком обучении."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3/6  3. Регуляризация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
