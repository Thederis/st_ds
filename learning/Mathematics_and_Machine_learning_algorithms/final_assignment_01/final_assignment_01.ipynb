{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Прежде чем проверять задания:\n",
    "- **Перезапустите ядро** (**restart the kernel**) (В меню, выбрать Ядро (Kernel) $\\rightarrow$ Перезапустить (Restart)\n",
    "- Затем **Выполнить все ячейки**  **run all cells** (В меню, выбрать Ячейка (Cell) $\\rightarrow$ Запустить все (Run All).\n",
    "\n",
    "Убедитесь, что заполнены все ячейки с комментарием \"НАЧАЛО ВАШЕГО РЕШЕНИЯ\".\n",
    "\n",
    "После ячеек с заданием следуют ячейки с проверкой с помощью assert.\n",
    "\n",
    "Если в коде есть ошибки, assert выведет уведомление об ошибке.\n",
    "\n",
    "Если в коде нет ошибок, assert отработает без вывода дополнительной информации."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "58fb45ec899162856f087cf7a91fa62c",
     "grade": false,
     "grade_id": "cell-e5e20c11a2df79d4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Цель занятия\n",
    "На этом занятии мы на практике закрепим работу с алгоритмами регрессии и классификации, изученными в рамках курса.\n",
    "В задании необходимо имплементировать 8 моделей регрессии и 7 моделей классификации, а также подобрать к этим моделям оптимальные параметры с помощью GridSearchCV."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "edf8f4ede57b944fdd013df302c42af1",
     "grade": false,
     "grade_id": "cell-c8b0af6ebda6c586",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Scikit-learn (sklearn) и ряд других библиотек предлагают множество алгоритмов регрессии, которые можно использовать для решения задач прогнозирования численных значений. Вот некоторые из наиболее популярных алгоритмов регрессии:\n",
    "\n",
    "1. Линейная регрессия (Linear Regression): `sklearn.linear_model.LinearRegression`\n",
    "   - Простая модель, основанная на линейной комбинации признаков.\n",
    "   - Подходит для задач с линейной зависимостью между признаками и целевой переменной.\n",
    "\n",
    "2. Регрессия LASSO (LASSO Regression): `sklearn.linear_model.Lasso`\n",
    "   - Линейная модель, которая также выполняет регуляризацию L1 (L1 regularization).\n",
    "   - Помогает в выборе наиболее важных признаков и обеспечивает разреженность весов.\n",
    "\n",
    "3. Регрессия Ridge (Ridge Regression): `sklearn.linear_model.Ridge`\n",
    "   - Линейная модель, которая выполняет регуляризацию L2 (L2 regularization).\n",
    "   - Помогает в уменьшении эффекта мультиколлинеарности и контролирует значения весов.\n",
    "\n",
    "4. ElasticNet регрессия (ElasticNet Regression): `sklearn.linear_model.ElasticNet`\n",
    "   - Комбинация регрессии LASSO и регрессии Ridge.\n",
    "   - Обеспечивает баланс между отбором признаков и контролем мультиколлинеарности.\n",
    "\n",
    "5. Регрессия по методу опорных векторов (Support Vector Regression): `sklearn.svm.SVR`\n",
    "   - Расширение метода опорных векторов для задачи регрессии.\n",
    "   - Позволяет работать с нелинейными зависимостями с помощью ядерных функций.\n",
    "\n",
    "6. Решающие деревья (Decision Trees): `sklearn.tree.DecisionTreeRegressor`\n",
    "   - Модель, основанная на деревьях принятия решений.\n",
    "   - Позволяет обрабатывать нелинейные зависимости и автоматически выбирать наиболее важные признаки.\n",
    "\n",
    "7. Случайный лес (Random Forest): `sklearn.ensemble.RandomForestRegressor`\n",
    "   - Ансамблевая модель, состоящая из множества решающих деревьев.\n",
    "   - Объединяет прогнозы множества деревьев для улучшения обобщающей способности.\n",
    "\n",
    "8. Градиентный бустинг (Gradient Boosting): `sklearn.ensemble.GradientBoostingRegressor`\n",
    "   - Ансамблевая модель, которая строит ансамбль слабых моделей в итеративном режиме.\n",
    "   - Каждая новая модель исправляет ошибки предыдущих моделей, улучшая предсказания.\n",
    "\n",
    "9. AdaBoost (Adaptive Boosting): `sklearn.ensemble.AdaBoostRegressor`\n",
    "   - Алгоритм адаптивного бустинга, который взвешивает обучающие примеры для создания модели.\n",
    "   - Фокусируется на примерах с большими ошибками для их исправления.\n",
    "\n",
    "10. XGBoost: `xgboost.XGBRegressor`\n",
    "    - Библиотека с открытым исходным кодом, предоставляющая градиентный бустинг.\n",
    "    - Позволяет эффективно обрабатывать большие наборы данных и достигать высокой точности.\n",
    "\n",
    "11. LightGBM: `lightgbm.LGBMRegressor`\n",
    "    - Библиотека с открытым исходным кодом, предоставляющая градиентный бустинг.\n",
    "    - Ориентирована на эффективность и скорость работы с большими объемами данных.\n",
    "\n",
    "12. CatBoost: `catboost.CatBoostRegressor`\n",
    "    - Библиотека с открытым исходным кодом, предоставляющая градиентный бустинг.\n",
    "    - Обладает встроенной поддержкой категориальных признаков и автоматическим кодированием.\n",
    "    \n",
    "Некоторые из наиболее популярных алгоритмов классификации:\n",
    "\n",
    "1. K-ближайших соседей (K-Nearest Neighbors): `sklearn.neighbors.KNeighborsClassifier`\n",
    "   - Алгоритм, который классифицирует объекты на основе ближайших соседей в пространстве признаков.\n",
    "   - Основывается на значении классов соседей для принятия решения о классификации.\n",
    "\n",
    "2. Логистическая регрессия (Logistic Regression): `sklearn.linear_model.LogisticRegression`\n",
    "   - Классификационная модель, которая использует логистическую функцию для предсказания вероятности принадлежности к классам.\n",
    "   - Часто используется в задачах бинарной классификации.\n",
    "   \n",
    "3. Наивный Байес (Naive Bayes): `sklearn.naive_bayes.GaussianNB` (для непрерывных признаков) или `sklearn.naive_bayes.MultinomialNB` (для дискретных признаков)\n",
    "   - Вероятностный классификатор, основанный на применении теоремы Байеса с предположением о независимости признаков.\n",
    "   - Хорошо работает с наборами данных с большим числом признаков и предположением о независимости признаков.\n",
    "\n",
    "4. Метод опорных векторов (Support Vector Machines): `sklearn.svm.SVC`\n",
    "   - Алгоритм, который строит гиперплоскость или набор гиперплоскостей в многомерном пространстве для классификации объектов.\n",
    "   - Может обрабатывать нелинейные зависимости с помощью ядерных функций.\n",
    "\n",
    "5. Решающие деревья (Decision Trees): `sklearn.tree.DecisionTreeClassifier`\n",
    "   - Модель, основанная на деревьях принятия решений.\n",
    "   - Позволяет обрабатывать нелинейные зависимости и автоматически выбирать наиболее важные признаки.\n",
    "\n",
    "6. Случайный лес (Random Forest): `sklearn.ensemble.RandomForestClassifier`\n",
    "   - Ансамблевая модель, состоящая из множества решающих деревьев.\n",
    "   - Объединяет прогнозы множества деревьев для улучшения обобщающей способности.\n",
    "\n",
    "7. Градиентный бустинг (Gradient Boosting): `sklearn.ensemble.GradientBoostingClassifier`\n",
    "   - Ансамблевая модель, которая строит ансамбль слабых моделей в итеративном режиме.\n",
    "   - Каждая новая модель исправляет ошибки предыдущих моделей, улучшая предсказания.\n",
    "\n",
    "8. AdaBoost (Adaptive Boosting): `sklearn.ensemble.AdaBoostClassifier`\n",
    "   - Алгоритм адаптивного бустинга, который взвешивает обучающие примеры для создания модели.\n",
    "   - Фокусируется на примерах с большими ошибками для их исправления.\n",
    "\n",
    "9. XGBoost: `xgboost.XGBClassifier`\n",
    "   - Библиотека с открытым исходным кодом, предоставляющая градиентный бустинг для классификации.\n",
    "   - Позволяет эффективно обрабатывать большие наборы данных и достигать высокой точности.\n",
    "\n",
    "10. LightGBM: `lightgbm.LGBMClassifier`\n",
    "    - Библиотека с открытым исходным кодом, предоставляющая градиентный бустинг для классификации.\n",
    "    - Ориентирована на эффективность и скорость работы с большими объемами данных.\n",
    "\n",
    "11. CatBoost: `catboost.CatBoostClassifier`\n",
    "    - Библиотека с открытым исходным кодом, предоставляющая градиентный бустинг для классификации.\n",
    "    - Обладает встроенной поддержкой категориальных признаков и автоматическим кодированием.\n",
    "\n",
    "Это некоторые из алгоритмов, доступных в scikit-learn и других библиотеках. Каждый алгоритм имеет свои особенности и подходит для разных типов данных и задач. Вам следует экспериментировать с разными алгоритмами и настраивать их параметры для достижения наилучших результатов в конкретной задаче."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ff920cf63e8176b38ff914db609e6417",
     "grade": false,
     "grade_id": "cell-6c7280d3091524bf",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "При решении данного задания потребуются следующие библиотеки:\n",
    "- pandas\n",
    "- numpy\n",
    "- sklearn\n",
    "- xgboost\n",
    "- catboost\n",
    "\n",
    "Установить их можно следующим образом:\n",
    "- pip install pandas==2.0.0\n",
    "- pip install numpy==1.24.0\n",
    "- pip install scikit-learn==1.2.0\n",
    "- pip install xgboost==1.7.5\n",
    "- pip install catboost==1.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f29e49eea386276e04ce9f2f418609d6",
     "grade": false,
     "grade_id": "cell-658289d13c79100f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Задача регрессии"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ef6eda1d9ec797900ddccc8c1d5cdb8c",
     "grade": false,
     "grade_id": "cell-16986542c6b77bcc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Датасет \"Boston\" является одним из классических наборов данных. Он представляет собой набор данных, связанных с ценами на жилье в Бостоне, Массачусетс, США. Этот набор данных широко используется в задачах регрессии и демонстрирует взаимосвязь между различными факторами и стоимостью жилья.\n",
    "\n",
    "Описание признаков (признаки ниже представлены в формате \"название признака (тип данных)\"):\n",
    "1. CRIM (float): уровень преступности на душу населения по городам.\n",
    "2. ZN (float): доля жилой земли, зонированной для участков более 25 000 кв.фут.\n",
    "3. INDUS (float): доля нерозничных площадей на город.\n",
    "4. CHAS (integer): Данный признак является фиктивной переменной, представляющей наличие или отсутствие ограничения участка жилья рекой Charles River.\n",
    "5. NOX (float): концентрация оксидов азота (частей на 10 миллионов).\n",
    "6. RM (float): среднее количество комнат в жилом помещении.\n",
    "7. AGE (float): доля занятых владельцами единиц, построенных до 1940 года.\n",
    "8. DIS (float): взвешенные расстояния до пяти бостонских центров занятости.\n",
    "9. RAD (integer): индекс доступности к радиальным магистралям.\n",
    "10. TAX (integer): полная ставка налога на имущество на 10 000 долларов США.\n",
    "11. PTRATIO (float): соотношение учеников и учителей по городам.\n",
    "12. B (float): 1000 * (Bk - 0.63) ^ 2, где Bk - доля чернокожего населения по городам.\n",
    "13. LSTAT (float): процент более низкого статуса населения.\n",
    "14. MEDV (float): медианная стоимость домов, занимаемых владельцами, в тысячах долларов.\n",
    "\n",
    "Целевая переменная (выходной признак):\n",
    "- MEDV: медианная стоимость домов, занимаемых владельцами, в тысячах долларов.\n",
    "\n",
    "Цель состоит в том, чтобы предсказать медианную стоимость жилья на основе доступных признаков. Этот набор данных часто используется для задачи регрессии и оценки моделей машинного обучения на основе различных признаков, связанных с жильем."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1236351f9da72c1753aec10cce8b61b3",
     "grade": false,
     "grade_id": "cell-41e0ea15e041076e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Мы будем использовать 8 моделей регрессии и GridSearchCV для подбора параметров:\n",
    "1. Линейная регрессия (Linear Regression): `sklearn.linear_model.LinearRegression`\n",
    "2. Регрессия по методу опорных векторов (Support Vector Regression): `sklearn.svm.SVR`\n",
    "3. Решающие деревья (Decision Trees): `sklearn.tree.DecisionTreeRegressor`\n",
    "4. Случайный лес (Random Forest): `sklearn.ensemble.RandomForestRegressor`\n",
    "5. Градиентный бустинг (Gradient Boosting): `sklearn.ensemble.GradientBoostingRegressor`\n",
    "6. AdaBoost (Adaptive Boosting): `sklearn.ensemble.AdaBoostRegressor`\n",
    "7. XGBoost: `xgboost.XGBRegressor`\n",
    "8. CatBoost: `catboost.CatBoostRegressor`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ab27e87b1fc86406aa40d2b1f437e462",
     "grade": false,
     "grade_id": "cell-8165953e47c32a9a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import xgboost as xgb\n",
    "import catboost as cb\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e2f530b54908bb866ba512b78d8997e9",
     "grade": false,
     "grade_id": "cell-db515d3b90a6f1e1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS     NX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296.0   \n",
       "1  0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242.0   \n",
       "2  0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242.0   \n",
       "3  0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222.0   \n",
       "4  0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  MEDV  \n",
       "0     15.3  396.90   4.98  24.0  \n",
       "1     17.8  396.90   9.14  21.6  \n",
       "2     17.8  392.83   4.03  34.7  \n",
       "3     18.7  394.63   2.94  33.4  \n",
       "4     18.7  396.90   5.33  36.2  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Загрузка данных из CSV файла\n",
    "data = pd.read_csv(\"boston.csv\", delimiter=\",\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cb4b2370c6a6120140636e7f7a27c1c4",
     "grade": false,
     "grade_id": "cell-ac74ce74f2e1410e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Разделение на признаки (X) и целевую переменную (y)\n",
    "X = data.drop('MEDV', axis=1)\n",
    "y = data['MEDV']\n",
    "\n",
    "\n",
    "# Разделение на обучающий и тестовый наборы данных\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Определение препроцессора для категориальных и числовых признаков\n",
    "categorical_features = ['RAD']\n",
    "categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "numerical_features = X_train.select_dtypes(include=['int64', 'float64']).columns\n",
    "numerical_transformer = StandardScaler()\n",
    "\n",
    "# Объединение препроцессоров\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', categorical_transformer, categorical_features),\n",
    "        ('num', numerical_transformer, numerical_features)\n",
    "    ])\n",
    "\n",
    "# Создание пайплайна для препроцессора\n",
    "preprocessing_pipeline = Pipeline(steps=[('preprocessor', preprocessor)])\n",
    "\n",
    "# Применение препроцессора к данным\n",
    "X_train = preprocessing_pipeline.fit_transform(X_train)\n",
    "X_test = preprocessing_pipeline.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8e09209458c8b7dd44d1e63f383e4031",
     "grade": false,
     "grade_id": "cell-a3a0470231ab2bc8",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression_best_params:  {'fit_intercept': True}\n",
      "LinearRegression_mse:  24.8249756005231\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\"\"\"\n",
    "Задание 1.1 (1 балл)\n",
    "Сохраните в переменную model экземпляр класса LinearRegression без параметров.\n",
    "Пример:\n",
    "var = ClassExample()\n",
    "\"\"\"\n",
    "# НАЧАЛО ВАШЕГО РЕШЕНИЯ\n",
    "\n",
    "model = LinearRegression()\n",
    "\n",
    "# raise NotImplementedError()\n",
    "# КОНЕЦ ВАШЕГО РЕШЕНИЯ\n",
    "\n",
    "# Определение параметров для GridSearchCV\n",
    "\"\"\"\n",
    "'fit_intercept' определяет, должен ли модель оценивать коэффициент смещения (пересечения) или нет. \n",
    "Если fit_intercept=True, модель будет оценивать коэффициент смещения, то есть точку, где линейная \n",
    "функция пересекает ось зависимой переменной (y-ось). Если fit_intercept=False, модель будет проходить \n",
    "через начало координат (0, 0), и коэффициент смещения будет равен нулю.\n",
    "\"\"\"\n",
    "params = {'fit_intercept': [True, False]}\n",
    "\n",
    "# Создание объекта GridSearchCV\n",
    "\"\"\"\n",
    "Задание 1.2 (1 балл)\n",
    "Сохраните в переменную grid_search экземпляр класса GridSearchCV со следующими параметрами:\n",
    "estimator=model\n",
    "param_grid=params\n",
    "scoring='neg_mean_squared_error'\n",
    "Пример:\n",
    "var = GridSearchCV(par1=value1, par2=value2, par3=value3)\n",
    "\"\"\"\n",
    "# НАЧАЛО ВАШЕГО РЕШЕНИЯ\n",
    "\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=params, scoring='neg_mean_squared_error')\n",
    "\n",
    "# raise NotImplementedError()\n",
    "# КОНЕЦ ВАШЕГО РЕШЕНИЯ\n",
    "\n",
    "\n",
    "# Обучение модели на обучающих данных\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Получение лучшей модели\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Предсказание на тестовых данных\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Получение лучших параметров LinearRegression\n",
    "LinearRegression_best_params = grid_search.best_params_\n",
    "print(\"LinearRegression_best_params: \", LinearRegression_best_params)\n",
    "\n",
    "# Вычисление MSE\n",
    "LinearRegression_mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"LinearRegression_mse: \", LinearRegression_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "64ab46dbfd3f3e982c1ce61e5954dbb2",
     "grade": true,
     "grade_id": "cell-3b4da2f7c279a8d3",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert type(model) == LinearRegression\n",
    "assert type(grid_search) == GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3e1377e01e31d91c48b4f7d92308b83f",
     "grade": false,
     "grade_id": "cell-ee967bd36c165b8b",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVR_best_params:  {'C': 10, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "SVR_mse:  13.497844888204211\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "\"\"\"\n",
    "Задание 1.3 (1 балл)\n",
    "Сохраните в переменную model экземпляр класса SVR без параметров.\n",
    "Пример:\n",
    "var = ClassExample()\n",
    "\"\"\"\n",
    "# НАЧАЛО ВАШЕГО РЕШЕНИЯ\n",
    "\n",
    "model = SVR()\n",
    "\n",
    "# raise NotImplementedError()\n",
    "# КОНЕЦ ВАШЕГО РЕШЕНИЯ\n",
    "\n",
    "# Определение параметров для GridSearchCV\n",
    "\"\"\"\n",
    "Описание параметров:\n",
    "\n",
    "1. `'C'` - параметр регуляризации (также известный как параметр сложности), \n",
    "    контролирует штраф за ошибки модели. Он определяет, насколько модель будет учитывать ошибки в данных \n",
    "    при подгонке к обучающим примерам. Значения `[0.1, 1, 10]` представляют различные величины штрафа. \n",
    "    Более высокое значение C соответствует меньшему штрафу, что позволяет модели более гибко подгоняться к \n",
    "    данным и учитывать даже сложные шаблоны. Низкое значение C, напротив, приводит к более сильному штрафу \n",
    "    и более простой модели.\n",
    "\n",
    "2. `'kernel'` - параметр, определяющий тип ядра, используемого в модели. Ядро определяет способ преобразования \n",
    "    пространства признаков, что позволяет модели обрабатывать нелинейные зависимости между признаками и целевой \n",
    "    переменной. Значения `['linear', 'rbf', 'poly']` определяют различные типы ядер:\n",
    "   - `'linear'` - линейное ядро, применяет линейное преобразование и подходит для линейно разделимых данных.\n",
    "   - `'rbf'` (радиально-базисное функциональное ядро) - нелинейное ядро, которое преобразует данные в более \n",
    "   высокие размерности, используя радиально-базисную функцию. Оно хорошо подходит для обработки нелинейных \n",
    "   зависимостей и может быть эффективным в случаях, когда данные не являются линейно разделимыми.\n",
    "   - `'poly'` (полиномиальное ядро) - преобразует данные в пространство более высокой размерности с \n",
    "   использованием полиномиальной функции. Полиномиальное ядро может обрабатывать нелинейные зависимости, \n",
    "   особенно в случаях, когда данные имеют несколько признаков.\n",
    "\n",
    "3. `'gamma'` - параметр ядра, контролирующий влияние каждого обучающего примера на формирование границы решения. \n",
    "    Значения `['scale', 'auto']` определяют различные стратегии для выбора значения гаммы:\n",
    "   - `'scale'` - значение гаммы рассчитывается как обратное среднее значение расстояний между обучающими \n",
    "       примерами.\n",
    "   - `'auto'` - значение гаммы рассчитывается как обратное численное значение признаков.\n",
    "\"\"\"\n",
    "params = {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf', 'poly'], 'gamma': ['scale', 'auto']}\n",
    "\n",
    "# Создание объекта GridSearchCV\n",
    "\"\"\"\n",
    "Задание 1.4 (1 балл)\n",
    "Сохраните в переменную grid_search экземпляр класса GridSearchCV со следующими параметрами:\n",
    "estimator=model\n",
    "param_grid=params\n",
    "scoring='neg_mean_squared_error'\n",
    "Пример:\n",
    "var = GridSearchCV(par1=value1, par2=value2, par3=value3)\n",
    "\"\"\"\n",
    "# НАЧАЛО ВАШЕГО РЕШЕНИЯ\n",
    "\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=params, scoring='neg_mean_squared_error')\n",
    "\n",
    "# raise NotImplementedError()\n",
    "# КОНЕЦ ВАШЕГО РЕШЕНИЯ\n",
    "\n",
    "# Обучение модели на обучающих данных\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Получение лучшей модели\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Предсказание на тестовых данных\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Получение лучших параметров LinearRegression\n",
    "SVR_best_params = grid_search.best_params_\n",
    "print(\"SVR_best_params: \", SVR_best_params)\n",
    "\n",
    "# Вычисление MSE\n",
    "SVR_mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"SVR_mse: \", SVR_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "60e4efb639a238607d8e79217717285c",
     "grade": true,
     "grade_id": "cell-d8eabe616f47c022",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert type(model) == SVR\n",
    "assert type(grid_search) == GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f0783ccf7315df9d7131b44681067acb",
     "grade": false,
     "grade_id": "cell-e56216bd2ec299b5",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeRegressor_best_params:  {'max_depth': 5}\n",
      "DecisionTreeRegressor_mse:  8.423318349352725\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "\"\"\"\n",
    "Задание 1.5 (1 балл)\n",
    "Сохраните в переменную model экземпляр класса DecisionTreeRegressor без параметров.\n",
    "Пример:\n",
    "var = ClassExample()\n",
    "\"\"\"\n",
    "# НАЧАЛО ВАШЕГО РЕШЕНИЯ\n",
    "\n",
    "model = DecisionTreeRegressor()\n",
    "\n",
    "# raise NotImplementedError()\n",
    "# КОНЕЦ ВАШЕГО РЕШЕНИЯ\n",
    "\n",
    "# Определение параметров для GridSearchCV\n",
    "\"\"\"\n",
    "'max_depth' определяет максимальную глубину дерева решений. \n",
    "Более высокое значение max_depth позволяет модели создавать более сложные правила, \n",
    "что может привести к переобучению. Значения [None, 5, 10] представляют \n",
    "различные значения максимальной глубины дерева.\n",
    "\"\"\"\n",
    "params = {'max_depth': [None, 5, 10]}\n",
    "\n",
    "# Создание объекта GridSearchCV\n",
    "\"\"\"\n",
    "Задание 1.6 (1 балл)\n",
    "Сохраните в переменную grid_search экземпляр класса GridSearchCV со следующими параметрами:\n",
    "estimator=model\n",
    "param_grid=params\n",
    "scoring='neg_mean_squared_error'\n",
    "Пример:\n",
    "var = GridSearchCV(par1=value1, par2=value2, par3=value3)\n",
    "\"\"\"\n",
    "# НАЧАЛО ВАШЕГО РЕШЕНИЯ\n",
    "\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=params, scoring='neg_mean_squared_error')\n",
    "\n",
    "# raise NotImplementedError()\n",
    "# КОНЕЦ ВАШЕГО РЕШЕНИЯ\n",
    "\n",
    "# Обучение модели на обучающих данных\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Получение лучшей модели\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Предсказание на тестовых данных\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Получение лучших параметров LinearRegression\n",
    "DecisionTreeRegressor_best_params = grid_search.best_params_\n",
    "print(\"DecisionTreeRegressor_best_params: \", DecisionTreeRegressor_best_params)\n",
    "\n",
    "# Вычисление MSE\n",
    "DecisionTreeRegressor_mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"DecisionTreeRegressor_mse: \", DecisionTreeRegressor_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d7816e5a98fce775be33cd02389fe5d5",
     "grade": true,
     "grade_id": "cell-e76219089ca29b9f",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert type(model) == DecisionTreeRegressor\n",
    "assert type(grid_search) == GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f28e4e40be51207a509254ccf20ebf2e",
     "grade": false,
     "grade_id": "cell-2de3053b178599de",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestRegressor_best_params:  {'max_depth': 10, 'min_samples_split': 2, 'n_estimators': 300}\n",
      "RandomForestRegressor_mse:  8.476705558125364\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Создание объекта RandomForestRegressor\n",
    "\"\"\"\n",
    "Задание 1.7 (1 балл)\n",
    "Сохраните в переменную model экземпляр класса RandomForestRegressor без параметров.\n",
    "Пример:\n",
    "var = ClassExample()\n",
    "\"\"\"\n",
    "# НАЧАЛО ВАШЕГО РЕШЕНИЯ\n",
    "\n",
    "model = RandomForestRegressor()\n",
    "\n",
    "# raise NotImplementedError()\n",
    "# КОНЕЦ ВАШЕГО РЕШЕНИЯ\n",
    "\n",
    "# Определение параметров для GridSearchCV\n",
    "\"\"\"\n",
    "- `n_estimators`: Это количество деревьев в случайном лесу. Определяет, сколько деревьев будет \n",
    "использоваться для построения ансамбля. Значение по умолчанию - 100. Увеличение значения может \n",
    "улучшить производительность модели, но с увеличением числа деревьев возрастает время обучения и \n",
    "предсказания. Обычно выбирают значения в диапазоне от 100 до 1000.\n",
    "\n",
    "- `max_depth`: Максимальная глубина каждого дерева в лесу. Ограничивает количество уровней в дереве. \n",
    "Значение `None` означает, что глубина деревьев не ограничена. Значение по умолчанию - `None`. \n",
    "Установка ограничения на глубину деревьев может помочь предотвратить переобучение модели. Обычно \n",
    "выбирают значения в диапазоне от 5 до 10.\n",
    "\n",
    "- `min_samples_split`: Минимальное количество образцов, необходимое для разделения внутреннего узла. \n",
    "Определяет, сколько образцов должно быть в узле, чтобы он мог быть разделен на дочерние узлы. \n",
    "Значение по умолчанию - 2. Увеличение значения может привести к более устойчивой модели и предотвратить \n",
    "переобучение. Обычно выбирают значения в диапазоне от 2 до 10.\n",
    "\"\"\"\n",
    "params = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 5, 10],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "# Создание объекта GridSearchCV\n",
    "\"\"\"\n",
    "Задание 1.8 (1 балл)\n",
    "Сохраните в переменную grid_search экземпляр класса GridSearchCV со следующими параметрами:\n",
    "estimator=model\n",
    "param_grid=params\n",
    "scoring='neg_mean_squared_error'\n",
    "Пример:\n",
    "var = GridSearchCV(par1=value1, par2=value2, par3=value3)\n",
    "\"\"\"\n",
    "# НАЧАЛО ВАШЕГО РЕШЕНИЯ\n",
    "\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=params, scoring='neg_mean_squared_error')\n",
    "\n",
    "# raise NotImplementedError()\n",
    "# КОНЕЦ ВАШЕГО РЕШЕНИЯ\n",
    "\n",
    "# Обучение модели на обучающих данных\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Получение лучшей модели\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Предсказание на тестовых данных\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Получение лучших параметров RandomForestRegressor\n",
    "RandomForestRegressor_best_params = grid_search.best_params_\n",
    "print(\"RandomForestRegressor_best_params: \", RandomForestRegressor_best_params)\n",
    "\n",
    "# Вычисление MSE\n",
    "RandomForestRegressor_mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"RandomForestRegressor_mse: \", RandomForestRegressor_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5ed2433c0e2eff6deb9af1c7a9084c56",
     "grade": true,
     "grade_id": "cell-243b0bf409d92646",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert type(model) == RandomForestRegressor\n",
    "assert type(grid_search) == GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cccdf6e80db560e8d502e97f31d37aa7",
     "grade": false,
     "grade_id": "cell-5ce5ce26909883fd",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingRegressor_best_params:  {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100}\n",
      "GradientBoostingRegressor_mse:  6.468420123259455\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# Создание объекта GradientBoostingRegressor\n",
    "\"\"\"\n",
    "Задание 1.9 (1 балл)\n",
    "Сохраните в переменную model экземпляр класса GradientBoostingRegressor без параметров.\n",
    "Пример:\n",
    "var = ClassExample()\n",
    "\"\"\"\n",
    "# НАЧАЛО ВАШЕГО РЕШЕНИЯ\n",
    "\n",
    "model = GradientBoostingRegressor()\n",
    "\n",
    "# raise NotImplementedError()\n",
    "# КОНЕЦ ВАШЕГО РЕШЕНИЯ\n",
    "\n",
    "# Определение параметров для GridSearchCV\n",
    "\"\"\"\n",
    "n_estimators (int): Определяет количество деревьев в ансамбле. Чем больше значение n_estimators, \n",
    "тем больше деревьев будет построено, и тем сложнее будет модель. Увеличение количества деревьев \n",
    "может улучшить производительность модели, но может также привести к увеличению времени обучения и \n",
    "потенциальному переобучению. В данном случае рассматриваются значения [100, 200, 300].\n",
    "\n",
    "learning_rate (float): Определяет скорость обучения модели. Этот параметр контролирует вклад каждого \n",
    "дерева в ансамбле. Более низкое значение learning_rate означает, что каждое дерево вносит меньший вклад \n",
    "в предсказание и, следовательно, модель будет обучаться медленнее, но может быть более устойчива к \n",
    "переобучению. В данном случае рассматриваются значения [0.1, 0.01, 0.001].\n",
    "\n",
    "max_depth (int): Определяет максимальную глубину каждого дерева в ансамбле. Глубина дерева указывает, \n",
    "сколько раз дерево будет делить данные на более мелкие группы. Увеличение глубины деревьев может \n",
    "привести к более сложным моделям, которые лучше адаптируются к обучающим данным, но могут быть более \n",
    "склонны к переобучению. В данном случае рассматриваются значения [3, 5, 10].\n",
    "\"\"\"\n",
    "params = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'learning_rate': [0.1, 0.01, 0.001],\n",
    "    'max_depth': [3, 5, 10]\n",
    "}\n",
    "\n",
    "# Создание объекта GridSearchCV\n",
    "\"\"\"\n",
    "Задание 1.10 (1 балл)\n",
    "Сохраните в переменную grid_search экземпляр класса GridSearchCV со следующими параметрами:\n",
    "estimator=model\n",
    "param_grid=params\n",
    "scoring='neg_mean_squared_error'\n",
    "Пример:\n",
    "var = GridSearchCV(par1=value1, par2=value2, par3=value3)\n",
    "\"\"\"\n",
    "# НАЧАЛО ВАШЕГО РЕШЕНИЯ\n",
    "\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=params, scoring='neg_mean_squared_error')\n",
    "\n",
    "# raise NotImplementedError()\n",
    "# КОНЕЦ ВАШЕГО РЕШЕНИЯ\n",
    "\n",
    "# Обучение модели на обучающих данных\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Получение лучшей модели\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Предсказание на тестовых данных\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Получение лучших параметров GradientBoostingRegressor\n",
    "GradientBoostingRegressor_best_params = grid_search.best_params_\n",
    "print(\"GradientBoostingRegressor_best_params: \", GradientBoostingRegressor_best_params)\n",
    "\n",
    "# Вычисление MSE\n",
    "GradientBoostingRegressor_mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"GradientBoostingRegressor_mse: \", GradientBoostingRegressor_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4538cfe7b9cab14a255105233a2733f3",
     "grade": true,
     "grade_id": "cell-c20b00f45cf2781c",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert type(model) == GradientBoostingRegressor\n",
    "assert type(grid_search) == GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0a575087d8a2bca2fa06ec5cd9af640e",
     "grade": false,
     "grade_id": "cell-65d703159cd1eda3",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoostRegressor_best_params:  {'learning_rate': 0.1, 'n_estimators': 100}\n",
      "AdaBoostRegressor_mse:  8.98759768805704\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "# Создание объекта AdaBoostRegressor\n",
    "\"\"\"\n",
    "Задание 1.11 (1 балл)\n",
    "Сохраните в переменную model экземпляр класса AdaBoostRegressor без параметров.\n",
    "Пример:\n",
    "var = ClassExample()\n",
    "\"\"\"\n",
    "# НАЧАЛО ВАШЕГО РЕШЕНИЯ\n",
    "\n",
    "model = AdaBoostRegressor()\n",
    "\n",
    "# raise NotImplementedError()\n",
    "# КОНЕЦ ВАШЕГО РЕШЕНИЯ\n",
    "\n",
    "\n",
    "# Определение параметров для GridSearchCV\n",
    "\"\"\"\n",
    "n_estimators: Этот параметр определяет количество базовых моделей (регрессоров), которые будут \n",
    "использоваться в ансамбле AdaBoost. Базовая модель представляет собой слабый регрессор, например, \n",
    "решающее дерево с ограниченной глубиной. Увеличение значения n_estimators может улучшить \n",
    "производительность модели, но может также привести к более длительному времени обучения. \n",
    "Обычно рекомендуется выбирать достаточно большое значение n_estimators, чтобы дать модели \n",
    "достаточно базовых моделей для обучения, но при этом избегать переобучения.\n",
    "\n",
    "learning_rate: Этот параметр контролирует вклад каждой базовой модели в окончательное предсказание. \n",
    "Меньшее значение learning_rate означает, что каждая базовая модель вносит меньший вклад, что может \n",
    "помочь улучшить обобщающую способность модели и уменьшить переобучение. Однако слишком низкое значение \n",
    "learning_rate может привести к несоответствию модели с данными и, как следствие, к понижению \n",
    "производительности. Обычно рекомендуется начинать с небольшого значения learning_rate и, \n",
    "при необходимости, увеличивать его.\n",
    "\"\"\"\n",
    "params = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.1, 0.01, 0.001]\n",
    "}\n",
    "\n",
    "# Создание объекта GridSearchCV\n",
    "\"\"\"\n",
    "Задание 1.12 (1 балл)\n",
    "Сохраните в переменную grid_search экземпляр класса GridSearchCV со следующими параметрами:\n",
    "estimator=model\n",
    "param_grid=params\n",
    "scoring='neg_mean_squared_error'\n",
    "Пример:\n",
    "var = GridSearchCV(par1=value1, par2=value2, par3=value3)\n",
    "\"\"\"\n",
    "# НАЧАЛО ВАШЕГО РЕШЕНИЯ\n",
    "\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=params, scoring='neg_mean_squared_error')\n",
    "\n",
    "# raise NotImplementedError()\n",
    "# КОНЕЦ ВАШЕГО РЕШЕНИЯ\n",
    "\n",
    "# Обучение модели на обучающих данных\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Получение лучшей модели\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Предсказание на тестовых данных\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Получение лучших параметров AdaBoostRegressor\n",
    "AdaBoostRegressor_best_params = grid_search.best_params_\n",
    "print(\"AdaBoostRegressor_best_params: \", AdaBoostRegressor_best_params)\n",
    "\n",
    "# Вычисление MSE\n",
    "AdaBoostRegressor_mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"AdaBoostRegressor_mse: \", AdaBoostRegressor_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1b4cbc52d27b3f7fb778fcc4ef5f4817",
     "grade": true,
     "grade_id": "cell-603495670d24c3c7",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert type(model) == AdaBoostRegressor\n",
    "assert type(grid_search) == GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "08aafec84aab642bf3e6af5401c4bc1a",
     "grade": false,
     "grade_id": "cell-61b471f7697689a9",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBRegressor_best_params:  {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 200}\n",
      "XGBRegressor_mse:  5.988378570059145\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Создание объекта XGBRegressor\n",
    "\"\"\"\n",
    "Задание 1.13 (1 балл)\n",
    "Сохраните в переменную model экземпляр класса XGBRegressor без параметров.\n",
    "Пример:\n",
    "var = ClassExample()\n",
    "\"\"\"\n",
    "# НАЧАЛО ВАШЕГО РЕШЕНИЯ\n",
    "\n",
    "model = XGBRegressor()\n",
    "\n",
    "# raise NotImplementedError()\n",
    "# КОНЕЦ ВАШЕГО РЕШЕНИЯ\n",
    "\n",
    "# Определение параметров для GridSearchCV\n",
    "\"\"\"\n",
    "'n_estimators' определяет количество деревьев в ансамбле XGBoost. Большее значение n_estimators может \n",
    "улучшить производительность модели, но при этом потребуется больше вычислительных ресурсов и время \n",
    "обучения. Рекомендуется выбирать достаточно большое значение, но избегать переобучения.\n",
    "\n",
    "'learning_rate' контролирует вклад каждого дерева в окончательное предсказание модели. Меньшее значение \n",
    "learning_rate означает меньший вклад каждого дерева, что может помочь улучшить обобщающую способность \n",
    "модели. Однако, слишком низкое значение может привести к недообучению модели.\n",
    "\n",
    "'max_depth' определяет максимальную глубину каждого дерева в ансамбле. Большая глубина может помочь \n",
    "модели захватить более сложные взаимодействия в данных, но также может привести к переобучению. \n",
    "Рекомендуется начинать с небольшой глубины и постепенно увеличивать, контролируя производительность и \n",
    "переобучение модели.\n",
    "\"\"\"\n",
    "params = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'learning_rate': [0.1, 0.01, 0.001],\n",
    "    'max_depth': [3, 5, 10]\n",
    "}\n",
    "\n",
    "# Создание объекта GridSearchCV\n",
    "\"\"\"\n",
    "Задание 1.14 (1 балл)\n",
    "Сохраните в переменную grid_search экземпляр класса GridSearchCV со следующими параметрами:\n",
    "estimator=model\n",
    "param_grid=params\n",
    "scoring='neg_mean_squared_error'\n",
    "Пример:\n",
    "var = GridSearchCV(par1=value1, par2=value2, par3=value3)\n",
    "\"\"\"\n",
    "# НАЧАЛО ВАШЕГО РЕШЕНИЯ\n",
    "\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=params, scoring='neg_mean_squared_error')\n",
    "\n",
    "# raise NotImplementedError()\n",
    "# КОНЕЦ ВАШЕГО РЕШЕНИЯ\n",
    "\n",
    "# Обучение модели на обучающих данных\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Получение лучшей модели\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Предсказание на тестовых данных\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Получение лучших параметров XGBRegressor\n",
    "XGBRegressor_best_params = grid_search.best_params_\n",
    "print(\"XGBRegressor_best_params: \", XGBRegressor_best_params)\n",
    "\n",
    "# Вычисление MSE\n",
    "XGBRegressor_mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"XGBRegressor_mse: \", XGBRegressor_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "35f1df60cdeb75a5ddf2c8708ca83aa6",
     "grade": true,
     "grade_id": "cell-7eb8f4527128f36b",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert type(model) == XGBRegressor\n",
    "assert type(grid_search) == GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "42866973592224a08addb553d0aae20e",
     "grade": false,
     "grade_id": "cell-0382c850da183c6e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from catboost import CatBoostRegressor\n",
    "\n",
    "# Создание объекта CatBoostRegressor\n",
    "\"\"\"\n",
    "Задание 1.15 (1 балл)\n",
    "Сохраните в переменную model экземпляр класса CatBoostRegressor с параметром silent=True.\n",
    "Пример:\n",
    "var = ClassExample()\n",
    "\"\"\"\n",
    "# НАЧАЛО ВАШЕГО РЕШЕНИЯ\n",
    "raise NotImplementedError()\n",
    "# КОНЕЦ ВАШЕГО РЕШЕНИЯ\n",
    "\n",
    "# Определение параметров для GridSearchCV\n",
    "\"\"\"\n",
    "\n",
    "learning_rate: Скорость обучения модели. Определяет вклад каждого дерева в композицию. \n",
    "Меньшие значения обычно требуют большего числа деревьев для достижения хорошей производительности модели.\n",
    "\n",
    "n_estimators: Количество деревьев в градиентном бустинге. Большее количество деревьев может улучшить \n",
    "производительность модели, но также может привести к переобучению, поэтому следует подбирать \n",
    "оптимальное значение.\n",
    "\n",
    "max_depth: Максимальная глубина каждого дерева в градиентном бустинге. Большая глубина может увеличить \n",
    "производительность модели, но также может привести к переобучению.\n",
    "\n",
    "subsample: Доля обучающих примеров, используемых для обучения каждого дерева в градиентном бустинге. \n",
    "Значение меньше 1.0 может помочь уменьшить переобучение.\n",
    "\n",
    "colsample_bylevel: Доля признаков, используемых для обучения каждого уровня дерева в градиентном бустинге. \n",
    "Значение меньше 1.0 может помочь уменьшить переобучение.\n",
    "\n",
    "reg_lambda: Коэффициент L2-регуляризации для весов модели. Используется для сдерживания переобучения.\n",
    "\"\"\"\n",
    "params = {\n",
    "    'learning_rate': [0.1, 0.01, 0.001],\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [3, 5, 10],\n",
    "    'subsample': [1.0],\n",
    "    'colsample_bylevel': [1.0],\n",
    "    'reg_lambda': [3.0]\n",
    "}\n",
    "\n",
    "# Создание объекта GridSearchCV\n",
    "\"\"\"\n",
    "Задание 1.16 (1 балл)\n",
    "Сохраните в переменную grid_search экземпляр класса GridSearchCV со следующими параметрами:\n",
    "estimator=model\n",
    "param_grid=params\n",
    "scoring='neg_mean_squared_error'\n",
    "Пример:\n",
    "var = GridSearchCV(par1=value1, par2=value2, par3=value3)\n",
    "\"\"\"\n",
    "# НАЧАЛО ВАШЕГО РЕШЕНИЯ\n",
    "raise NotImplementedError()\n",
    "# КОНЕЦ ВАШЕГО РЕШЕНИЯ\n",
    "\n",
    "# Обучение модели на обучающих данных\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Получение лучшей модели\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Предсказание на тестовых данных\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Получение лучших параметров CatBoostRegressor\n",
    "CatBoostRegressor_best_params = grid_search.best_params_\n",
    "print(\"CatBoostRegressor_best_params: \", CatBoostRegressor_best_params)\n",
    "\n",
    "# Вычисление MSE\n",
    "CatBoostRegressor_mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"CatBoostRegressor_mse: \", CatBoostRegressor_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e29c5962b501dac74989a82b0f3f3ef0",
     "grade": true,
     "grade_id": "cell-3e124666cb4b7f82",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert type(model) == CatBoostRegressor\n",
    "assert type(grid_search) == GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "77169bd05ffe9bc969c07b3d8f43ddc5",
     "grade": false,
     "grade_id": "cell-b89ed3aeeed8a45f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Вывод результатов моделей регрессии \n",
    "\n",
    "data = [ \n",
    "    ['LinearRegression', f'{LinearRegression_mse}', f'{LinearRegression_best_params}'],\n",
    "    ['SVR', f'{SVR_mse}', f'{SVR_best_params}'],\n",
    "    ['DecisionTreeRegressor', f'{DecisionTreeRegressor_mse}', f'{DecisionTreeRegressor_best_params}'],\n",
    "    ['RandomForestRegressor', f'{RandomForestRegressor_mse}', f'{RandomForestRegressor_best_params}'],\n",
    "    ['GradientBoostingRegressor', f'{GradientBoostingRegressor_mse}', f'{GradientBoostingRegressor_best_params}'],\n",
    "    ['AdaBoostRegressor', f'{AdaBoostRegressor_mse}', f'{AdaBoostRegressor_best_params}'],\n",
    "    ['XGBRegressor', f'{XGBRegressor_mse}', f'{XGBRegressor_best_params}'],\n",
    "    ['CatBoostRegressor', f'{CatBoostRegressor_mse}', f'{CatBoostRegressor_best_params}']\n",
    "]\n",
    "\n",
    "\n",
    "# Создание DataFrame из данных\n",
    "df = pd.DataFrame(data, columns=['Модель', 'MSE', 'Параметры'], index=range(1, 1 + len(data)))\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "# Отображение DataFrame\n",
    "df.head(len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4070537cc1fb10e7d78a40e31b317932",
     "grade": false,
     "grade_id": "cell-92541b6ce59eefe6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Задача классификации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a352b0ac880abaea011b2c64a4dd8071",
     "grade": false,
     "grade_id": "cell-346b722ea4909367",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Мы будем использовать датасет \"Bank Marketing\". В датасете \"Bank Marketing\" содержатся данные, связанные с маркетинговыми кампаниями банка. Вот колонки, представленные в датасете \"Bank Marketing\":\n",
    "\n",
    "1. **age**: Возраст клиента.\n",
    "\n",
    "2. **job**: Тип работы клиента.\n",
    "\n",
    "3. **marital**: Семейное положение клиента.\n",
    "\n",
    "4. **education**: Образование клиента.\n",
    "\n",
    "5. **default**: Есть ли у клиента кредитный дефолт (задолженность).\n",
    "\n",
    "6. **balance**: Баланс на счете клиента.\n",
    "\n",
    "7. **housing**: Имеет ли клиент ипотеку (жилую недвижимость).\n",
    "\n",
    "8. **loan**: Имеет ли клиент личный заем.\n",
    "\n",
    "9. **contact**: Способ связи с клиентом.\n",
    "\n",
    "10. **day**: День месяца, когда был выполнен последний контакт.\n",
    "\n",
    "11. **month**: Месяц года, когда был выполнен последний контакт.\n",
    "\n",
    "12. **duration**: Продолжительность последнего контакта в секундах.\n",
    "\n",
    "13. **campaign**: Количество контактов, выполненных во время данной кампании.\n",
    "\n",
    "14. **pdays**: Количество дней, прошедших с момента последнего контакта до предыдущей кампании.\n",
    "\n",
    "15. **previous**: Количество контактов, выполненных перед текущей кампанией.\n",
    "\n",
    "16. **poutcome**: Результат предыдущей маркетинговой кампании.\n",
    "\n",
    "17. **y**: Целевая переменная, которую необходимо предсказать. Например, это может быть информация о том, стал ли клиент подписчиком (1) или нет (0) на определенное предложение банка."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "67b189575fa3ce37df0339861ff91c63",
     "grade": false,
     "grade_id": "cell-7b84e59798c59c9f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Мы будем использовать 7 моделей классификации и GridSearchCV для подбора параметров:\n",
    "1. Логистическая регрессия (Logistic Regression): `sklearn.linear_model.LogisticRegression`\n",
    "2. Метод опорных векторов (Support Vector Machines): `sklearn.svm.SVC`\n",
    "3. Решающие деревья (Decision Trees): `sklearn.tree.DecisionTreeClassifier`\n",
    "4. Случайный лес (Random Forest): `sklearn.ensemble.RandomForestClassifier`\n",
    "5. Градиентный бустинг (Gradient Boosting): `sklearn.ensemble.GradientBoostingClassifier`\n",
    "6. XGBoost: `xgboost.XGBClassifier`\n",
    "7. CatBoost: `catboost.CatBoostClassifier`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3ed7d9a7f783933a2b34c6e113ac4592",
     "grade": false,
     "grade_id": "cell-de4a44becf4c1d6f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Загрузка данных из CSV файла\n",
    "data = pd.read_csv(\"bank-full.csv\", delimiter=\";\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c4110e7f15b50163016415761e1371d5",
     "grade": false,
     "grade_id": "cell-522272613baf84a2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Разделение на признаки (X) и целевую переменную (y)\n",
    "X = data.drop('y', axis=1)\n",
    "y = data['y'].apply(lambda x: 1 if x==\"yes\" else 0)\n",
    "\n",
    "\n",
    "# Разделение на обучающий и тестовый наборы данных\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Определение препроцессора для категориальных и числовых признаков\n",
    "categorical_features = ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'poutcome']\n",
    "categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "numerical_features = X_train.select_dtypes(include=['int64', 'float64']).columns\n",
    "numerical_transformer = StandardScaler()\n",
    "\n",
    "# Объединение препроцессоров\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', categorical_transformer, categorical_features),\n",
    "        ('num', numerical_transformer, numerical_features)\n",
    "    ])\n",
    "\n",
    "# Создание пайплайна для препроцессора\n",
    "preprocessing_pipeline = Pipeline(steps=[('preprocessor', preprocessor)])\n",
    "\n",
    "# Применение препроцессора к данным\n",
    "X_train = preprocessing_pipeline.fit_transform(X_train)\n",
    "X_test = preprocessing_pipeline.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bff6a4f1dce8ee3617c004c2bc080a3a",
     "grade": false,
     "grade_id": "cell-b36ae883d67c44b4",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\"\"\"\n",
    "Задание 2.1 (1 балл)\n",
    "Сохраните в переменную model экземпляр класса LogisticRegression без параметров.\n",
    "Пример:\n",
    "var = ClassExample()\n",
    "\"\"\"\n",
    "# НАЧАЛО ВАШЕГО РЕШЕНИЯ\n",
    "raise NotImplementedError()\n",
    "# КОНЕЦ ВАШЕГО РЕШЕНИЯ\n",
    "\n",
    "# Определение параметров для GridSearchCV\n",
    "\"\"\"\n",
    "'penalty': ['l1', 'l2']\n",
    "\n",
    "Параметр 'penalty' отвечает за регуляризацию модели, то есть штраф за сложность модели. Значение 'l1' \n",
    "соответствует L1-регуляризации (Лассо), которая добавляет штраф, равный абсолютному значению коэффициентов \n",
    "модели. Значение 'l2' соответствует L2-регуляризации (гребневая регрессия), которая добавляет штраф, \n",
    "равный квадрату значений коэффициентов модели. Выбор между 'l1' и 'l2' позволяет контролировать влияние \n",
    "каждого из этих типов регуляризации на модель.\n",
    "\n",
    "'C': [0.1, 1.0, 10.0]\n",
    "Параметр 'C' определяет обратную силу регуляризации. Значение 'C' контролирует степень регуляризации: \n",
    "чем меньше значение 'C', тем сильнее применяется регуляризация, а чем больше значение 'C', тем слабее \n",
    "регуляризация. Таким образом, параметр 'C' позволяет настраивать баланс между точностью модели на \n",
    "обучающих данных и ее сложностью, предотвращая переобучение.\n",
    "\"\"\"\n",
    "\n",
    "params = {\n",
    "'penalty': ['l1', 'l2'],\n",
    "'C': [0.1, 1.0, 10.0]\n",
    "}\n",
    "\n",
    "# Создание объекта GridSearchCV\n",
    "\"\"\"\n",
    "Задание 2.2 (1 балл)\n",
    "Сохраните в переменную grid_search экземпляр класса GridSearchCV со следующими параметрами:\n",
    "estimator=model\n",
    "param_grid=params\n",
    "scoring='f1_macro'\n",
    "Пример:\n",
    "var = GridSearchCV(par1=value1, par2=value2, par3=value3)\n",
    "\"\"\"\n",
    "# НАЧАЛО ВАШЕГО РЕШЕНИЯ\n",
    "raise NotImplementedError()\n",
    "# КОНЕЦ ВАШЕГО РЕШЕНИЯ\n",
    "\n",
    "# Обучение модели на обучающих данных\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Получение лучшей модели\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Предсказание на тестовых данных\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Получение лучших параметров LogisticRegression\n",
    "LogisticRegression_best_params = grid_search.best_params_\n",
    "print(\"LogisticRegression_best_params: \", LogisticRegression_best_params)\n",
    "\n",
    "# Вычисление F1-меры\n",
    "LogisticRegression_f1 = f1_score(y_test, y_pred, average='macro')\n",
    "print(\"LogisticRegression_f1: \", LogisticRegression_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bc2257dfaf816bf3244dda7d622fe5e3",
     "grade": true,
     "grade_id": "cell-e8f682ad6574994e",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert type(model) == LogisticRegression\n",
    "assert type(grid_search) == GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fe74e42542359d0744392ffec6faabde",
     "grade": false,
     "grade_id": "cell-07c7a82699aba882",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "\"\"\"\n",
    "Задание 2.3 (1 балл)\n",
    "Сохраните в переменную model экземпляр класса SVC без параметров.\n",
    "Пример:\n",
    "var = ClassExample()\n",
    "\"\"\"\n",
    "# НАЧАЛО ВАШЕГО РЕШЕНИЯ\n",
    "raise NotImplementedError()\n",
    "# КОНЕЦ ВАШЕГО РЕШЕНИЯ\n",
    "\n",
    "# Определение параметров для GridSearchCV\n",
    "\"\"\"\n",
    "'kernel': ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "Параметр 'kernel' определяет тип используемого ядра для построения гиперплоскости. Значение 'linear'\n",
    "означает линейное ядро, которое строит гиперплоскость с помощью линейной функции. Значение 'poly' \n",
    "означает полиномиальное ядро, которое строит гиперплоскость с помощью полиномиальной функции. \n",
    "Значение 'rbf' означает радиальное базисное ядро (RBF), которое строит гиперплоскость с помощью \n",
    "радиальной базисной функции. Значение 'sigmoid' означает сигмоидное ядро, которое строит гиперплоскость \n",
    "с помощью сигмоидной функции.\n",
    "\n",
    "'C': [0.1, 1.0, 10.0]\n",
    "Параметр 'C' определяет параметр регуляризации модели SVM. Большее значение 'C' означает меньшую \n",
    "регуляризацию, что может привести к более точной модели на обучающих данных, но также может привести \n",
    "к переобучению. Меньшее значение 'C' означает большую регуляризацию, что может привести к менее точной \n",
    "модели, но более устойчивой к шуму и выбросам.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# params = {\n",
    "#     'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "#     'C': [0.1, 1.0, 10.0]\n",
    "# }\n",
    "params = {\n",
    "    'kernel': ['linear'],\n",
    "    'C': [1.0]\n",
    "}\n",
    "\n",
    "# Создание объекта GridSearchCV\n",
    "\"\"\"\n",
    "Задание 2.4 (1 балл)\n",
    "Сохраните в переменную grid_search экземпляр класса GridSearchCV со следующими параметрами:\n",
    "estimator=model\n",
    "param_grid=params\n",
    "scoring='f1_macro'\n",
    "Пример:\n",
    "var = GridSearchCV(par1=value1, par2=value2, par3=value3)\n",
    "\"\"\"\n",
    "# НАЧАЛО ВАШЕГО РЕШЕНИЯ\n",
    "raise NotImplementedError()\n",
    "# КОНЕЦ ВАШЕГО РЕШЕНИЯ\n",
    "\n",
    "# Обучение модели на обучающих данных\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Получение лучшей модели\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Предсказание на тестовых данных\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Получение лучших параметров SVC\n",
    "SVC_best_params = grid_search.best_params_\n",
    "print(\"SVC_best_params: \", SVC_best_params)\n",
    "\n",
    "# Вычисление F1-меры\n",
    "SVC_f1 = f1_score(y_test, y_pred, average='macro')\n",
    "print(\"SVC_f1: \", SVC_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e18c112201eac01a7a1c2c1561774cf8",
     "grade": true,
     "grade_id": "cell-e7f61e84459f0c86",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert type(model) == SVC\n",
    "assert type(grid_search) == GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9dc117e28baec357fb0943943fa8311c",
     "grade": false,
     "grade_id": "cell-9028c34e4703f7f8",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\"\"\"\n",
    "Задание 2.5 (1 балл)\n",
    "Сохраните в переменную model экземпляр класса DecisionTreeClassifier без параметров.\n",
    "Пример:\n",
    "var = ClassExample()\n",
    "\"\"\"\n",
    "# НАЧАЛО ВАШЕГО РЕШЕНИЯ\n",
    "raise NotImplementedError()\n",
    "# КОНЕЦ ВАШЕГО РЕШЕНИЯ\n",
    "\n",
    "# Определение параметров для GridSearchCV\n",
    "\"\"\"\n",
    "'criterion': ['gini', 'entropy']\n",
    "Параметр 'criterion' определяет критерий, используемый для измерения качества разделения. Значение \n",
    "'gini' означает использование индекса Джини, который измеряет неопределенность набора данных. Значение \n",
    "'entropy' означает использование энтропийного критерия, который также измеряет неопределенность набора \n",
    "данных, но использует логарифмическую шкалу.\n",
    "\n",
    "'max_depth': [None, 5, 10]\n",
    "Параметр 'max_depth' определяет максимальную глубину дерева решений. Значение None означает, что глубина \n",
    "дерева не ограничена. Числовые значения указывают конкретное ограничение на глубину дерева.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "params = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [None, 5, 10]\n",
    "}\n",
    "\n",
    "# Создание объекта GridSearchCV\n",
    "\"\"\"\n",
    "Задание 2.6 (1 балл)\n",
    "Сохраните в переменную grid_search экземпляр класса GridSearchCV со следующими параметрами:\n",
    "estimator=model\n",
    "param_grid=params\n",
    "scoring='f1_macro'\n",
    "Пример:\n",
    "var = GridSearchCV(par1=value1, par2=value2, par3=value3)\n",
    "\"\"\"\n",
    "# НАЧАЛО ВАШЕГО РЕШЕНИЯ\n",
    "raise NotImplementedError()\n",
    "# КОНЕЦ ВАШЕГО РЕШЕНИЯ\n",
    "\n",
    "# Обучение модели на обучающих данных\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Получение лучшей модели\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Предсказание на тестовых данных\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Получение лучших параметров DecisionTreeClassifier\n",
    "DecisionTreeClassifier_best_params = grid_search.best_params_\n",
    "print(\"DecisionTreeClassifier_best_params: \", DecisionTreeClassifier_best_params)\n",
    "\n",
    "# Вычисление F1-меры\n",
    "DecisionTreeClassifier_f1 = f1_score(y_test, y_pred, average='macro')\n",
    "print(\"DecisionTreeClassifier_f1: \", DecisionTreeClassifier_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ec5dcce233039436b25d1c0d58767fba",
     "grade": true,
     "grade_id": "cell-e5f4270f3ee48fa8",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert type(model) == DecisionTreeClassifier\n",
    "assert type(grid_search) == GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "347380abf4684731da3773727bfd8037",
     "grade": false,
     "grade_id": "cell-3a383c70d0b572c3",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\"\"\"\n",
    "Задание 2.7 (1 балл)\n",
    "Сохраните в переменную model экземпляр класса RandomForestClassifier без параметров.\n",
    "Пример:\n",
    "var = ClassExample()\n",
    "\"\"\"\n",
    "# НАЧАЛО ВАШЕГО РЕШЕНИЯ\n",
    "raise NotImplementedError()\n",
    "# КОНЕЦ ВАШЕГО РЕШЕНИЯ\n",
    "\n",
    "# Определение параметров для GridSearchCV\n",
    "\"\"\"\n",
    "'n_estimators': [100, 200, 300]\n",
    "Параметр 'n_estimators' определяет количество деревьев в лесу. Большее количество деревьев может повысить \n",
    "точность модели, но может также увеличить время обучения и инференса.\n",
    "\n",
    "'max_depth': [None, 5, 10]\n",
    "Параметр 'max_depth' определяет максимальную глубину дерева решений в лесу. Значение None означает, что \n",
    "глубина деревьев не ограничена. Числовые значения указывают конкретное ограничение на глубину дерева.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "params = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 5, 10]\n",
    "}\n",
    "\n",
    "# Создание объекта GridSearchCV\n",
    "\"\"\"\n",
    "Задание 2.8 (1 балл)\n",
    "Сохраните в переменную grid_search экземпляр класса GridSearchCV со следующими параметрами:\n",
    "estimator=model\n",
    "param_grid=params\n",
    "scoring='f1_macro'\n",
    "Пример:\n",
    "var = GridSearchCV(par1=value1, par2=value2, par3=value3)\n",
    "\"\"\"\n",
    "# НАЧАЛО ВАШЕГО РЕШЕНИЯ\n",
    "raise NotImplementedError()\n",
    "# КОНЕЦ ВАШЕГО РЕШЕНИЯ\n",
    "\n",
    "# Обучение модели на обучающих данных\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Получение лучшей модели\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Предсказание на тестовых данных\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Получение лучших параметров RandomForestClassifier\n",
    "RandomForestClassifier_best_params = grid_search.best_params_\n",
    "print(\"RandomForestClassifier_best_params: \", RandomForestClassifier_best_params)\n",
    "\n",
    "# Вычисление F1-меры\n",
    "RandomForestClassifier_f1 = f1_score(y_test, y_pred, average='macro')\n",
    "print(\"RandomForestClassifier_f1: \", RandomForestClassifier_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "77881ec6fb4523e32de848deee63b50b",
     "grade": true,
     "grade_id": "cell-1558a47cc9230343",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert type(model) == RandomForestClassifier\n",
    "assert type(grid_search) == GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "89e5c3d027cdf574af5f7d391c620ae9",
     "grade": false,
     "grade_id": "cell-87c99b53ef046ce5",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "\"\"\"\n",
    "Задание 2.9 (1 балл)\n",
    "Сохраните в переменную model экземпляр класса GradientBoostingClassifier без параметров.\n",
    "Пример:\n",
    "var = ClassExample()\n",
    "\"\"\"\n",
    "# НАЧАЛО ВАШЕГО РЕШЕНИЯ\n",
    "raise NotImplementedError()\n",
    "# КОНЕЦ ВАШЕГО РЕШЕНИЯ\n",
    "\n",
    "# Определение параметров для GridSearchCV\n",
    "\"\"\"\n",
    "'n_estimators': [100, 200, 300]\n",
    "Параметр 'n_estimators' определяет количество деревьев в градиентном бустинге. Большее количество деревьев \n",
    "может повысить точность модели, но может также увеличить время обучения и инференса.\n",
    "\n",
    "'max_depth': [3, 5, 10]\n",
    "Параметр 'max_depth' определяет максимальную глубину дерева решений в градиентном бустинге. Значение 3, 5 \n",
    "или 10 указывает конкретное ограничение на глубину дерева.\n",
    "\n",
    "'learning_rate': [0.1, 0.01, 0.001]\n",
    "Параметр 'learning_rate' определяет скорость обучения модели. Меньшие значения 'learning_rate' могут \n",
    "требовать большего количества деревьев для достижения высокой точности модели.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# params = {\n",
    "#     'n_estimators': [100, 200, 300],\n",
    "#     'max_depth': [3, 5, 10],\n",
    "#     'learning_rate': [0.1, 0.01, 0.001]\n",
    "# }\n",
    "\n",
    "params = {\n",
    "    'n_estimators': [30, 50, 100],\n",
    "    'max_depth': [5],\n",
    "    'learning_rate': [0.1, 0.01]\n",
    "}\n",
    "\n",
    "# Создание объекта GridSearchCV\n",
    "\"\"\"\n",
    "Задание 2.10 (1 балл)\n",
    "Сохраните в переменную grid_search экземпляр класса GridSearchCV со следующими параметрами:\n",
    "estimator=model\n",
    "param_grid=params\n",
    "scoring='f1_macro'\n",
    "Пример:\n",
    "var = GridSearchCV(par1=value1, par2=value2, par3=value3)\n",
    "\"\"\"\n",
    "# НАЧАЛО ВАШЕГО РЕШЕНИЯ\n",
    "raise NotImplementedError()\n",
    "# КОНЕЦ ВАШЕГО РЕШЕНИЯ\n",
    "\n",
    "# Обучение модели на обучающих данных\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Получение лучшей модели\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Предсказание на тестовых данных\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Получение лучших параметров GradientBoostingClassifier\n",
    "GradientBoostingClassifier_best_params = grid_search.best_params_\n",
    "print(\"GradientBoostingClassifier_best_params: \", GradientBoostingClassifier_best_params)\n",
    "\n",
    "# Вычисление F1-меры\n",
    "GradientBoostingClassifier_f1 = f1_score(y_test, y_pred, average='macro')\n",
    "print(\"GradientBoostingClassifier_f1: \", GradientBoostingClassifier_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bdb5b4095e167ad7f8f8ec16f78c4955",
     "grade": true,
     "grade_id": "cell-eef10fd55b17650e",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert type(model) == GradientBoostingClassifier\n",
    "assert type(grid_search) == GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b9b9f0d203db96abf5869f0f0d177667",
     "grade": false,
     "grade_id": "cell-9ff51eaa71d964a9",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "\"\"\"\n",
    "Задание 2.11 (1 балл)\n",
    "Сохраните в переменную model экземпляр класса xgb.XGBClassifier без параметров.\n",
    "Пример:\n",
    "var = ClassExample()\n",
    "\"\"\"\n",
    "# НАЧАЛО ВАШЕГО РЕШЕНИЯ\n",
    "raise NotImplementedError()\n",
    "# КОНЕЦ ВАШЕГО РЕШЕНИЯ\n",
    "\n",
    "# Определение параметров для GridSearchCV\n",
    "\"\"\"\n",
    "'n_estimators': [100, 200, 300]\n",
    "Параметр 'n_estimators' определяет количество деревьев в ансамбле. Большее количество деревьев может \n",
    "улучшить качество модели, но может также увеличить время обучения и инференса.\n",
    "\n",
    "'max_depth': [3, 5, 10]\n",
    "Параметр 'max_depth' определяет максимальную глубину дерева. Увеличение глубины дерева может привести к \n",
    "более сложной модели, которая может переобучиться на тренировочных данных.\n",
    "\n",
    "'learning_rate': [0.1, 0.01, 0.001]\n",
    "Параметр 'learning_rate' определяет скорость обучения модели. Меньшие значения 'learning_rate' требуют \n",
    "большего числа деревьев для достижения хорошей точности модели.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# params = {\n",
    "#     'n_estimators': [100, 200, 300],\n",
    "#     'max_depth': [3, 5, 10],\n",
    "#     'learning_rate': [0.1, 0.01, 0.001]\n",
    "# }\n",
    "params = {\n",
    "    'n_estimators': [30, 50, 100],\n",
    "    'max_depth': [3, 5],\n",
    "    'learning_rate': [0.1, 0.01]\n",
    "}\n",
    "\n",
    "# Создание объекта GridSearchCV\n",
    "\"\"\"\n",
    "Задание 2.12 (1 балл)\n",
    "Сохраните в переменную grid_search экземпляр класса GridSearchCV со следующими параметрами:\n",
    "estimator=model\n",
    "param_grid=params\n",
    "scoring='f1_macro'\n",
    "Пример:\n",
    "var = GridSearchCV(par1=value1, par2=value2, par3=value3)\n",
    "\"\"\"\n",
    "# НАЧАЛО ВАШЕГО РЕШЕНИЯ\n",
    "raise NotImplementedError()\n",
    "# КОНЕЦ ВАШЕГО РЕШЕНИЯ\n",
    "\n",
    "# Обучение модели на обучающих данных\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Получение лучшей модели\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Предсказание на тестовых данных\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Получение лучших параметров XGBClassifier\n",
    "XGBClassifier_best_params = grid_search.best_params_\n",
    "print(\"XGBClassifier_best_params: \", XGBClassifier_best_params)\n",
    "\n",
    "# Вычисление F1-меры\n",
    "XGBClassifier_f1 = f1_score(y_test, y_pred, average='macro')\n",
    "print(\"XGBClassifier_f1: \", XGBClassifier_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fe4b85f9c56e63d14a015ff53594d00d",
     "grade": true,
     "grade_id": "cell-265ff171f6dfff58",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert type(model) == xgb.XGBClassifier\n",
    "assert type(grid_search) == GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "90d875aa8e46e9b2ced8d0386fd7cba4",
     "grade": false,
     "grade_id": "cell-e49e7d38996f3ac1",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import catboost as cb\n",
    "\n",
    "\"\"\"\n",
    "Задание 2.13 (1 балл)\n",
    "Сохраните в переменную model экземпляр класса cb.CatBoostClassifier с параметром silent=True.\n",
    "Пример:\n",
    "var = ClassExample(silent=True)\n",
    "\"\"\"\n",
    "# НАЧАЛО ВАШЕГО РЕШЕНИЯ\n",
    "raise NotImplementedError()\n",
    "# КОНЕЦ ВАШЕГО РЕШЕНИЯ\n",
    "\n",
    "# Определение параметров для GridSearchCV\n",
    "\"\"\"\n",
    "'n_estimators': [100, 200, 300]\n",
    "Параметр 'n_estimators' определяет количество деревьев в ансамбле. Большее количество деревьев может \n",
    "улучшить качество модели, но может также увеличить время обучения и инференса.\n",
    "\n",
    "'max_depth': [3, 5, 10]\n",
    "Параметр 'max_depth' определяет максимальную глубину дерева. Увеличение глубины дерева может привести к \n",
    "более сложной модели, которая может переобучиться на тренировочных данных.\n",
    "\n",
    "'learning_rate': [0.1, 0.01, 0.001]\n",
    "Параметр 'learning_rate' определяет скорость обучения модели. Меньшие значения 'learning_rate' требуют \n",
    "большего числа деревьев для достижения хорошей точности модели.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# params = {\n",
    "#     'n_estimators': [100, 200, 300],\n",
    "#     'max_depth': [3, 5, 10],\n",
    "#     'learning_rate': [0.1, 0.01, 0.001]\n",
    "# }\n",
    "params = {\n",
    "    'n_estimators': [30, 50, 100],\n",
    "    'max_depth': [3, 5],\n",
    "    'learning_rate': [0.1, 0.01]\n",
    "}\n",
    "\n",
    "# Создание объекта GridSearchCV\n",
    "\"\"\"\n",
    "Задание 2.14 (1 балл)\n",
    "Сохраните в переменную grid_search экземпляр класса GridSearchCV со следующими параметрами:\n",
    "estimator=model\n",
    "param_grid=params\n",
    "scoring='f1_macro'\n",
    "Пример:\n",
    "var = GridSearchCV(par1=value1, par2=value2, par3=value3)\n",
    "\"\"\"\n",
    "# НАЧАЛО ВАШЕГО РЕШЕНИЯ\n",
    "raise NotImplementedError()\n",
    "# КОНЕЦ ВАШЕГО РЕШЕНИЯ\n",
    "\n",
    "# Обучение модели на обучающих данных\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Получение лучшей модели\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Предсказание на тестовых данных\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Получение лучших параметров CatBoostClassifier\n",
    "CatBoostClassifier_best_params = grid_search.best_params_\n",
    "print(\"CatBoostClassifier_best_params: \", CatBoostClassifier_best_params)\n",
    "\n",
    "# Вычисление F1-меры\n",
    "CatBoostClassifier_f1 = f1_score(y_test, y_pred, average='macro')\n",
    "print(\"CatBoostClassifier_f1: \", CatBoostClassifier_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "55c25f616762a061267700bd9ec4552a",
     "grade": true,
     "grade_id": "cell-bc10a3a8366a4951",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert type(model) == cb.CatBoostClassifier\n",
    "assert type(grid_search) == GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "83a4d88c191d7a019df15b48b26336e2",
     "grade": false,
     "grade_id": "cell-15cc0a96bd42fd2a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Вывод результатов моделей классификации \n",
    "data = [ \n",
    "    ['LogisticRegression', f'{LogisticRegression_f1}', f'{LogisticRegression_best_params}'],\n",
    "    ['SVC', f'{SVC_f1}', f'{SVC_best_params}'],\n",
    "    ['DecisionTreeClassifier', f'{DecisionTreeClassifier_f1}', f'{DecisionTreeClassifier_best_params}'],\n",
    "    ['RandomForestClassifier', f'{RandomForestClassifier_f1}', f'{RandomForestClassifier_best_params}'],\n",
    "    ['GradientBoostingClassifier', f'{GradientBoostingClassifier_f1}', f'{GradientBoostingClassifier_best_params}'],\n",
    "    ['XGBClassifier', f'{XGBClassifier_f1}', f'{XGBClassifier_best_params}'],\n",
    "    ['CatBoostClassifier', f'{CatBoostClassifier_f1}', f'{CatBoostClassifier_best_params}']\n",
    "]\n",
    "\n",
    "\n",
    "# Создание DataFrame из данных\n",
    "df = pd.DataFrame(data, columns=['Модель', 'F1', 'Параметры'], index=range(1, 1 + len(data)))\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "# Отображение DataFrame\n",
    "df.head(len(data))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
