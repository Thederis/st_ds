{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Содержание\n",
    "- [Pandas: описание возможностей](#pandas)\n",
    "- [Структуры данных](#structures)\n",
    "- [Чтение и запись данных](#read_write)\n",
    "- [Индексация и выборка данных](#indexing)\n",
    "- [Обработка данных](#processing)\n",
    "- [Объединение и слияние данных](#merging)\n",
    "- [Визуализация данных](#visualization)\n",
    "- [Работа с временными рядами](#time_series)\n",
    "- [Работа с большими файлами](#big_files)\n",
    "- [Примеры с реальными данными](#real_examples)\n",
    "- [KNN](#KNN)\n",
    "- [KNN для регрессии](#KNN_regression)\n",
    "- [KNN для классификации](#KNN_classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas: описание возможностей  <a class=\"anchor\" id=\"pandas\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas - это библиотека языка программирования Python для работы с данными, которая предоставляет множество функций для обработки и анализа структурированных данных. Некоторые из основных возможностей pandas включают в себя:\n",
    "\n",
    "1. Структуры данных: Pandas предоставляет две основные структуры данных - Series и DataFrame - для работы с одномерными и двумерными данными соответственно. Эти структуры данных позволяют легко обрабатывать и анализировать различные типы данных.\n",
    "\n",
    "2. Чтение и запись данных: Pandas обеспечивает возможность чтения и записи данных в различных форматах, включая CSV, Excel, SQL, JSON, HTML и другие.\n",
    "\n",
    "3. Индексация и выборка данных: Pandas позволяет выбирать и фильтровать данные с помощью различных методов индексации и срезов, а также выполнять группировку и агрегацию данных.\n",
    "\n",
    "4. Обработка данных: Pandas предоставляет функции для отсутствующих данных, таких как удаление, заполнение, агрегация или замена пропущенных значений.\n",
    "\n",
    "5. Объединение и слияние данных: Pandas позволяет объединять и сливать данные из различных источников, включая объединение по строкам и столбцам, а также соединение таблиц.\n",
    "\n",
    "6. Визуализация данных: Pandas обеспечивает возможность создания различных типов графиков и диаграмм для визуализации данных.\n",
    "\n",
    "7. Работа с временными рядами: Pandas предоставляет функциональность для работы с временными рядами, включая создание временных индексов, агрегацию и ресемплирование данных по времени.\n",
    "\n",
    "8. Работа с большими данными: Pandas поддерживает работу с большими наборами данных, включая возможность чтения и записи данных по частям, использование индексации и выборки для сокращения использования памяти и другие методы оптимизации работы с данными."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Структуры данных  <a class=\"anchor\" id=\"structures\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas предоставляет две основные структуры данных - Series и DataFrame.\n",
    "\n",
    "Series - это одномерный массив данных, который можно индексировать и доступ к элементам которого можно осуществлять по индексу. Он может быть разных типов (например, числа, строки, даты и т.д.), но все элементы должны быть одного типа данных. Series удобен для хранения и обработки временных рядов, рядов цен, статистических данных и т.д.\n",
    "\n",
    "DataFrame - это двумерная таблица данных, которая состоит из рядов и колонок. Каждая колонка в DataFrame может содержать данные разных типов (например, числа, строки, даты и т.д.). DataFrame удобен для хранения и обработки больших и сложных наборов данных, таких как таблицы баз данных, файлы Excel, CSV-файлы и т.д.\n",
    "\n",
    "Обе структуры данных Pandas позволяют осуществлять быстрый и удобный доступ к данным, фильтровать данные, выполнять арифметические операции над данными, агрегировать данные, а также визуализировать данные в различных форматах.\n",
    "\n",
    "Series и DataFrame также имеют множество методов и функций для обработки данных, например, для сортировки, фильтрации, замены, удаления и объединения данных. Эти функции и методы делают работу с данными в Pandas быстрой, удобной и эффективной."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Создание"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    10\n",
      "1    20\n",
      "2    30\n",
      "3    40\n",
      "4    50\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Создание Series из списка\n",
    "my_list = [10, 20, 30, 40, 50]\n",
    "s = pd.Series(my_list)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1\n",
      "1    2\n",
      "2    3\n",
      "3    4\n",
      "4    5\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Создание Series из массива NumPy\n",
    "import numpy as np\n",
    "arr = np.array([1, 2, 3, 4, 5])\n",
    "s = pd.Series(arr)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a    1\n",
      "b    2\n",
      "c    3\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Создание Series из словаря\n",
    "my_dict = {'a': 1, 'b': 2, 'c': 3}\n",
    "s = pd.Series(my_dict)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание списка списков\n",
    "data = [[10, 20, 30], [40, 50, 60], [70, 80, 90]]\n",
    "\n",
    "# Создание DataFrame из списка списков\n",
    "df = pd.DataFrame(data, columns=['A', 'B', 'C'])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание списка словарей\n",
    "data = [\n",
    "    {'name': 'John', 'age': 30},\n",
    "    {'name': 'Alice', 'age': 25},\n",
    "    {'name': 'Bob', 'age': 40}\n",
    "]\n",
    "\n",
    "# Создание DataFrame из списка словарей\n",
    "df = pd.DataFrame(data)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание словаря списков\n",
    "data = {'A': [10, 20, 30], 'B': [40, 50, 60], 'C': [70, 80, 90]}\n",
    "\n",
    "# Создание DataFrame из словаря списков\n",
    "df = pd.DataFrame(data)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Создание массива NumPy\n",
    "data = np.array([[10, 20, 30], [40, 50, 60], [70, 80, 90]])\n",
    "\n",
    "# Создание DataFrame из массива NumPy\n",
    "df = pd.DataFrame(data, columns=['A', 'B', 'C'])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Чтение и запись <a class=\"anchor\" id=\"read_write\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Загрузка CSV-файла в DataFrame\n",
    "# df = pd.read_csv('file.csv')\n",
    "\n",
    "# # Вывод содержимого DataFrame\n",
    "# print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Загрузка Excel-файла в DataFrame\n",
    "# df = pd.read_excel('file.xlsx')\n",
    "\n",
    "# # Вывод содержимого DataFrame\n",
    "# print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sqlite3\n",
    "\n",
    "# # Создание подключения к базе данных\n",
    "# conn = sqlite3.connect('database.db')\n",
    "\n",
    "# # Загрузка SQL-запроса в DataFrame\n",
    "# df = pd.read_sql_query('SELECT * FROM table', conn)\n",
    "\n",
    "# # Вывод содержимого DataFrame\n",
    "# print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Загрузка URL-адреса в DataFrame\n",
    "# df = pd.read_html('https://example.com')[0]\n",
    "\n",
    "# # Вывод содержимого DataFrame\n",
    "# print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Загрузка текстового файла в объект Series\n",
    "# s = pd.read_csv('file.txt', header=None, squeeze=True)\n",
    "\n",
    "# # Вывод содержимого Series\n",
    "# print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В Pandas есть несколько способов записи данных из объектов Series и DataFrame в файлы. Рассмотрим несколько примеров.\n",
    "В каждом примере мы записываем данные из объектов Series и DataFrame в различные форматы файлов. Каждый пример также показывает, как использовать различные параметры функций для управления процессом записи данных в файлы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание DataFrame\n",
    "data = {'name': ['John', 'Jane', 'Sam'],\n",
    "        'age': [25, 30, 35],\n",
    "        'city': ['New York', 'Paris', 'London']}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Запись DataFrame в CSV-файл\n",
    "df.to_csv('file.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Запись DataFrame в Excel-файл\n",
    "# df.to_excel('file.xlsx', index=False)\n",
    "# ModuleNotFoundError: No module named 'openpyxl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sqlite3\n",
    "\n",
    "# # Создание подключения к базе данных\n",
    "# conn = sqlite3.connect('database.db')\n",
    "\n",
    "# # Запись DataFrame в SQL-базу данных\n",
    "# df.to_sql('table', conn, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Запись DataFrame в формате JSON\n",
    "df.to_json('file.json', orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание объекта Series\n",
    "s = pd.Series([10, 20, 30])\n",
    "\n",
    "# Запись Series в текстовый файл\n",
    "s.to_csv('file.txt', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Индексация и выборка данных <a class=\"anchor\" id=\"indexing\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Создание объекта Series\n",
    "s = pd.Series([10, 20, 30, 40, 50])\n",
    "\n",
    "# Индексация по номеру элемента\n",
    "print(s[2])  # выводит 30\n",
    "\n",
    "# Индексация по метке элемента\n",
    "s = pd.Series([10, 20, 30, 40, 50], index=['a', 'b', 'c', 'd', 'e'])\n",
    "print(s[\"a\"])  # выводит 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание DataFrame\n",
    "data = {'name': ['John', 'Jane', 'Sam'],\n",
    "        'age': [25, 30, 35],\n",
    "        'city': ['New York', 'Paris', 'London']}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Индексация по метке строки\n",
    "print(df.loc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Индексация по названию столбца\n",
    "print(df['name'])  # выводит столбец 'name'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Индексация по номеру строки и столбца\n",
    "print(df.iloc[1, 2])  # выводит 'Paris'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Индексация по метке строки и названию столбца\n",
    "print(df.loc[1, 'city'])  # выводит 'Paris'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Индексация по условию\n",
    "print(df[df['age'] >= 30])  # выводит строки с возрастом больше 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание DataFrame\n",
    "data = {'name': ['John', 'Jane', 'Sam', 'Alice', 'Bob'],\n",
    "        'age': [25, 30, 35, 40, 45],\n",
    "        'city': ['New York', 'Paris', 'London', 'Paris', 'London']}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Индексация DataFrame по условию с использованием оператора &\n",
    "print(df[(df['age'] > 30) & (df['city'] == 'Paris')]) # выводит строки с возрастом больше 30 и городом Paris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Индексация DataFrame по условию с использованием оператора |\n",
    "print(df[(df['age'] > 30) | (df['city'] == 'Paris')]) # выводит строки с возрастом больше 30 или городом Paris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Индексация DataFrame по условию с использованием метода query()\n",
    "print(df.query(\"age > 30 and city == 'Paris'\")) # выводит строки с возрастом больше 30 и городом Paris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Индексация DataFrame по условию с использованием метода loc[]\n",
    "print(df.loc[(df['age'] > 30) & (df['city'] == 'Paris')]) # выводит строки с возрастом больше 30 и городом Paris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Слайсинг DataFrame по индексу строк и столбцов с использованием метода loc[]\n",
    "print(df.loc[1:3, 'name':'age']) # выводит строки 1-3 и столбцы name и age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Слайсинг DataFrame по позиции строк и столбцов с использованием метода iloc[]\n",
    "print(df.iloc[1:3, 0:2]) # выводит строки 1-2 и столбцы 0-1 (name и age)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обработка данных <a class=\"anchor\" id=\"processing\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Замена значений в столбце на другие значения\n",
    "\n",
    "Можно использовать метод .replace(), передав в него словарь, где ключи - значения, \n",
    "которые нужно заменить, а значения - значения, на которые нужно заменить.\n",
    "Например, заменим значения \"male\" на \"M\" и \"female\" на \"F\" в столбце gender:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# создаем DataFrame\n",
    "df = pd.DataFrame({'name': ['John', 'Mary', 'Peter'],\n",
    "                   'gender': ['male', 'female', 'male']})\n",
    "# заменяем значения в столбце gender\n",
    "df['gender'] = df['gender'].replace({'male': 'M', 'female': 'F'})\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Преобразование типа данных столбца\n",
    "Можно использовать метод .astype(), передав в него новый тип данных.\n",
    "Например, преобразуем столбец age из типа object в тип int:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# создаем DataFrame\n",
    "df = pd.DataFrame({'name': ['John', 'Mary', 'Peter'],\n",
    "                   'age': ['25', '30', '35']})\n",
    "# преобразуем тип данных столбца age\n",
    "df['age'] = df['age'].astype(int)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Объединение значений столбцов\n",
    "\n",
    "Можно использовать метод .apply(), передав в него функцию, которая будет объединять значения столбцов.\n",
    "Например, объединим значения столбцов first_name и last_name в новый столбец full_name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# создаем DataFrame\n",
    "df = pd.DataFrame({'first_name': ['John', 'Mary', 'Peter'],\n",
    "                   'last_name': ['Doe', 'Smith', 'Johnson']})\n",
    "# объединяем значения столбцов first_name и last_name\n",
    "df['full_name'] = df.apply(lambda row: row['first_name'] + ' ' + row['last_name'], axis=1)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Удаление строк или столбцов\n",
    "\n",
    "Можно использовать метод .drop(), передав в него индексы строк или столбцов, которые нужно удалить, а также параметр axis=0 для удаления строк или axis=1 для удаления столбцов.\n",
    "Например, удалим столбец age:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# создаем DataFrame\n",
    "df = pd.DataFrame({'name': ['John', 'Mary', 'Peter'],\n",
    "                   'age': ['25', '30', '35']})\n",
    "# удаляем столбец age\n",
    "df = df.drop('age', axis=1)\n",
    "df = df.drop(0, axis=0)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Группировка и агрегация данных\n",
    "\n",
    "Можно использовать метод .groupby(), чтобы сгруппировать данные по значениям столбца или нескольких столбцов, а затем применить к группам агрегационную функцию, например, сумму, среднее значение, максимальное значение и т.д.\n",
    "Например, посчитаем средний возраст для каждого пола в DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# создаем DataFrame\n",
    "df = pd.DataFrame({'name': ['John', 'Mary', 'Peter', 'Mike', 'Sarah'],\n",
    "                   'gender': ['M', 'F', 'M', 'M', 'F'],\n",
    "                   'age': [25, 30, 35, 40, 45]})\n",
    "# считаем средний возраст для каждого пола\n",
    "mean_age_by_gender = df.groupby('gender')['age'].mean()\n",
    "print(mean_age_by_gender)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Фильтрация данных по условию\n",
    "\n",
    "Можно использовать условный оператор и метод .loc[], чтобы выбрать строки, удовлетворяющие заданному условию.\n",
    "Например, выберем только те строки, в которых возраст больше 30:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# создаем DataFrame\n",
    "df = pd.DataFrame({'name': ['John', 'Mary', 'Peter', 'Mike', 'Sarah'],\n",
    "                   'age': [25, 30, 35, 40, 45]})\n",
    "# выбираем только строки, у которых возраст больше 30\n",
    "df_filtered = df.loc[df['age'] > 30]\n",
    "print(df_filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Объединение и слияние данных <a class=\"anchor\" id=\"merging\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Слияние данных - это процесс соединения двух или более наборов данных на основе общих признаков. В pandas это делается с помощью метода merge(). Он принимает на вход два DataFrame и объединяет их по заданным колонкам."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# создаем первый DataFrame\n",
    "df1 = pd.DataFrame({'key': ['A', 'B', 'C', 'D'],\n",
    "                    'value': [1, 2, 3, 4]})\n",
    "# создаем второй DataFrame\n",
    "df2 = pd.DataFrame({'key': ['B', 'D', 'E', 'F'],\n",
    "                    'value': [5, 6, 7, 8]})\n",
    "# объединяем по колонке 'key'\n",
    "merged_df = pd.merge(df1, df2, on='key')\n",
    "print(merged_df)\n",
    "\n",
    "# В результате мы получили новый DataFrame, в котором объединены два исходных DataFrame по значению колонки 'key'. \n",
    "# В данном случае в объединенном DataFrame остались только строки, где значение 'key' было общим для обоих \n",
    "# DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Объединение данных - это процесс соединения двух или более наборов данных по вертикали (добавление новых строк)\n",
    "или горизонтали (добавление новых колонок). В pandas это делается с помощью методов concat() и join()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# создаем первый DataFrame\n",
    "df1 = pd.DataFrame({'key': ['A', 'B', 'C', 'D'],\n",
    "                    'value': [1, 2, 3, 4]})\n",
    "# создаем второй DataFrame\n",
    "df2 = pd.DataFrame({'key': ['E', 'F', 'G', 'H'],\n",
    "                    'value': [5, 6, 7, 8]})\n",
    "# объединяем по вертикали\n",
    "concat_df = pd.concat([df1, df2])\n",
    "print(concat_df)\n",
    "\n",
    "# В данном примере мы объединили два DataFrame по вертикали с помощью метода concat(). \n",
    "# В результате мы получили новый DataFrame, состоящий из строк обоих исходных DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С помощью метода join() можно объединять DataFrame по колонкам, а не по строкам. Он принимает на вход два DataFrame и объединяет их по заданным колонкам."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# создаем первый DataFrame\n",
    "df1 = pd.DataFrame({'key': ['A', 'B', 'C', 'D'],\n",
    "                    'value1': [1, 2, 3, 4]})\n",
    "# создаем второй DataFrame\n",
    "df2 = pd.DataFrame({'key': ['B', 'D', 'E', 'F'],\n",
    "                    'value2': [5, 6, 7, 8]})\n",
    "# объединяем по колонке 'key'\n",
    "joined_df = df1.set_index('key').join(df2.set_index('key'))\n",
    "print(joined_df)\n",
    "\n",
    "# В данном примере мы объединили два DataFrame по колонке 'key' с помощью метода join(). \n",
    "# В результате мы получили новый DataFrame, в котором значения из обоих исходных DataFrame \n",
    "# объединены по значениям колонки 'key'. Если значение отсутствует в одном из DataFrame, \n",
    "# то в объединенном DataFrame оно будет NaN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Визуализация данных <a class=\"anchor\" id=\"visualization\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Создание DataFrame\n",
    "data = {'name': ['John', 'Jane', 'Sam', 'Alice', 'Bob'],\n",
    "        'age': [25, 30, 35, 40, 45],\n",
    "        'city': ['New York', 'Paris', 'London', 'Paris', 'London']}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Отображение диаграммы разброса числовых данных DataFrame\n",
    "df.plot.scatter(x='age', y='name')\n",
    "plt.title('Диаграмма разброса возраста и имени')\n",
    "plt.xlabel('Возраст')\n",
    "plt.ylabel('Имя')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание DataFrame с категориальными данными\n",
    "data = {'city': ['New York', 'Paris', 'London'],\n",
    "        'count': [10, 15, 12]}\n",
    "df2 = pd.DataFrame(data)\n",
    "\n",
    "# Отображение столбчатой диаграммы категориальных данных DataFrame\n",
    "df2.plot.bar(x='city', y='count', rot=0)\n",
    "plt.title('Диаграмма количества людей в городах')\n",
    "plt.xlabel('Город')\n",
    "plt.ylabel('Количество людей')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Работа с временными рядами <a class=\"anchor\" id=\"time_series\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание временного ряда с шагом в дни\n",
    "dates = pd.date_range('20220101', periods=365)\n",
    "\n",
    "# Создание DataFrame с временным индексом\n",
    "df = pd.DataFrame({'value': range(365)}, index=dates)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Срез по диапазону дат\n",
    "print(df['20220301':'20220501'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Агрегирование данных по дням\n",
    "# print(df.resample('D').sum())\n",
    "\n",
    "# # Агрегирование данных по неделям\n",
    "# print(df.resample('W').sum())\n",
    "\n",
    "# Агрегирование данных по месяцам\n",
    "print(df.resample('M').sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для вычисления скользящего среднего в pandas можно использовать метод rolling(). Например, чтобы вычислить скользящее среднее с окном размером 3 для столбца \"value\" в DataFrame \"df\", можно использовать следующий код:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['rolling_mean'] = df['value'].rolling(window=3).mean()\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метод rolling() также позволяет задавать другие параметры, такие как минимальное количество наблюдений для вычисления среднего значения (min_periods) и тип окна (window). Например, чтобы использовать взвешенное скользящее среднее с экспоненциальным затуханием, можно задать параметр window следующим образом:\n",
    "```python\n",
    "df['rolling_mean1'] = df['column_name'].rolling(window='expanding').mean()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Работа с большими файлами <a class=\"anchor\" id=\"big_files\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas предоставляет множество инструментов для работы с большими файлами данных, которые могут не поместиться в оперативную память компьютера.\n",
    "\n",
    "Некоторые из этих инструментов:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Использование параметра chunksize при чтении файла с помощью метода read_csv. Этот параметр позволяет читать файл по кускам определенного размера и выполнять операции с каждым куском данных отдельно. Например, следующий код читает файл \"large_data.csv\" по кускам в 1000 строк и суммирует значения столбца \"value\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunksize = 1000\n",
    "sum_value = 0\n",
    "\n",
    "# for chunk in pd.read_csv(\"large_data.csv\", chunksize=chunksize):\n",
    "#     sum_value += chunk[\"value\"].sum()\n",
    "\n",
    "# print(\"Total sum of values: \", sum_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Использование функции to_csv для записи данных по частям. В этом случае можно использовать параметры chunksize и mode. Например, следующий код сохраняет файл \"large_data.csv\" по частям в 1000 строк каждая:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunksize = 1000\n",
    "i = 0\n",
    "\n",
    "# for chunk in pd.read_csv(\"large_data.csv\", chunksize=chunksize):\n",
    "#     chunk.to_csv(\"large_data_part{}.csv\".format(i), index=False, mode=\"a\")\n",
    "#     i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Использование модуля Dask. Dask - это библиотека, которая позволяет обрабатывать большие наборы данных, не помещающиеся в оперативную память, путем распределения задач на несколько вычислительных узлов. Dask имеет сходный с Pandas API, поэтому переход на Dask может быть довольно простым. Например, следующий код считывает файл \"large_data.csv\" с помощью Dask и выводит сумму значений столбца \"value\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dask.dataframe as dd\n",
    "\n",
    "# df = dd.read_csv(\"large_data.csv\")\n",
    "# sum_value = df[\"value\"].sum().compute()\n",
    "\n",
    "# print(\"Total sum of values: \", sum_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Использование модуля Vaex. Vaex - это библиотека для работы с большими наборами данных, которая использует ленивую загрузку и индексирование, чтобы обеспечить быстрое выполнение запросов к данным. Vaex также имеет сходный с Pandas API, но работает намного быстрее для больших наборов данных. Например, следующий код считывает файл \"large_data.csv\" с помощью Vaex и выводит сумму значений столбца \"value\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import vaex\n",
    "\n",
    "# df = vaex.open(\"large_data.csv\")\n",
    "# sum_value = df.sum(\"value\")\n",
    "\n",
    "# print(\"Total sum of values: \", sum_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Примеры с реальными данными <a class=\"anchor\" id=\"real_examples\"></a>\n",
    "\n",
    "https://www.kaggle.com/datasets?search=sales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN  <a class=\"anchor\" id=\"KNN\"></a>\n",
    "\n",
    "Алгоритм k-ближайших соседей (k-nearest neighbors, KNN) является простым алгоритмом машинного обучения, который используется как для задач классификации, так и для задач регрессии. Он основывается на принципе ближайших соседей, где объекты данных классифицируются или предсказываются на основе ближайших к ним соседей.\n",
    "\n",
    "Для задачи классификации, алгоритм KNN присваивает объекту класс на основе большинства (голосования) классов его k ближайших соседей. Например, если k > 4 и объект имеет k-2 ближайших соседей, принадлежащих к классу \"1\", и только 2 соседей принадлежат к классу \"0\", то объект будет отнесен к классу \"1\".\n",
    "\n",
    "Для задачи регрессии, алгоритм KNN предсказывает числовое значение для объекта на основе среднего (или медианы) значений целевой переменной его k ближайших соседей. Например, если объект имеет k ближайших соседей с целевыми значениями [2, 3, 4, 5, 6], то предсказанное значение будет равно среднему значению 4.\n",
    "\n",
    "Основной параметр алгоритма KNN - это k, который определяет количество ближайших соседей, которые будут участвовать в классификации или предсказании. Выбор оптимального значения k зависит от данных и требует экспериментирования.\n",
    "\n",
    "Алгоритм KNN прост в реализации и понимании, но может быть вычислительно интенсивным для больших наборов данных. Он также может быть чувствителен к масштабированию признаков и может требовать предварительной обработки данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Отладчик <a class=\"anchor\" id=\"debugger\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В Python есть встроенный дебаггер pdb (Python debugger), который позволяет отслеживать выполнение кода, исследовать значения переменных, исправлять ошибки и многое другое. Вот некоторые основные команды, которые могут быть полезны при работе с pdb:\n",
    "\n",
    "1. `pdb.set_trace()`: это команда, которую вы можете вставить в свой код там, где вы хотите начать отслеживать выполнение. Когда интерпретатор Python достигает этой команды, он останавливается и переходит в интерактивный режим pdb.\n",
    "\n",
    "2. `n` (или `next`): это команда, которая переходит к следующей строке кода. Если строка содержит вызов функции, то pdb просто перескочит ее, не заходя внутрь функции.\n",
    "\n",
    "3. `s` (или `step`): это команда, которая переходит к следующей строке кода, но если строка содержит вызов функции, pdb перейдет внутрь функции.\n",
    "\n",
    "4. `c` (или `continue`): это команда, которая продолжает выполнение кода до тех пор, пока не достигнет конца программы или не встретит другой `pdb.set_trace()`.\n",
    "\n",
    "5. `p <expression>`: это команда, которая выводит значение выражения.\n",
    "\n",
    "6. `l` (или `list`): это команда, которая выводит список строк кода вокруг текущей позиции.\n",
    "\n",
    "7. `q` (или `quit`): это команда, которая завершает выполнение программы.\n",
    "\n",
    "Например, предположим, что у нас есть следующий код, в котором мы хотим отследить выполнение:\n",
    "\n",
    "```\n",
    "def sum(a, b):\n",
    "    return a + b\n",
    "\n",
    "def multiply(a, b):\n",
    "    return a * b\n",
    "\n",
    "def calculate(a, b):\n",
    "    pdb.set_trace()\n",
    "    s = sum(a, b)\n",
    "    m = multiply(a, b)\n",
    "    return s, m\n",
    "\n",
    "result = calculate(2, 3)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "Когда интерпретатор Python достигнет `pdb.set_trace()`, он перейдет в интерактивный режим pdb. Мы можем использовать различные команды pdb, чтобы отслеживать выполнение кода и исследовать значения переменных. Например, мы можем использовать команды `n` и `s`, чтобы перейти к следующей строке кода или перейти внутрь функции. Мы также можем использовать команду `p` для вывода значений переменных. Когда мы закончим отслеживание выполнения, мы можем использовать команду `q`, чтобы выйти из pdb и завершить выполнение программы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для включения режима отладки в Jupyter необходимо выполнить следующие шаги:\n",
    "\n",
    "1. Импортируйте библиотеку pdb:\n",
    "\n",
    "```\n",
    "import pdb\n",
    "```\n",
    "\n",
    "2. Включите режим отладки с помощью магической команды `%pdb`:\n",
    "\n",
    "```\n",
    "%pdb on\n",
    "```\n",
    "\n",
    "3. Запустите свой код в ячейке Jupyter.\n",
    "\n",
    "4. Если в процессе выполнения кода возникнет исключение, то Jupyter автоматически включит pdb.\n",
    "\n",
    "После того, как pdb включен, вы можете использовать команды pdb, чтобы отслеживать выполнение кода и исследовать значения переменных, как описано выше.\n",
    "\n",
    "Чтобы выключить режим отладки, можно использовать магическую команду `%pdb off`. Если вы хотите включить pdb только в определенных местах вашего кода, вы можете использовать функцию `pdb.set_trace()` вместо магической команды `%pdb`.\n",
    "\n",
    "Для того чтобы показать список переменных и их текущие значения в pdb, вы можете использовать команду `pp locals()` или `pp <dictionary>`.\n",
    "\n",
    "Команда `locals()` возвращает словарь локальных переменных, доступных в текущей области видимости. Команда `pp` используется для красивого вывода значений словаря.\n",
    "\n",
    "Например, предположим, что у нас есть следующий код:\n",
    "\n",
    "```\n",
    "def calculate(a, b):\n",
    "    c = a + b\n",
    "    d = a * b\n",
    "    pdb.set_trace()\n",
    "    return c, d\n",
    "\n",
    "result = calculate(2, 3)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "Когда интерпретатор Python достигнет `pdb.set_trace()`, мы можем использовать команду `pp locals()` для вывода списка локальных переменных и их текущих значений:\n",
    "\n",
    "```\n",
    "(Pdb) pp locals()\n",
    "{'a': 2, 'b': 3, 'c': 5, 'd': 6}\n",
    "```\n",
    "\n",
    "В этом примере `locals()` возвращает словарь с ключами `'a'`, `'b'`, `'c'` и `'d'`, которые представляют значения аргументов функции `calculate` и локальных переменных `c` и `d`. Команда `pp` выводит этот словарь в красивом формате.\n",
    "\n",
    "Вы также можете использовать команду `pp <dictionary>` для вывода значений любого словаря. Например, если у вас есть словарь `my_dict`, вы можете напечатать его значения с помощью команды `pp my_dict`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pdb\n",
    "# def sum(a, b):\n",
    "#     return a + b\n",
    "\n",
    "# def multiply(a, b):\n",
    "#     return a * b\n",
    "\n",
    "# def calculate(a, b):\n",
    "#     pdb.set_trace()\n",
    "#     s = sum(a, b)\n",
    "#     m = multiply(a, b)\n",
    "#     return s, m\n",
    "\n",
    "# result = calculate(2, 3)\n",
    "# print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN для регрессии  <a class=\"anchor\" id=\"KNN_regression\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class KNNRegressor:\n",
    "    def __init__(self, k):\n",
    "        self.k = k\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.X_train = X  # Запоминаем обучающие данные\n",
    "        self.y_train = y  # Запоминаем метки классов\n",
    "\n",
    "    def euclidean_distance(self, x1, x2):\n",
    "        return np.sqrt(np.sum((x1 - x2)**2))  # Вычисляем евклидово расстояние между двумя точками\n",
    "\n",
    "    def predict(self, X):\n",
    "        y_pred = []  # Список для хранения предсказанных значений\n",
    "\n",
    "        for x in X:\n",
    "            distances = [self.euclidean_distance(x, x_train) for x_train in self.X_train]  # Вычисляем расстояния до всех точек в обучающих данных\n",
    "            k_indices = np.argsort(distances)[:self.k]  # Получаем индексы k ближайших соседей\n",
    "            k_nearest_targets = [self.y_train[i] for i in k_indices]  # Получаем значения целевых переменных ближайших соседей\n",
    "            y_pred.append(np.mean(k_nearest_targets))  # Добавляем предсказанное значение в список\n",
    "\n",
    "        return np.array(y_pred)  # Преобразуем список в массив и возвращаем его\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание экземпляра класса KNN\n",
    "knn = KNNRegressor(k=3)\n",
    "\n",
    "# Обучение модели\n",
    "X_train = np.array([[1, 2], [3, 4], [5, 6]])\n",
    "y_train = np.array([0, 0.5, 1])\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Новые данные для классификации\n",
    "X_test = np.array([[2, 3], [4, 5]])\n",
    "\n",
    "# Предсказание меток классов\n",
    "y_pred = knn.predict(X_test)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN для классификации  <a class=\"anchor\" id=\"KNN_classification\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNNClassifier:\n",
    "    def __init__(self, k):\n",
    "        self.k = k\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.X_train = X  # Запоминаем обучающие данные\n",
    "        self.y_train = y  # Запоминаем метки классов\n",
    "\n",
    "    def euclidean_distance(self, x1, x2):\n",
    "        return np.sqrt(np.sum((x1 - x2)**2))  # Вычисляем евклидово расстояние между двумя точками\n",
    "\n",
    "    def predict(self, X):\n",
    "        y_pred = []  # Список для хранения предсказанных меток классов\n",
    "\n",
    "        for x in X:\n",
    "            distances = [self.euclidean_distance(x, x_train) for x_train in self.X_train]  # Вычисляем расстояния до всех точек в обучающих данных\n",
    "            k_indices = np.argsort(distances)[:self.k]  # Получаем индексы k ближайших соседей\n",
    "            k_nearest_labels = [self.y_train[i] for i in k_indices]  # Получаем метки классов k ближайших соседей\n",
    "            most_common = np.argmax(np.bincount(k_nearest_labels))  # Находим наиболее часто встречающуюся метку класса среди соседей\n",
    "            y_pred.append(most_common)  # Добавляем предсказанную метку класса в список\n",
    "\n",
    "        return np.array(y_pred)  # Преобразуем список в массив и возвращаем его\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание экземпляра класса KNN\n",
    "knn = KNNClassifier(k=3)\n",
    "\n",
    "# Обучение модели\n",
    "X_train = np.array([[1, 2], [3, 4], [5, 6]])\n",
    "y_train = np.array([0, 0, 1])\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Новые данные для классификации\n",
    "X_test = np.array([[2, 3], [4, 5]])\n",
    "\n",
    "# Предсказание меток классов\n",
    "y_pred = knn.predict(X_test)\n",
    "print(y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
