<div class="main-block">
<h1>1/7 О модуле</h1>
<p>Добро пожаловать в модуль «Диффузионные модели. Часть 1».</p>
<p>После изучения этого модуля вы будете:</p>
<ul class="list">
<li>Знать теорию диффузионных моделей и реализовывать их с помощью библиотеки pytorch.</li>
<li>Уметь решать проблемы обучения и инференса диффузионных моделей.</li>
<li>Уметь обучать диффузионную модель на выбранном датасете, с помощью библиотеки diffusers.</li>
</ul>
<h2>Содержание модуля</h2>
<p class="h3">Контент на учебной платформе</p>
<p><strong>Занятие 1.</strong> Что такое генеративные модели</p>
<ul class="list">
<li>Генеративные &amp; Дискриминативные модели.</li>
<li>Виды генеративных моделей: VAE, Flow-based, GAN.</li>
<li>Автоэнкодеры, скрытое пространство.</li>
<li>VAE.</li>
</ul>
<p><strong>Занятие 2.</strong> Диффузионные модели</p>
<ul class="list">

<li>Диффузия в физике.</li>
<li>Математика диффузионных моделей.</li>
<li>Как происходит обучение.</li>
<li>Архитектура диффузионной модели.</li>
</ul>
<p><strong>Занятие 3.</strong> Модификации диффузионных моделей</p>
<ul class="list">
<li>Модификации с noise scheduler.</li>
<li>Classifier guidance, classifier-free guidance объединил в conditional guidance.</li>
<li>Ускорение сэмплирование диффузионных моделей.</li>
</ul>
<h3>Семинарские занятия</h3>
<p><strong>Семинар №1.</strong> Практическая реализация диффузионной модели</p>
<ul class="list">
<li>Реализация и разбор архитектуры стандартных диффузионных моделей на Pytorch.</li>
</ul>
<p><strong>Семинар №2.</strong> Работа с библиотекой Hugging Face</p>
<ul class="list">
<li>Работа с основной библиотекой по диффузии diffusers и ее применение для обучения диффузионных моделей.</li>
</ul>
<h2>Оцениваемые задания модуля</h2>
<p><strong>Домашнее задание №1. </strong>Реализация модели latent diffusion</p>
<p>Вам предстоит реализовать модель латентной диффузии, а также внести в неё модификации.</p>
</div>

# 2/7   1. Что такое генеративные модели



<h2>Цель занятия</h2>
<p>Ознакомиться с различными видами генеративных моделей.</p>
<h2>План занятия</h2>
<ol class="num-list">
<li>Генеративные и дискриминативные модели.</li>
<li>Виды генеративных моделей.</li>
<li>Скрытое пространство и автоэнкодеры.</li>
<li>Модель VAE.</li>
</ol>
<h2>Генеративные и дискриминативные модели</h2>
<p>Когда говорят о генеративных моделях, часто упоминают и дискриминативные. Генеративные модели генерируют новые данные.</p>
<p>Дискриминативные модели различают разные виды экземпляров данных.</p>
<p>Генеративная модель может генерировать новые фотографии животных, которые выглядят как настоящие животные, а дискриминативная модель может отличить собаку от кошки.</p>
<figure class="img"><img src="http://lms-cdn.skillfactory.ru/assets/courseware/v1/aacf9cb2545b254acf9edd98485b92a1/asset-v1:SkillFactory+MFTIDSLIGHT+2022_DEC+type@asset+block/mftidslight_ml_m1_01.png" alt="" width="500">
<p class="grey-text">Источник: <a target="blank" href="https://www.baeldung.com/wp-content/uploads/sites/4/2021/04/gen_vs_disc-versus-1.png">Generative vs discriminative algorithms</a></p>
</figure>

Если говорить более формально, пусть даны набор данных $X$ и меток $Y$:

- Генеративные модели определяют совместную вероятность $p(Y,X)$ или просто $p(X)$, если меток нет.

- Дискриминативные модели определяют условную вероятность $p(Y|X)$.

<p class="term"><strong>Дискриминативные модели </strong>— это тип моделей машинного обучения, который используется для прогнозирования целевой переменной на основе набора входных признаков. Эти модели изучают взаимосвязь между входными объектами и целевой переменной, а затем используют эту взаимосвязь для прогнозирования. Дискриминативные модели часто используются для задач классификации, где цель — предсказать, к какому классу принадлежит экземпляр. Например, такие модели могут предсказать, является ли электронное письмо спамом.</p>
<p>В целом дискриминационные модели лучше подходят для задач классификации, тогда как генеративные модели — для оценки плотности и задач обучения без учителя. На рисунке ниже показано, как дискриминантная модель работает в случае классификации. Изображение помечается как 1, если оно было нарисовано Ван Гогом, и 0, если нет. Изображение передается в дискриминационную модель и прогнозируется вероятность.</p>
<figure class="img"><img src="http://lms-cdn.skillfactory.ru/assets/courseware/v1/efcb7fd4e87e6d4ae74e16569c73f4a1/asset-v1:SkillFactory+MFTIDSLIGHT+2022_DEC+type@asset+block/mftidslight_ml_m1_02.png" alt="" width="800">
<p class="grey-text">Источник: <a target="blank" href="https://vitalflux.com/wp-content/uploads/2023/03/discriminative-modeling-example-640x274.png">Generative vs discriminative models: examples</a></p>
</figure>
<p>Дискриминативные модели работают, находя границу решения, которая может наилучшим образом разделить точки обучающих данных на соответствующие классы. Они изучают взаимосвязь между входными объектами и целевыми метками. Другими словами, они учатся сопоставлять входные данные с правильной меткой. Как только граница будет найдена, модель можно использовать, чтобы прогнозировать метки класса для новых данных.</p>
<p>Существуют различные типы дискриминативных моделей — логистическая регрессия, метод опорных векторов, деревья решений, случайный лес и т. д. (подробно каждый из этих типов мы разобрали на курсе «Математика и алгоритмы машинного обучения»). Каждый тип модели имеет свои сильные и слабые стороны. Логистическая регрессия обычно используется для задач бинарной классификации, тогда как методы опорных векторов лучше подходят для более сложных задач. Деревья решений можно использовать как для задач классификации, так и для задач регрессии. Таким образом, важно понимать различные типы дискриминационных моделей, чтобы выбрать правильную для поставленной задачи.</p>
<p class="term"><strong>Генеративные модели </strong>— это тип моделей машинного обучения, который используется для создания новых выборок данных на основе обучающего набора. Например, генеративную модель можно обучить на наборе данных изображений кошек, а затем использовать ее для создания новых изображений кошек. Или можно использовать генеративную модель, обученную на изображениях лиц для создания новых изображений лиц, которые выглядят реалистично, но не обязательно идентичны обучающим изображениям.</p>
<p>На рисунке ниже показано, как работает генеративное моделирование. Набор обучающих данных состоит из разных изображений лошадей. Модель обучена фиксировать сложные отношения между различными пикселями на изображениях лошадей. Образец («Наблюдение») из обучающих данных используется для создания различных новых изображений лошадей, показанных в сгенерированных образцах.</p>
<figure class="img"><img src="http://lms-cdn.skillfactory.ru/assets/courseware/v1/9f36109dff36704111cd31a2c9365d1a/asset-v1:SkillFactory+MFTIDSLIGHT+2022_DEC+type@asset+block/mftidslight_ml_m1_03.png" alt="" width="">
<p class="grey-text">Источник: <a target="blank" href="https://vitalflux.com/wp-content/uploads/2023/03/generative-modeling-example-640x282.png">Generative vs discriminative models: examples</a></p>
</figure>
<p>Генеративные модели должны генерировать различные варианты желаемых результатов. По этой причине они должны быть вероятностными по своей природе, а не детерминированными. Генеративная модель должна иметь случайную часть, которая по-разному влияет на каждый результат.</p>
<p><strong>Преимущества использования генеративных моделей:</strong></p>
<ul class="list">
<li><strong>Помогают понять сложные наборы данных. </strong>Например, если мы хотим узнать, как ведет себя определенный вид птиц, мы можем использовать генеративную модель для получения этих данных. Это поможет нам узнать больше о видах и о том, как они взаимодействуют с окружающей средой.</li>
<li><strong>Помогают создавать новые данные. </strong>Например, мы можем использовать генеративную модель, если нужно создать набор данных для целей тестирования. Это сэкономит время и усилия.</li>
<li><strong>Улучшают алгоритмы машинного обучения. </strong>Используя генеративную модель для генерации данных, мы можем более реалистично обучать наши алгоритмы машинного обучения. Это приводит к повышению производительности и более точным результатам.</li>
</ul>
<p class="h2">Виды генеративных моделей</p>
<p>Четыре хорошо известные модели генерации изображений, основанные на глубоком обучении:</p>
<ol class="num-list">
<li>Вариационные автоэнкодеры (VAE).</li>
<li>Flow-based models.</li>
<li>Генеративные состязательные сети (GAN).</li>
<li>Диффузионные модели (Diffusion models).</li>
</ol>
<figure class="img"><img src="http://lms-cdn.skillfactory.ru/assets/courseware/v1/522aaecbab4d6da0060e8bb47df96d2e/asset-v1:SkillFactory+MFTIDSLIGHT+2022_DEC+type@asset+block/mftidslight_ml_m1_04.png" alt="" width="">
<p class="grey-text">Источник: <a target="blank" href="https://lilianweng.github.io/posts/2021-07-11-diffusion-models/generative-overview.png">Lilian Weng’ blog</a></p>
</figure>
<p>Эти модели добились больших успехов в создании высококачественных изображений, но у каждой из них есть свои ограничения.</p>
<div class="overflow-table">
<table style="width: 1100px;">
<tbody>
<tr>
<th width="100px"></th>
<th width="250px"><strong>VAE</strong></th>
<th width="250px"><strong>Flow-base</strong></th>
<th width="250px"><strong>GAN</strong></th>
<th width="250px"><strong>Диффузионные модели</strong></th>
</tr>
<tr>
<td><strong>Плюсы</strong></td>
<td>
<ul class="list">
<li>Быстрое сэмплирование</li>
<li>Генерация разнообразных образцов</li>
</ul>
</td>
<td>
<ul class="list">
<li>Быстрое сэмплирование</li>
<li>Генерация разнообразных образцов</li>
</ul>
</td>
<td>
<ul class="list">
<li>Быстрое сэмплирование</li>
<li>Высокое качество генерации</li>
</ul>
</td>
<td>
<ul class="list">
<li>Высокое качество генерации</li>
<li>Генерация разнообразных образцов</li>
</ul>
</td>
</tr>
<tr>
<td><strong>Минусы</strong></td>
<td>
<ul class="list">
<li>Низкое качество генерации</li>
</ul>
</td>
<td>
<ul class="list">
<li>Требуется специализированная архитектура</li>
<li>Низкое качество генерации</li>
</ul>
</td>
<td>
<ul class="list">
<li>Нестабильное обучение</li>
<li>Низкое разнообразие генерации (mode collapse)</li>
</ul>
</td>
<td>
<ul class="list">
<li>Медленное сэмплирование</li>
</ul>
</td>
</tr>
</tbody>
</table>
</div>
<h2>Скрытое пространство и автоэнкодеры</h2>
<p>Прежде чем поговорить о VAE (Variational autoencoder), вспомним про скрытое пространство и автоэнкодеры.</p>
<p class="term"><strong>Латентное (скрытое) пространство </strong>— это некоторое лежащее в основе «скрытое» представление для данного распределения необработанных данных. Чтобы лучше понять, рассмотрим простой пример.</p>

Представьте, что исходные точки данных $A \epsilon \mathbb{R}^{n \times m}$. Они с шумом генерируются с помощью линейного преобразования из некоторого меньшего измерения $\mathbf{z} \epsilon \mathbb{R}^{m} (m<n)$. В частности, $x$ генерируется как $\mathbf{x}=A\mathbf{z}+ \upsilon$, где $u$ — $n$-мерный независимый одинаково распределенный гауссовский шум, а $A \epsilon \mathbb{R}^{n \times m}$.

Как правило, мы видим только необработанные данные $\mathbf{x}$. Мы не получаем доступа к $\mathbf{z}$, поэтому его называют латентным или скрытым представлением данных. Однако мы хотим получить доступ к $\mathbf{z}$, потому что это более фундаментальное и сжатое представление данных. Кроме того, это скрытое представление может быть более полезным для многих других алгоритмов.</p>
Конкретная установка, в которой необработанные данные представляют линейное преобразование скрытого пространства, — это именно то, для чего предназначен классический алгоритм PCA (подробнее про PCA можно почитать на $\mathbf{z}$-представление из приведенного выше примера. Это здорово, но что если скрытое представление имело бы более сложную нелинейную связь с необработанными данными?</p>
<p>Например, на рисунке ниже показаны виды высокоуровневой информации, которую может кодировать более сложное скрытое пространство. В этом случае PCA не сможет этого сделать. Вместо него можно использовать автоэнкодер — он находит более абстрактное скрытое пространство.</p>
<p>Скрытое пространство не обязательно должно быть непрерывным векторным пространством. Вместо этого оно может быть дискретным набором переменных. Упрощенный пример скрытого пространства изображения кот/собака:</p>
<figure class="img"><img src="http://lms-cdn.skillfactory.ru/assets/courseware/v1/fe8ee8ecc067c310ef30ea188336b324/asset-v1:SkillFactory+MFTIDSLIGHT+2022_DEC+type@asset+block/mftidslight_ml_m1_05.png" alt="" width="">
<p class="grey-text">Источник: <a target="blank" href="https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdb8a9438-cdeb-43ef-aa9e-fe7312e9a664_1336x1100.png">ML@B blog</a></p>
</figure>
<p class="term"><strong>Автоэнкодер</strong> — это метод обучения без учителя, который использует нейронные сети для поиска нелинейных скрытых представлений для заданного распределения данных.</p>
<p>Нейронная сеть состоит из двух частей:</p>
<ul class="list">

- сети энкодера $\mathbf{z}=f(\mathbf{x})$;
- сети декодера $\hat{\mathbf{x}} = g(\mathbf{z})$.
<p></p>

Здесь $\mathbf{z}$ — представление скрытого вектора, а $\hat{\mathbf{\mathbf{x}}}$ — «реконструкция» $\mathbf{\mathbf{x}}$ из скрытого пространства. $f(\mathbf{x})$ и $g(\mathbf{z})$ — нейронные сети. Если соединить две части вместе, всю модель можно описать соотношением:
$$\hat{\mathbf{x}} = g(f(\mathbf{x}))$$

В идеале декодер должен иметь возможность точно восстанавливать необработанные данные из скрытого представления энкодера. Если модель способна обучиться такой реконструкции, то мы можем предположить, что наше скрытое пространство хорошо представляет данные. Чтобы реализовать эту цель, мы обучаем модель с некоторой потерей реконструкции между ${||\mathbf{x}-\hat{\mathbf{x}}||}_{2}^{2}$ или $\log (p(\mathbf{x}|\mathbf{z}))$).
<figure class="img"><img src="http://lms-cdn.skillfactory.ru/assets/courseware/v1/e4417a2b6965f1aba40f632edb68cdf0/asset-v1:SkillFactory+MFTIDSLIGHT+2022_DEC+type@asset+block/mftidslight_ml_m1_06.png" alt="" width="">
<p class="grey-text">Источник: <a target="blank" href="https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdb8a9438-cdeb-43ef-aa9e-fe7312e9a664_1336x1100.png">ML@B blog</a></p>
</figure>

Также важно отметить, что $\mathbf{z}$ всегда должен иметь меньшую размерность, чем $\mathbf{x}$. В конце концов, смысл — закодировать сжатое представление данных, чтобы алгоритм был вынужден находить наиболее важные компоненты необработанных данных. Эту сжатую скрытую часть автоэнкодера также часто называют <strong>узким местом автоэнкодера</strong> (bottleneck), потому что она сжимает данные в гораздо меньшем пространстве.
<h2>Модель VAE</h2>
<p>Теперь посмотрим, что отличает вариационный автоэнкодер от обычного. Ключевое отличие связано со структурой, наложенной на скрытое пространство VAE. В идеале мы хотели бы, чтобы наше скрытое пространство объединяло семантически сходные точки данных рядом друг с другом и располагало семантически непохожие точки далеко друг от друга. Желательно, чтобы большая часть распределения данных составляла довольно компактные значения в скрытом пространстве и не простиралась до бесконечности.</p>
<p>Основная проблема с автоэнкодерами Vanilla заключается в том, что изученные латентные данные не обязательно обладают одним из этих свойств. Модель может изучить любое скрытое пространство, которое захочет, поэтому часто запоминает отдельные точки данных, помещая их в свои собственные отдаленные карманы скрытого пространства. На рисунке ниже показаны проблемы со скрытыми пространствами автоэнкодера и VAE.</p>
<figure class="img"><img src="http://lms-cdn.skillfactory.ru/assets/courseware/v1/45f3f024e8d526819223cb868c9c65ad/asset-v1:SkillFactory+MFTIDSLIGHT+2022_DEC+type@asset+block/mftidslight_ml_m1_07.png" alt="" width="">
<p class="grey-text">Источник: <a target="blank" href="https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F665c5c27-7bdb-4a5c-bbd5-3d52b880e863_1384x782.png">ML@B blog</a></p>
</figure>

Вариационные автоэнкодеры преодолевают эту проблему — они применяют априорную вероятность к скрытому пространству. Чтобы формализовать это, рассмотрим наше скрытое пространство $\mathbf{z}$ как случайную величину. Сначала применим априорное $p(\mathbf{z})$ к латентным данным — $j$, обычно в большинстве VAE это стандартное гауссово распределение $\mathcal{N}(0,1)$. Учитывая необработанную точку данных $\mathbf{\mathbf{x}}$, мы также определяем апостериорное значение для скрытого пространства как $p(\mathbf{z}|\mathbf{x})$.
</p>
Наша конечная цель — вычисление апостериорного значения для данных, которое мы можем выразить с помощью правила Байеса:
</p>

$$p(\mathbf{z}|\mathbf{x})=\frac {p(\mathbf{x}|\mathbf{z})p(\mathbf{z})}{p(\mathbf{x})}$$

К сожалению, поскольку мы работаем с непрерывными переменными, $p(\mathbf{x})$ — вычислительно сложная величина. Чтобы сделать вещи вычислимыми, мы ограничиваем нашу аппроксимацию апостериорного распределения определенным семейством распределений — независимыми гауссовскими. Назовем это аппроксимированное распределение $p(\mathbf{z}|\mathbf{x})$. Теперь целью становится минимизация расхождения KL (Кульбака-Лейблера) между истинной апостериорной и этой аппроксимированной формой.

Опустим математические детали и получаем, что для конечной цели нужно минимизировать функцию потерь:

$$- E_{\mathbf{z}\sim q(\mathbf{z}|\mathbf{x})}[\log(p(\mathbf{x}|\mathbf{z}))]+KL(q(\mathbf{z}|\mathbf{x})||p(\mathbf{z}))$$

В этом случае $q(\mathbf{z}|\mathbf{x})$ аппроксимируется энкодером, а $p(\mathbf{x}|\mathbf{z})$ представляется декодером.

<p>На самом деле, функция потерь VAE имеет хорошую интуитивную интерпретацию — первый член отвечает за реконструкцию, а второй представляет собой регуляризацию апостериорного распределения. Апостериорное значение притягивается к априорному из-за дивергенции KL, по существу выравнивая латентное пространство по направлению к гауссовскому априорному. Это приводит к сохранению скрытого распределения около 0.</p>
<p>Учитывая достаточно выразительные нейронные сети, скрытое пространство VAE может очень точно соответствовать сложным распределениям данных. Как правило, можно ожидать плавных переходов между различными типами точек данных в скрытом пространстве. Например, если VAE обучается на MNIST (датасет с изображениями цифр), можно ожидать кластер для 6 и отдельный кластер для 5. Если пойти между двумя кластерами, то должна получиться цифра, которая выглядит как странная смесь 5 и 6.</p>
<h2>Итоги занятия</h2>
<ol class="num-list">
<li>Генеративные модели оценивают распределение данных. Дискриминативные модели различают разные виды экземпляров данных.</li>
<li>Генеративные модели можно использовать для понимания структуры данных, генерации данных для обучения и тестирования.</li>
<li>В основном выделяют 4 класса генеративных моделей: VAE, GAN, Normalizing Flow, Diffusion Models. Каждый класс моделей имеет свои плюсы и минусы.</li>
<li>Часто из данных можно получить сжатое скрытое представление. Для этого используется модель автоэнкодера.</li>
<li>Чтобы обеспечить непрерывность этого представления, используются вариационные автоэнкодеры.</li>
</ol>
</div>

# 3/7   2. Диффузионные модели

<h2>Цель занятия</h2>
<p>Ознакомимся с диффузионными моделями.</p>
<h2>План занятия</h2>
<ol class="num-list">
<li>Диффузия в физике.</li>
<li>Математика диффузионных моделей.</li>
<li>Как происходит обучение</li>
<li>Архитектура диффузионной модели</li>
</ol>
<h2>Диффузия в физике</h2>
<p>Как известно еще со школы, <strong>процессом диффузии</strong> называется перемещение частиц или молекул из области высокой концентрации в область низкой концентрации, обусловленное градиентом концентрации.</p>
<p>Представим, что у нас есть закрытая банка с некоторым газом. Если ее открыть, то молекулы газа быстро выйдут из банки и попадут в окружающую среду. Спустя какое-то время концентрация молекул газа внутри и снаружи банки станет одинаковой, а распределение молекул газа полностью изменится. Но что, если мы хотим обратить этот процесс вспять?</p>
<figure class="img"><img src="http://lms-cdn.skillfactory.ru/assets/courseware/v1/5e1045dff1640bd5d723567b012e22d9/asset-v1:SkillFactory+MFTIDSLIGHT+2022_DEC+type@asset+block/mftidslight_ml_m1_08.png" alt="" width="400">
<p class="grey-text">Источник: <a target="blank" href="https://chem.libretexts.org/Under_Construction/Purgatory/Kinetic_Theory_of_Gases">Kinetic theory of gases</a></p>
</figure>
<p>Это непростая задача. На помощь приходит неравновесная статистическая физика. Идея заключается в том, чтобы постепенно преобразовывать одно распределение в другое. Диффузионные модели как раз используют данную концепцию. Они определяют марковскую цепь шагов диффузии, чтобы постепенно добавлять случайный шум к данным, а затем учатся обращать процесс диффузии вспять, чтобы создавать желаемые выборки данных из шума.</p>
<p class="term"><strong>Марковская цепь </strong>— последовательность случайных событий с конечным или счетным числом исходов, где вероятность наступления каждого события зависит только от состояния, достигнутого в предыдущем событии. Говоря простым языком, она характеризуется следующим свойством — при фиксированном настоящем будущее независимо от прошлого.</p>
<p>Добавление шума к исходным данным постепенно нарушает их распределение, а затем с помощью нейронной сети этот шум устраняется и восстанавливает данные. Повторяя этот процесс с качественными данными достаточное количество раз, модель научится оценивать исходное распределение данных. После этого мы можем начать с простого шума и применить обученную нейронную сеть для создания нового изображения, которое представляет исходный обучающий набор данных.</p>
<p>Таким образом, каждая диффузионная модель выполняет два основных процесса:</p>
<ul class="list">
<li><strong>forward pass</strong> (прямое распространение);</li>
<li><strong>backward pass </strong>(обратное распространение).</li>
</ul>
<p></p>
<p><strong>Немного истории.</strong> Диффузионные модели в глубоком обучении впервые были представлены в 2015 году Соул-Дикштейном в статье «Глубокое неконтролируемое обучение с использованием неравновесной термодинамики». К сожалению, некоторое время информация оставалась за кулисами, пока в 2019 году не опубликовали статью «Генеративное моделирование путем оценки градиентов распределения данных». Ее авторы (Сонг и др.) использовали тот же принцип, что и Соул-Дикштейн, но другой подход. В 2020 году Хо опубликовал популярную в настоящее время статью «Вероятностные модели рассеяния шума» (сокращенно — DDPM).</p>
<p>После 2020 года исследования в области диффузионных моделей получили активную популярность. За относительно короткое время был достигнут значительный прогресс в создании, обучении и улучшении генеративного моделирования на основе диффузии.</p>
</div>
<h2>Математика диффузионных моделей</h2>

<h3>Forward process</h3>
