{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0f5eee496d7f491bb628a623a184faf4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bfd65d72f19246ed8ca7cf0538c68cd2",
              "IPY_MODEL_6d8eeb19615d4c37847cddd1da95f49b",
              "IPY_MODEL_e71652813ea44c61b652c2b841e663eb"
            ],
            "layout": "IPY_MODEL_ee6b9e18021c4e3cbc66260bd50a2c5e"
          }
        },
        "bfd65d72f19246ed8ca7cf0538c68cd2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_56a17ae296a94e869281a939e040162b",
            "placeholder": "​",
            "style": "IPY_MODEL_778ac1a727234232bbe2e6f770adf4e8",
            "value": "Downloading model.safetensors: 100%"
          }
        },
        "6d8eeb19615d4c37847cddd1da95f49b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_09061d75a18441bf884de7ae61f10ec5",
            "max": 102548236,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_aa1e74cb00964841ae7e5818362be741",
            "value": 102548236
          }
        },
        "e71652813ea44c61b652c2b841e663eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3804d6a3bb054db99f8968b9e9ad3273",
            "placeholder": "​",
            "style": "IPY_MODEL_6fcc6fce94c34328a4fbce056f54764e",
            "value": " 103M/103M [00:00&lt;00:00, 221MB/s]"
          }
        },
        "ee6b9e18021c4e3cbc66260bd50a2c5e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "56a17ae296a94e869281a939e040162b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "778ac1a727234232bbe2e6f770adf4e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "09061d75a18441bf884de7ae61f10ec5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa1e74cb00964841ae7e5818362be741": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3804d6a3bb054db99f8968b9e9ad3273": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6fcc6fce94c34328a4fbce056f54764e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Модуль 2. Диффузионные модели. Часть 2.\n",
        "##Семинар №3.Изучение особенностей диффузионных моделей с библиотекой accelerate.\n",
        "\n",
        "### Цель занятия\n",
        "Рассмотреть библиотеку accelerate для обучения, дообучения диффузионных моделей и поработать с ней.\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "### Перенос вашего кода в Accelerate"
      ],
      "metadata": {
        "id": "TP1IpbMqUUxy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "В этом руководстве подробно описано, как легко преобразовать существующий код PyTorch для использования Accelerate. Вы увидите, что, просто изменив несколько строк кода, Accelerate может творить чудеса и помочь вам с легкостью запускать свой код в распределенных системах."
      ],
      "metadata": {
        "id": "E14f4JELUUD4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Базовый цикл обучения"
      ],
      "metadata": {
        "id": "tT0z5sJKVFG7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Для начала напишем очень простой цикл обучения PyTorch."
      ],
      "metadata": {
        "id": "WZtGCtZ6VT2Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Мы предполагаем, что `training_dataloader`, `model`, `optimizer`, `scheduler` и `loss_function` были определены заранее."
      ],
      "metadata": {
        "id": "r2R3vRtaazwg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "device = \"cuda\"\n",
        "model.to(device)\n",
        "\n",
        "for batch in training_dataloader:\n",
        "    optimizer.zero_grad()\n",
        "    inputs, targets = batch\n",
        "    inputs = inputs.to(device)\n",
        "    targets = targets.to(device)\n",
        "    outputs = model(inputs)\n",
        "    loss = loss_function(outputs, targets)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    scheduler.step()\n",
        "```"
      ],
      "metadata": {
        "id": "0ttgvCCbaviT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Добавляем Accelerate"
      ],
      "metadata": {
        "id": "PSVWxxi6XYS_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Чтобы начать использовать Accelerate, сначала импортируйте и создайте экземпляр Accelerator:"
      ],
      "metadata": {
        "id": "xSPKbDT4Xoio"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "from accelerate import Accelerator\n",
        "\n",
        "accelerator = Accelerator()\n",
        "```"
      ],
      "metadata": {
        "id": "i2Zgl6YtbImG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accelerator — это основная сила, позволяющая использовать все возможные варианты распределенного обучения!"
      ],
      "metadata": {
        "id": "60iwA1v_XvNg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Настройка правильного устройства"
      ],
      "metadata": {
        "id": "Awn4yuiyX4l9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Класс Accelerator знает, на какое устройство можно в любой момент переместить любой объект PyTorch, поэтому вам следует изменить определение устройства, чтобы оно исходило из Accelerator:"
      ],
      "metadata": {
        "id": "Cmq4ksqKX6pT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "- device = 'cuda'\n",
        "+ device = accelerator.device\n",
        "  model.to(device)\n",
        "```"
      ],
      "metadata": {
        "id": "QUse7qd5bQz0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Подготовка объектов"
      ],
      "metadata": {
        "id": "rX9x_lyDYT7N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Далее нужно передать все важные объекты, связанные с обучением, в `prepare()`. Accelerate позаботится о том, чтобы все было настроено в текущей среде, чтобы вы могли начать обучение:"
      ],
      "metadata": {
        "id": "asXMYCmPYXHY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "model, optimizer, training_dataloader, scheduler = accelerator.prepare(\n",
        "    model, optimizer, training_dataloader, scheduler\n",
        ")\n",
        "```"
      ],
      "metadata": {
        "id": "0OvzW6tZbUUC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Эти объекты возвращаются в том же порядке, в котором они были отправлены. По умолчанию при использовании `device_placement=True` все объекты, которые можно отправить на нужное устройство, будут возвращены. Если вам нужно работать с данными, которые не передаются в [~Accelerator.prepare], но должны находиться на активном устройстве, вам следует передать устройство, созданное вами ранее.\n",
        "\n",
        "> Accelerate подготавливает только объекты, которые наследуются от соответствующих классов PyTorch (например, torch.optim.Optimizer)."
      ],
      "metadata": {
        "id": "JACg1HMMYluX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Изменение цикла обучения"
      ],
      "metadata": {
        "id": "hLZ03JsoZmVj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Наконец, в цикле обучения необходимо изменить три строки кода. Классы `DataLoader` Accelerate по умолчанию автоматически обрабатывают размещение устройства, а для выполнения обратного прохода следует использовать метод `backward()`:"
      ],
      "metadata": {
        "id": "nKdtUzzVZo_t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "outputs = model(inputs)\n",
        "loss = loss_function(outputs, targets)\n",
        "accelerator.backward(loss)\n",
        "\n",
        "# Вместо:\n",
        "# inputs = inputs.to(device)\n",
        "# targets = targets.to(device)\n",
        "# outputs = model(inputs)\n",
        "# loss = loss_function(outputs, targets)\n",
        "# loss.backward()\n",
        "```"
      ],
      "metadata": {
        "id": "JTiQ8CL2bYK8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Теперь ваш тренировочный цикл готов к использованию Accelerate!"
      ],
      "metadata": {
        "id": "w0sXY2KGabG4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Конечный код"
      ],
      "metadata": {
        "id": "KfaR8_rKag9x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ниже приведена окончательная версия преобразованного кода:"
      ],
      "metadata": {
        "id": "OPhCVzfkahJh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from accelerate import Accelerator\n",
        "\n",
        "accelerator = Accelerator()\n",
        "\n",
        "model, optimizer, training_dataloader, scheduler = accelerator.prepare(\n",
        "    model, optimizer, training_dataloader, scheduler\n",
        ")\n",
        "\n",
        "for batch in training_dataloader:\n",
        "    optimizer.zero_grad()\n",
        "    inputs, targets = batch\n",
        "    outputs = model(inputs)\n",
        "    loss = loss_function(outputs, targets)\n",
        "    accelerator.backward(loss)\n",
        "    optimizer.step()\n",
        "    scheduler.step()"
      ],
      "metadata": {
        "id": "Z8TjGf1ksmQT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Но как запустить этот код и заставить его использовать специальное оборудование, доступное для него?\n",
        "\n",
        "Во-первых, следует переписать приведенный выше код в функцию и сделать ее вызываемой как скрипт. Например:"
      ],
      "metadata": {
        "id": "atMRDZGRstRO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from accelerate import Accelerator\n",
        "\n",
        "def main():\n",
        "    accelerator = Accelerator()\n",
        "\n",
        "    model, optimizer, training_dataloader, scheduler = accelerator.prepare(\n",
        "        model, optimizer, training_dataloader, scheduler\n",
        "    )\n",
        "\n",
        "    for batch in training_dataloader:\n",
        "        optimizer.zero_grad()\n",
        "        inputs, targets = batch\n",
        "        outputs = model(inputs)\n",
        "        loss = loss_function(outputs, targets)\n",
        "        accelerator.backward(loss)\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "Zi6lwmzEtyG-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Использование запуска Accelerate"
      ],
      "metadata": {
        "id": "7jXpI_sDt_gN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "В Accelerate есть специальная команда CLI, которая поможет вам запустить код в вашей системе посредством accelerate launch. Эта команда охватывает все различные команды, необходимые для запуска вашего скрипта на различных платформах, и вам не нужно запоминать, что представляет собой каждая из них.\n",
        "\n",
        "Можно быстро запустить свой скрипт, используя:"
      ],
      "metadata": {
        "id": "Yi0np1jGuEGC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "accelerate launch {script_name.py} --arg1 --arg2 ..."
      ],
      "metadata": {
        "id": "jbiEApkOvW4V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Просто поместите `accelerate launch` в начало вашей команды, а затем передайте дополнительные аргументы и параметры в ваш скрипт, как обычно.\n",
        "\n",
        "Здесь также можно изменить все ожидаемые переменные среды. Например, вот как использовать `accelerate launch` с одним GPU:"
      ],
      "metadata": {
        "id": "T_dE9gEouqh8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CUDA_VISIBLE_DEVICES=\"0\" accelerate launch {script_name.py} --arg1 --arg2 ..."
      ],
      "metadata": {
        "id": "ynIAxhRvvTCf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Вы также можете использовать `accelerate launch` без предварительного конфига accelerate, но вам может потребоваться вручную передать правильные параметры конфигурации. В этом случае Accelerate примет за вас некоторые решения по гиперпараметрам, например, если GPU доступны, он будет использовать их все по умолчанию без смешанной точности. Вот как можно использовать все GPU и тренироваться с отключенной смешанной точностью:"
      ],
      "metadata": {
        "id": "RJwEgqzQvO1-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "accelerate launch --multi_gpu {script_name.py} {--arg1} {--arg2} ..."
      ],
      "metadata": {
        "id": "yoH3kMijuEKy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Или указав количество используемых GPU:"
      ],
      "metadata": {
        "id": "p0uBAme4v8AZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "accelerate launch --num_processes=2 {script_name.py} {--arg1} {--arg2} ..."
      ],
      "metadata": {
        "id": "FjhlDXBhv8Gd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Чтобы получить более конкретную информацию, вам следует передать необходимые параметры самостоятельно. Например, вот как можно запустить тот же сценарий на двух графических процессорах со смешанной точностью, избегая при этом всех предупреждений:"
      ],
      "metadata": {
        "id": "z1EYX54Rv_u8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "accelerate launch --multi_gpu --mixed_precision=fp16 --num_processes=2 {script_name.py} {--arg1} {--arg2} ..."
      ],
      "metadata": {
        "id": "hkcF9WTov_0I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Чтобы получить полный список параметров, которые вы можете передать, запустите:"
      ],
      "metadata": {
        "id": "u3FRKkG7wHQZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "accelerate launch -h"
      ],
      "metadata": {
        "id": "3U4jEfjnwHi5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Для визуализации этой разницы более ранний запуск `accelerate` на нескольких GPU с torchrun выглядел бы примерно так:"
      ],
      "metadata": {
        "id": "0f0yvItzwO6p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MIXED_PRECISION=\"fp16\" torchrun --nproc_per_node=2 --num_machines=1 {script_name.py} {--arg1} {--arg2} ..."
      ],
      "metadata": {
        "id": "GULV-aUOwPBh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Вы также можете запустить свой скрипт, используя CLI запуск в качестве самого модуля Python, что позволяет передавать другие варианты поведения запуска, специфичные для Python. Для этого используйте `accelerate.commands.launch` вместо «accelerate launch»:"
      ],
      "metadata": {
        "id": "18DLXtuVxwoy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "python -m accelerate.commands.launch --num_processes=2 {script_name.py} {--arg1} {--arg2}"
      ],
      "metadata": {
        "id": "fMOus-T1x5bA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Если вы хотите выполнить сценарий с любыми другими флагами python, вы можете передать их так же, как и -m, например, как в приведенном ниже примере, включающем небуферизованный стандартный вывод и стандартный поток ошибок:"
      ],
      "metadata": {
        "id": "-YC1b16pzpSN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "python -u -m accelerate.commands.launch --num_processes=2 {script_name.py} {--arg1} {--arg2}"
      ],
      "metadata": {
        "id": "hqcCM6MXzpZT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Почему вы всегда должны использовать accelerate config"
      ],
      "metadata": {
        "id": "3NwihNZGz0nJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Почему это настолько полезно, что вам всегда нужно запускать `accelerate config`?\n",
        "\n",
        "Помните тот предыдущий вызов `accelerate launch`, а также запуск `torchrun`? После настройки, чтобы запустить этот скрипт с необходимыми частями, вам просто нужно сразу использовать `accelerate launch`, не передавая ничего больше:"
      ],
      "metadata": {
        "id": "sl8LkKhgz4MQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "accelerate launch {script_name.py} {--arg1} {--arg2} ..."
      ],
      "metadata": {
        "id": "c5pT6TPsz2g4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Пользовательские конфигурации"
      ],
      "metadata": {
        "id": "RFUXaydD0TnH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Как кратко упоминалось ранее, ускоренный запуск следует в основном использовать путем объединения настроек набора, созданных с помощью команды ускорения конфигурации. Эти конфигурации сохраняются в файле `default_config.yaml` в папке кэша для `Accelerate`. Эта папка кэша находится по адресу (в порядке убывания приоритета):\n",
        "\n",
        "К содержимому вашей переменной среды `HF_HOME` добавлен суффикс ускорения.\n",
        "Если он не существует, к содержимому вашей переменной среды `XDG_CACHE_HOME` добавляется суффикс `huggingface/accelerate`.\n",
        "Если и его не существует, папка `~/.cache/huggingface/accelerate`.\n",
        "Чтобы иметь несколько конфигураций, флаг `--config_file` можно передать команде ускоренного запуска вместе с расположением пользовательского файла `yaml`.\n",
        "\n",
        "Пример `yaml` может выглядеть примерно так для двух GPU на одной машине с использованием `fp16` для смешанной точности:"
      ],
      "metadata": {
        "id": "AOtQOtSB0b5G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "compute_environment: LOCAL_MACHINE\n",
        "deepspeed_config: {}\n",
        "distributed_type: MULTI_GPU\n",
        "fsdp_config: {}\n",
        "machine_rank: 0\n",
        "main_process_ip: null\n",
        "main_process_port: null\n",
        "main_training_function: main\n",
        "mixed_precision: fp16\n",
        "num_machines: 1\n",
        "num_processes: 2\n",
        "use_cpu: false"
      ],
      "metadata": {
        "id": "PbCRZ12w0Tuu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Запуск сценария из местоположения этого пользовательского файла `yaml` выглядит следующим образом:"
      ],
      "metadata": {
        "id": "77DRlAJ40kie"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "accelerate launch --config_file {path/to/config/my_config_file.yaml} {script_name.py} {--arg1} {--arg2} ..."
      ],
      "metadata": {
        "id": "miYt4o--0k5Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Запуск обучения на нескольких узлах"
      ],
      "metadata": {
        "id": "teCSO1SZbnYM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Настройка среды"
      ],
      "metadata": {
        "id": "mCVoAbPVbqAZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Прежде чем можно будет выполнить какое-либо обучение, в системе должен существовать файл accelerate config. Обычно это можно сделать, выполнив в терминале следующую команду:\n",
        "```\n",
        "accelerate config\n",
        "```\n",
        "Однако, если общие настройки по умолчанию подходят и вы не используете TPU, у ускорения есть утилита для быстрой записи конфигурации вашего GPU в файл конфигурации через `write_basic_config`.\n",
        "\n",
        "Следующая ячейка перезапустит Jupyter после записи конфигурации, поскольку для этого был вызван код CUDA. CUDA не может быть инициализирован более одного раза (один раз для ноутбуков с одним GPU, используемых по умолчанию, а затем еще раз при вызове `notebook_launcher`). Можно выполнять отладку в блокноте и вызывать CUDA, но помните, что для окончательного обучения необходимо выполнить полную очистку и перезапуск, как показано ниже:\n",
        "\n"
      ],
      "metadata": {
        "id": "Mg6XuxmXbxBb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install timm accelerate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K2iaAsnQzM69",
        "outputId": "113df509-4b2f-4e43-f22e-308a0c1ea5fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting timm\n",
            "  Downloading timm-0.9.7-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting accelerate\n",
            "  Downloading accelerate-0.23.0-py3-none-any.whl (258 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m258.1/258.1 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.7 in /usr/local/lib/python3.10/dist-packages (from timm) (2.0.1+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm) (0.15.2+cu118)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm) (6.0.1)\n",
            "Collecting huggingface-hub (from timm)\n",
            "  Downloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors (from timm)\n",
            "  Downloading safetensors-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.7->timm) (3.27.4.1)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.7->timm) (16.0.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (4.66.1)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.7->timm) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.7->timm) (1.3.0)\n",
            "Installing collected packages: safetensors, huggingface-hub, timm, accelerate\n",
            "Successfully installed accelerate-0.23.0 huggingface-hub-0.17.3 safetensors-0.3.3 timm-0.9.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import os\n",
        "# from accelerate.utils import write_basic_config\n",
        "# write_basic_config() # Write a config file\n",
        "# os._exit(00) # Restart the notebook"
      ],
      "metadata": {
        "id": "jMXMGUlMbxNa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Подготовка датасета и модели"
      ],
      "metadata": {
        "id": "SlHVqAS2d3ax"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Далее нужно подготовить набор данных. Как упоминалось ранее, при подготовке `DataLoaders` и модели следует проявлять особую осторожность, чтобы убедиться, что ни на один GPU данные внутри не переносятся.\n",
        "\n",
        "Если вы это сделаете, рекомендуется поместить этот конкретный код в функцию и вызывать ее из интерфейса запуска ноутбука, который будет показан позже.\n",
        "\n",
        "Убедитесь, что датасет загружен в соответствии с инструкциями [здесь](https://github.com/huggingface/accelerate/tree/main/examples#simple-vision-example)."
      ],
      "metadata": {
        "id": "tOYp-CjDd3dV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://www.robots.ox.ac.uk/~vgg/data/pets/data/images.tar.gz\n",
        "!tar -xzf images.tar.gz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZTzJdRGkq0an",
        "outputId": "9f957abf-02c4-42fa-bd44-8a32a2ca9f9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-09-26 18:06:06--  https://www.robots.ox.ac.uk/~vgg/data/pets/data/images.tar.gz\n",
            "Resolving www.robots.ox.ac.uk (www.robots.ox.ac.uk)... 129.67.94.2\n",
            "Connecting to www.robots.ox.ac.uk (www.robots.ox.ac.uk)|129.67.94.2|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://thor.robots.ox.ac.uk/~vgg/data/pets/images.tar.gz [following]\n",
            "--2023-09-26 18:06:07--  https://thor.robots.ox.ac.uk/~vgg/data/pets/images.tar.gz\n",
            "Resolving thor.robots.ox.ac.uk (thor.robots.ox.ac.uk)... 129.67.95.98\n",
            "Connecting to thor.robots.ox.ac.uk (thor.robots.ox.ac.uk)|129.67.95.98|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://thor.robots.ox.ac.uk/datasets/pets/images.tar.gz [following]\n",
            "--2023-09-26 18:06:08--  https://thor.robots.ox.ac.uk/datasets/pets/images.tar.gz\n",
            "Reusing existing connection to thor.robots.ox.ac.uk:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 791918971 (755M) [application/octet-stream]\n",
            "Saving to: ‘images.tar.gz’\n",
            "\n",
            "images.tar.gz       100%[===================>] 755.23M  26.6MB/s    in 29s     \n",
            "\n",
            "2023-09-26 18:06:37 (26.1 MB/s) - ‘images.tar.gz’ saved [791918971/791918971]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, re, torch, PIL\n",
        "import numpy as np\n",
        "\n",
        "from torch.optim.lr_scheduler import OneCycleLR\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision.transforms import Compose, RandomResizedCrop, Resize, ToTensor\n",
        "\n",
        "from accelerate import Accelerator\n",
        "from accelerate.utils import set_seed\n",
        "from timm import create_model"
      ],
      "metadata": {
        "id": "J0UAn-5hfq01"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Сначала мы создадим функцию для извлечения имени класса на основе файла:"
      ],
      "metadata": {
        "id": "-y3TxKsTdyU-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "data_dir = \"/content/images\"\n",
        "fnames = os.listdir(data_dir)\n",
        "fname = fnames[0]\n",
        "print(fname)"
      ],
      "metadata": {
        "id": "m0xfx3-pfv8M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ba49eae-10b1-40cc-ec8d-56c8f8d071d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Maine_Coon_131.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "В данном случае метка — `Maine_Coon`:"
      ],
      "metadata": {
        "id": "T-1ZltUbfxJq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchvision"
      ],
      "metadata": {
        "id": "HqOlvuIzf1Ff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a801b67a-2907-44d1-8e3a-4803761a2a49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.15.2+cu118)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.23.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.31.0)\n",
            "Requirement already satisfied: torch==2.0.1 in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.0.1+cu118)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1->torchvision) (3.27.4.1)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1->torchvision) (16.0.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.0.1->torchvision) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.0.1->torchvision) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "def extract_label(fname):\n",
        "    stem = fname.split(os.path.sep)[-1]\n",
        "    return re.search(r\"^(.*)_\\d+\\.jpg$\", stem).groups()[0]"
      ],
      "metadata": {
        "id": "FplDmoyaf16T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "extract_label(fname)"
      ],
      "metadata": {
        "id": "G8Ft1hYgf3Vi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4cc3f09d-af81-4e1c-8a5e-405bf74f0496"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Maine_Coon'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Дальше создаем класс `Dataset`"
      ],
      "metadata": {
        "id": "pNnewkkff4y8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PetsDataset(Dataset):\n",
        "    def __init__(self, file_names, image_transform=None, label_to_id=None):\n",
        "        self.file_names = file_names\n",
        "        self.image_transform = image_transform\n",
        "        self.label_to_id = label_to_id\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.file_names)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        fname = self.file_names[idx]\n",
        "        raw_image = PIL.Image.open(fname)\n",
        "        image = raw_image.convert(\"RGB\")\n",
        "        if self.image_transform is not None:\n",
        "            image = self.image_transform(image)\n",
        "        label = extract_label(fname)\n",
        "        if self.label_to_id is not None:\n",
        "            label = self.label_to_id[label]\n",
        "        return {\"image\": image, \"label\": label}"
      ],
      "metadata": {
        "id": "N3DByCTLf44C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "И создадим наш набор данных"
      ],
      "metadata": {
        "id": "p-rO4Sz8gKwS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Захватываем все имена файлов изображений\n",
        "fnames = [\n",
        "    os.path.join(data_dir, fname)\n",
        "    for fname in fnames\n",
        "    if fname.endswith(\".jpg\")\n",
        "]\n",
        "\n",
        "# Создаем метки\n",
        "all_labels = [\n",
        "    extract_label(fname)\n",
        "    for fname in fnames\n",
        "]\n",
        "id_to_label = list(set(all_labels))\n",
        "id_to_label.sort()\n",
        "label_to_id = {lbl: i for i, lbl in enumerate(id_to_label)}"
      ],
      "metadata": {
        "id": "1aTljOhDgK55"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "> Примечание: это будет храниться внутри функции, поскольку мы будем устанавливать `seed` во время обучения.\n",
        "\n"
      ],
      "metadata": {
        "id": "NPP_sX4qgUHI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_dataloaders(batch_size:int=64):\n",
        "    \"Создает множество dataloaders с batch_size\"\n",
        "    random_perm = np.random.permutation(len(fnames))\n",
        "    cut = int(0.8 * len(fnames))\n",
        "    train_split = random_perm[:cut]\n",
        "    eval_split = random_perm[:cut]\n",
        "\n",
        "    # Для обучения мы используемы обычный RandomResizedCrop\n",
        "    train_tfm = Compose([\n",
        "        RandomResizedCrop((224, 224), scale=(0.5, 1.0)),\n",
        "        ToTensor()\n",
        "    ])\n",
        "    train_dataset = PetsDataset(\n",
        "        [fnames[i] for i in train_split],\n",
        "        image_transform=train_tfm,\n",
        "        label_to_id=label_to_id\n",
        "    )\n",
        "\n",
        "    # Для eval мы используем детерминированный Resize\n",
        "    eval_tfm = Compose([\n",
        "        Resize((224, 224)),\n",
        "        ToTensor()\n",
        "    ])\n",
        "    eval_dataset = PetsDataset(\n",
        "        [fnames[i] for i in eval_split],\n",
        "        image_transform=eval_tfm,\n",
        "        label_to_id=label_to_id\n",
        "    )\n",
        "\n",
        "    # Создание экземпляров dataloader\n",
        "    train_dataloader = DataLoader(\n",
        "        train_dataset,\n",
        "        shuffle=True,\n",
        "        batch_size=batch_size,\n",
        "        num_workers=4\n",
        "    )\n",
        "    eval_dataloader = DataLoader(\n",
        "        eval_dataset,\n",
        "        shuffle=False,\n",
        "        batch_size=batch_size*2,\n",
        "        num_workers=4\n",
        "    )\n",
        "    return train_dataloader, eval_dataloader"
      ],
      "metadata": {
        "id": "-8SN1OB7gUQU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Написание функции обучения"
      ],
      "metadata": {
        "id": "8KeXxp7xg_vQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Теперь мы можем построить наш цикл обучения. `notebook_launcher` работает, передавая функцию для вызова, которая будет выполняться в распределенной системе.\n",
        "\n",
        "Вот базовый цикл обучения для нашей задачи классификации животных:"
      ],
      "metadata": {
        "id": "_r7KOwJOhDk0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim.lr_scheduler import CosineAnnealingLR"
      ],
      "metadata": {
        "id": "6oc69kLqhDue"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def training_loop(mixed_precision=\"fp16\", seed:int=42, batch_size:int=64):\n",
        "    set_seed(seed)\n",
        "    # Создаем accelerator\n",
        "    accelerator = Accelerator(mixed_precision=mixed_precision)\n",
        "    # Создаем dataloaders\n",
        "    train_dataloader, eval_dataloader = get_dataloaders(batch_size)\n",
        "\n",
        "    # Создаем экземпляр модели (здесь мы строим модель так, чтобы начальное число также контролировало новые инициализации веса)\n",
        "    model = create_model(\"resnet50d\", pretrained=True, num_classes=len(label_to_id))\n",
        "\n",
        "    # Замораживаем базовую модель\n",
        "    for param in model.parameters():\n",
        "        param.requires_grad=False\n",
        "    for param in model.get_classifier().parameters():\n",
        "        param.requires_grad=True\n",
        "\n",
        "    # Нормализуем батчи изображений чтобы было более быстро\n",
        "    mean = torch.tensor(model.default_cfg[\"mean\"])[None, :, None, None]\n",
        "    std = torch.tensor(model.default_cfg[\"std\"])[None, :, None, None]\n",
        "\n",
        "    # Чтобы сделать эту константу доступной на активном устройстве, мы устанавливаем ее на accelerator устройство.\n",
        "    mean = mean.to(accelerator.device)\n",
        "    std = std.to(accelerator.device)\n",
        "\n",
        "    # Создаем экземпляр оптимизатора\n",
        "    optimizer = torch.optim.Adam(params=model.parameters(), lr = 3e-2/25)\n",
        "\n",
        "    # Создаем learning rate scheduler\n",
        "    lr_scheduler = OneCycleLR(\n",
        "        optimizer=optimizer,\n",
        "        max_lr=3e-2,\n",
        "        epochs=5,\n",
        "        steps_per_epoch=len(train_dataloader)\n",
        "    )\n",
        "\n",
        "    # Подготовка\n",
        "    # Нет определенного порядка, который нужно запомнить,\n",
        "    # нам просто нужно распаковать объекты в том же порядке,\n",
        "    # в котором мы указали их в методе подготовки..\n",
        "    model, optimizer, train_dataloader, eval_dataloader, lr_scheduler = accelerator.prepare(\n",
        "        model, optimizer, train_dataloader, eval_dataloader, lr_scheduler\n",
        "    )\n",
        "\n",
        "    # Теперь тренируем модель\n",
        "    for epoch in range(5):\n",
        "        model.train()\n",
        "        for step, batch in enumerate(train_dataloader):\n",
        "            # Мы могли бы избежать этой строки, поскольку установили accelerator с помощью device_placement=True.\n",
        "            batch = {k: v.to(accelerator.device) for k, v in batch.items()}\n",
        "            inputs = (batch[\"image\"] - mean) / std\n",
        "            outputs = model(inputs)\n",
        "            loss = torch.nn.functional.cross_entropy(outputs, batch[\"label\"])\n",
        "            accelerator.backward(loss)\n",
        "            optimizer.step()\n",
        "            lr_scheduler.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        model.eval()\n",
        "        accurate = 0\n",
        "        num_elems = 0\n",
        "        for _, batch in enumerate(eval_dataloader):\n",
        "            # Мы могли бы избежать этой строки, поскольку установили accelerator с помощью device_placement=True.\n",
        "            batch = {k: v.to(accelerator.device) for k, v in batch.items()}\n",
        "            inputs = (batch[\"image\"] - mean) / std\n",
        "            with torch.no_grad():\n",
        "                outputs = model(inputs)\n",
        "            predictions = outputs.argmax(dim=-1)\n",
        "            accurate_preds = accelerator.gather(predictions) == accelerator.gather(batch[\"label\"])\n",
        "            num_elems += accurate_preds.shape[0]\n",
        "            accurate += accurate_preds.long().sum()\n",
        "\n",
        "        eval_metric = accurate.item() / num_elems\n",
        "        # Используем accelerator.print чтобы вывести только на главном процессе.\n",
        "        accelerator.print(f\"epoch {epoch}: {100 * eval_metric:.2f}\")"
      ],
      "metadata": {
        "id": "iuJqgy1khKOH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Все, что осталось, — это использовать `notebook_launcher`.\n",
        "\n",
        "Мы передаем функцию, аргументы (в виде кортежа) и количество процессов для обучения. (Дополнительную информацию см. в [документации](https://huggingface.co/docs/accelerate/package_reference/launchers#accelerate.notebook_launcher))"
      ],
      "metadata": {
        "id": "gJx5Ya_2hMTG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from accelerate import notebook_launcher"
      ],
      "metadata": {
        "id": "TX4jLiZdhXT2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "args = (\"fp16\", 42, 64)\n",
        "notebook_launcher(training_loop, args, num_processes=2)"
      ],
      "metadata": {
        "id": "30bhli3UhZWW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208,
          "referenced_widgets": [
            "0f5eee496d7f491bb628a623a184faf4",
            "bfd65d72f19246ed8ca7cf0538c68cd2",
            "6d8eeb19615d4c37847cddd1da95f49b",
            "e71652813ea44c61b652c2b841e663eb",
            "ee6b9e18021c4e3cbc66260bd50a2c5e",
            "56a17ae296a94e869281a939e040162b",
            "778ac1a727234232bbe2e6f770adf4e8",
            "09061d75a18441bf884de7ae61f10ec5",
            "aa1e74cb00964841ae7e5818362be741",
            "3804d6a3bb054db99f8968b9e9ad3273",
            "6fcc6fce94c34328a4fbce056f54764e"
          ]
        },
        "outputId": "cc6c302b-49af-48ea-f9b2-31fed7794711"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Launching training on one GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading model.safetensors:   0%|          | 0.00/103M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0f5eee496d7f491bb628a623a184faf4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0: 85.88\n",
            "epoch 1: 87.82\n",
            "epoch 2: 93.83\n",
            "epoch 3: 96.96\n",
            "epoch 4: 97.41\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Распределенный inference с Accelerate"
      ],
      "metadata": {
        "id": "z8nMjA4dBz0t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Распределенный inference — распространенный вариант использования, когда вы хотите реализовать запуск модели на нескольких GPU. Пользователи часто хотят отправить несколько разных запросов, каждый на отдельный графический процессор, а затем получить результаты обратно."
      ],
      "metadata": {
        "id": "Mj-G_JbBCIvn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Проблема"
      ],
      "metadata": {
        "id": "LDGPuy25CNyE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Обычно при этом пользователи отправляют модель на определенное устройство, чтобы загрузить ее из CPU, а затем перемещают каждый промпт на другое устройство.\n",
        "\n",
        "Базовый пайплайн, использующий библиотеку `diffusers`, может выглядеть примерно так:"
      ],
      "metadata": {
        "id": "Y83WlnIXCUr8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.distributed as dist\n",
        "from diffusers import DiffusionPipeline\n",
        "\n",
        "pipe = DiffusionPipeline.from_pretrained(\"runwayml/stable-diffusion-v1-5\", torch_dtype=torch.float16)"
      ],
      "metadata": {
        "id": "Nz-6n0-7Bz-C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Затем следует выполнение вывода на основе конкретного промпта:"
      ],
      "metadata": {
        "id": "sUlGZKdXCmdX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_inference(rank, world_size):\n",
        "    dist.init_process_group(\"nccl\", rank=rank, world_size=world_size)\n",
        "    pipe.to(rank)\n",
        "\n",
        "    if torch.distributed.get_rank() == 0:\n",
        "        prompt = \"a dog\"\n",
        "    elif torch.distributed.get_rank() == 1:\n",
        "        prompt = \"a cat\"\n",
        "\n",
        "    result = pipe(prompt).images[0]\n",
        "    result.save(f\"result_{rank}.png\")"
      ],
      "metadata": {
        "id": "kAM7GlZICmjI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Можно заметить, что нам приходится проверять ранг, чтобы знать, какой промпт отправить, что может быть немного утомительно.\n",
        "\n",
        "Тогда пользователь также может подумать, что с `Accelerate` использование `Accelerator` для подготовки `dataloader` для такой задачи также может быть простым способом справиться с этим.\n",
        "\n",
        "Сможет ли оно справиться с этим? Да. Однако добавляет ли это ненужный дополнительный код: тоже да."
      ],
      "metadata": {
        "id": "L7mEjkHGCxBv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Решение\n"
      ],
      "metadata": {
        "id": "mVgG86BPCO6j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "С помощью `Accelerate` мы можем упростить этот процесс, используя контекстный менеджер `Accelerator.split_between_processes()` (который также существует в `PartialState` и `AcceleratorState`). Эта функция автоматически разделит любые данные, которые вы ей передаете (будь то промпт, набор тензоров, словарь предыдущих данных и т. д.) по всем процессам (с возможностью дополнения), чтобы вы могли их сразу использовать.\n",
        "\n",
        "Давайте перепишем приведенный выше пример, используя этот контекстный менеджер:"
      ],
      "metadata": {
        "id": "v3_FsZ6zDCgP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from accelerate import PartialState  # Может быть Accelerator или AcceleratorState\n",
        "from diffusers import DiffusionPipeline\n",
        "\n",
        "pipe = DiffusionPipeline.from_pretrained(\"runwayml/stable-diffusion-v1-5\", torch_dtype=torch.float16)\n",
        "distributed_state = PartialState()\n",
        "pipe.to(distributed_state.device)\n",
        "\n",
        "# Предполагаем\n",
        "with distributed_state.split_between_processes([\"a dog\", \"a cat\"]) as prompt:\n",
        "    result = pipe(prompt).images[0]\n",
        "    result.save(f\"result_{distributed_state.process_index}.png\")"
      ],
      "metadata": {
        "id": "VyWLAtU6DF1c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "А затем, чтобы запустить код, мы можем использовать `Accelerate`:\n",
        "\n",
        "Если вы создали файл конфигурации для использования с помощью `accelerate config`:"
      ],
      "metadata": {
        "id": "FIWFOIpsDSVD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "accelerate launch distributed_inference.py"
      ],
      "metadata": {
        "id": "ZPsK5EwVDSdK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Если у вас есть конкретный файл конфигурации, который вы хотите использовать:"
      ],
      "metadata": {
        "id": "opRiWEqYDgm6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "accelerate launch --config_file my_config.json distributed_inference.py"
      ],
      "metadata": {
        "id": "meye94hsDgrT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Или, если вы не хотите создавать какие-либо файлы конфигурации и запускать их на двух GPU:"
      ],
      "metadata": {
        "id": "hu_rhQ2bDlyj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "accelerate launch --num_processes 2 distributed_inference.py"
      ],
      "metadata": {
        "id": "QNfMzPgrDrDT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Теперь мы довольно легко сократили шаблонный код, необходимый для разделения этих данных, на несколько строк кода.\n",
        "\n",
        "Но что, если у нас будет странное распределение подсказок по графическим процессорам? Например, что, если у нас есть 3 промпта, но только 2 GPU?\n",
        "\n",
        "Под управлением контекстного менеджера первый GPU получит первые два запроса, а второй GPU — третий, гарантируя, что все запросы будут разделены и не потребуется никаких дополнительных затрат.\n",
        "\n",
        "Однако что, если мы затем захотим что-то сделать с результатами всех GPU? (Скажем, собрать их все и выполнить какую-то постобработку). Вы можете передать `apply_padding=True`, чтобы гарантировать, что списки промптов заполняются до одинаковой длины, а дополнительные данные берутся из последней выборки. Таким образом, все GPU будут получать одинаковое количество запросов, и вы сможете собрать результаты.\n",
        "\n",
        "Например:"
      ],
      "metadata": {
        "id": "GnPwxLGEDyer"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from accelerate import PartialState  # Может также быть Accelerator или AcceleratorState\n",
        "from diffusers import DiffusionPipeline\n",
        "\n",
        "pipe = DiffusionPipeline.from_pretrained(\"runwayml/stable-diffusion-v1-5\", torch_dtype=torch.float16)\n",
        "distributed_state = PartialState()\n",
        "pipe.to(distributed_state.device)\n",
        "\n",
        "# Предполагаем два процесса\n",
        "with distributed_state.split_between_processes([\"a dog\", \"a cat\", \"a chicken\"], apply_padding=True) as prompt:\n",
        "    result = pipe(prompt).images"
      ],
      "metadata": {
        "id": "BGcDleqlEE9F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "На первом GPU промптами будут [\"a dog\", \"a cat\"], а на втором GPU - [\"a chicken\", \"a chicken\"]. Обязательно отбросьте окончательный образец, так как он будет копией предыдущего."
      ],
      "metadata": {
        "id": "2585H_6NEI-t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Вывод"
      ],
      "metadata": {
        "id": "_6S6fPynhbrw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "В этом блокноте показано, как выполнять распределенное обучение изнутри Jupyter Notebook. Некоторые ключевые замечания, которые следует запомнить:\n",
        "\n",
        "* Обязательно сохраните любой код, использующий CUDA (или импорт CUDA) для функции, передаваемой в `notebook_launcher`.\n",
        "* Установите `num_processes` как количество устройств, используемых для обучения (например, количество GPU, CPU, TPU и т.д.)."
      ],
      "metadata": {
        "id": "LO0_Rf_XhhJy"
      }
    }
  ]
}